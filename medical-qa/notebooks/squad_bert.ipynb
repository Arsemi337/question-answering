{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T20:02:34.092834100Z",
     "start_time": "2023-10-24T20:02:29.937538900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, DefaultDataCollator, create_optimizer\n",
    "import datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../notebooks')\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# from notebooks.core import constants\n",
    "# from notebooks.core import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7529904f21909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T20:02:34.990191900Z",
     "start_time": "2023-10-24T20:02:34.096342200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "def load_train_val_test_datasets(dataset_path='./../data/datasets/squad'):\n",
    "    train = pd.read_csv(f'{dataset_path}/train.csv').dropna()\n",
    "    val = pd.read_csv(f'{dataset_path}/dev.csv').dropna()\n",
    "    test = pd.read_csv(f'{dataset_path}/test.csv').dropna()\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "def convert_dataframes_to_datasets(dataframes: list):\n",
    "    return tuple(\n",
    "        [datasets.Dataset.from_pandas(dataframe, preserve_index=False) for dataframe in\n",
    "         dataframes])\n",
    "\n",
    "\n",
    "df_train, df_val, df_test = load_train_val_test_datasets()\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = convert_dataframes_to_datasets([df_train, df_val, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd82f21a8585dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T20:02:35.004206400Z",
     "start_time": "2023-10-24T20:02:34.984672600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['index', 'id', 'context', 'question', 'answer_text', 'answer_start'],\n",
       "     num_rows: 68716\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['index', 'id', 'context', 'question', 'answer_text', 'answer_start'],\n",
       "     num_rows: 14724\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['index', 'id', 'context', 'question', 'answer_text', 'answer_start'],\n",
       "     num_rows: 14725\n",
       " }))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db291e0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T20:02:35.576154Z",
     "start_time": "2023-10-24T20:02:35.001208600Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d177b07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T20:03:31.786485700Z",
     "start_time": "2023-10-24T20:02:35.578157600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a6d5265a774e9998891e3005c2f1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/68716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df8459cbed0492b9fdf3b4169140614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14724 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69da8a714d246cf8d75250c5e19c734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens in tokenized train dataset:  870\n",
      "Max number of tokens in tokenized val dataset:  866\n",
      "Max number of tokens in tokenized test dataset:  817\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sample(sample, max_tokens=None, padding=False):\n",
    "    question = sample['question'].strip()\n",
    "    context = sample['context'].strip()\n",
    "\n",
    "    return tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=max_tokens,\n",
    "        padding=padding\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_sample)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_sample)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_sample)\n",
    "\n",
    "print('Max number of tokens in tokenized train dataset: ', len(max(tokenized_train_dataset['input_ids'], key=len)))\n",
    "print('Max number of tokens in tokenized val dataset: ', len(max(tokenized_val_dataset['input_ids'], key=len)))\n",
    "print('Max number of tokens in tokenized test dataset: ', len(max(tokenized_test_dataset['input_ids'], key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e53325b1b3a28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T20:04:12.615175200Z",
     "start_time": "2023-10-24T20:03:31.790492400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object filter_samples_below_number_of_tokens.<locals>.<genexpr> at 0x00000206FCE90C80> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "max_length = 384\n",
    "\n",
    "def filter_samples_below_number_of_tokens(dataset, max_tokens: int):\n",
    "    indices_to_remove = []\n",
    "\n",
    "    # Find indices of samples where number of tokens exceeds max number of tokens\n",
    "    for index, sample in enumerate(dataset):\n",
    "        tokenized_sample = tokenize_sample(sample)\n",
    "        if len(tokenized_sample['input_ids']) > max_tokens:\n",
    "            indices_to_remove.append(index)\n",
    "\n",
    "    # Keep only samples with number of tokens less or equal than max number of tokens\n",
    "    dataset_indices = range(len(dataset))\n",
    "    filtered_dataset = dataset.select(\n",
    "        index for index in dataset_indices if index not in set(indices_to_remove)\n",
    "    )\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "filtered_train_dataset = filter_samples_below_number_of_tokens(train_dataset, max_tokens=max_length)\n",
    "filtered_val_dataset = filter_samples_below_number_of_tokens(val_dataset, max_tokens=max_length)\n",
    "filtered_test_dataset = filter_samples_below_number_of_tokens(test_dataset, max_tokens=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1aebcb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T20:04:12.642224100Z",
     "start_time": "2023-10-24T20:04:12.616680100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in tokenized train dataset before filtering:  68716\n",
      "Number of samples in tokenized val dataset before filtering:  14724\n",
      "Number of samples in tokenized test dataset before filtering:  14725\n",
      "\n",
      "---------------\n",
      "\n",
      "Number of samples in tokenized train dataset after filtering:  67964\n",
      "Number of samples in tokenized val dataset after filtering:  14573\n",
      "Number of samples in tokenized test dataset after filtering:  14552\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples in tokenized train dataset before filtering: ', len(train_dataset))\n",
    "print('Number of samples in tokenized val dataset before filtering: ', len(val_dataset))\n",
    "print('Number of samples in tokenized test dataset before filtering: ', len(test_dataset))\n",
    "\n",
    "print('\\n---------------\\n')\n",
    "\n",
    "print('Number of samples in tokenized train dataset after filtering: ', len(filtered_train_dataset))\n",
    "print('Number of samples in tokenized val dataset after filtering: ', len(filtered_val_dataset))\n",
    "print('Number of samples in tokenized test dataset after filtering: ', len(filtered_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6cdd06c7a27f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T20:12:40.882119Z",
     "start_time": "2023-10-24T20:12:40.853203900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    questions = [q.strip() for q in dataset['question']]\n",
    "    contexts = [c.strip() for c in dataset['context']]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop('offset_mapping')\n",
    "    \n",
    "    answer_start_indices = dataset['answer_start']\n",
    "    answer_texts = dataset['answer_text']\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for index, offset in enumerate(offset_mapping):\n",
    "        start_char = answer_start_indices[index]\n",
    "        end_char = start_char + len(answer_texts[index])\n",
    "        sequence_ids = inputs.sequence_ids(index)\n",
    "\n",
    "        # Find the start and end token indices of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        idx = context_start\n",
    "        while idx <= context_end and offset[idx][0] <= start_char:\n",
    "            idx += 1\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "        idx = context_end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:\n",
    "            idx -= 1\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "    inputs['start_positions'] = start_positions\n",
    "    inputs['end_positions'] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b72cf37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T20:13:01.692748300Z",
     "start_time": "2023-10-24T20:12:41.541247800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a240c814fd4a48228feaed870570c917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefe73ef2de6437b9e50aaa01773c9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14573 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbec157ab8444f8497b81e172042b300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14552 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = filtered_train_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_train_dataset.column_names,\n",
    ")\n",
    "tokenized_val_dataset = filtered_val_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_val_dataset.column_names,\n",
    ")\n",
    "tokenized_test_dataset = filtered_test_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_test_dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc093e38a8b9eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T19:29:26.213150400Z",
     "start_time": "2023-10-24T19:29:15.413453200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokenized train dataset entries have 384 tokens:  True\n",
      "All tokenized val dataset entries have 384 tokens:  True\n",
      "All tokenized test dataset entries have 384 tokens:  True\n"
     ]
    }
   ],
   "source": [
    "print(f'All tokenized train dataset entries have {max_length} tokens: ',\n",
    "      all([len(input_ids) == max_length for input_ids in tokenized_train_dataset['input_ids']]))\n",
    "print(f'All tokenized val dataset entries have {max_length} tokens: ',\n",
    "      all([len(input_ids) == max_length for input_ids in tokenized_val_dataset['input_ids']]))\n",
    "print(f'All tokenized test dataset entries have {max_length} tokens: ',\n",
    "      all([len(input_ids) == max_length for input_ids in tokenized_test_dataset['input_ids']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d5bedb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T19:43:42.416765300Z",
     "start_time": "2023-10-24T19:43:41.118521700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6038e6a163d17a8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T19:43:42.462607800Z",
     "start_time": "2023-10-24T19:43:42.417771600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a9266b102c3f216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T19:43:42.512279800Z",
     "start_time": "2023-10-24T19:43:42.435289400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = tokenized_train_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'token_type_ids', 'attention_mask'],\n",
    "    label_cols=['start_positions', 'end_positions'],\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "tf_val_dataset = tokenized_val_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'token_type_ids', 'attention_mask'],\n",
    "    label_cols=['start_positions', 'end_positions'],\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_test_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'token_type_ids', 'attention_mask'],\n",
    "    label_cols=['start_positions', 'end_positions'],\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcff7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "training_number = 1\n",
    "model_name = \"squad_bert\"\n",
    "batch_size = 8\n",
    "\n",
    "training_name = f\"training_{training_number}\"\n",
    "checkpoint_filename_template = \"cp-{epoch:04d}.ckpt\"\n",
    "# checkpoints_dir = os.path.join(constants.TRAINING_CHECKPOINTS_PATH, model_name, training_name)\n",
    "figures_dir = f\"./../documentation/models/{model_name}/figures\"\n",
    "# checkpoint_path = os.path.join(checkpoints_dir, checkpoint_filename_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10641c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only=True)\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "callbacks = [checkpoint_cb, early_stop_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4ec7915adf3b24c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T19:44:12.090638500Z",
     "start_time": "2023-10-24T19:44:12.053431100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "num_train_epochs = 10\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "lr_scheduler = PolynomialDecay(\n",
    "    initial_learning_rate=2e-5, end_learning_rate=0.0, decay_steps=num_train_steps, num_warmup_steps=0, weight_decay_rate=0.01\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ed3bc04bffb6bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T18:33:36.847962500Z",
     "start_time": "2023-10-22T18:33:36.809822400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108891648 \n",
      "                                                                 \n",
      " qa_outputs (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,893,186\n",
      "Trainable params: 108,893,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [\"accuracy\"]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "943d016bd9af345c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T19:44:28.176416500Z",
     "start_time": "2023-10-24T19:44:12.925479700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8496/8496 [==============================] - 2203s 257ms/step - loss: 1.3071 - val_loss: 0.9779\n",
      "Epoch 2/3\n",
      "8496/8496 [==============================] - 2163s 255ms/step - loss: 0.7649 - val_loss: 0.9746\n",
      "Epoch 3/3\n",
      "8496/8496 [==============================] - 2153s 253ms/step - loss: 0.5206 - val_loss: 1.0521\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tf_train_dataset, validation_data=tf_val_dataset, epochs=num_train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e3d2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name, training_number, saved_models_dir, default_model_version):\n",
    "    saved_model_name = f\"{model_name}_{training_number}\"\n",
    "    model.save(os.path.join(saved_models_dir, saved_model_name, default_model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac46ace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as serving, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses while saving (showing 5 of 417). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./../trained_models\\squad_bert_1\\1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./../trained_models\\squad_bert_1\\1\\assets\n"
     ]
    }
   ],
   "source": [
    "save_model(model, model_name, training_number, saved_models_dir='./../trained_models', default_model_version='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75bb7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = tf.keras.models.load_model('./../trained_models/squad_bert_1/1/', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a08a496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108891648 \n",
      "                                                                 \n",
      " qa_outputs (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,893,186\n",
      "Trainable params: 108,893,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c85529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc068cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.plot_and_save_fig_from_history(history,\n",
    "                                           attributes=['accuracy', 'val_accuracy'],\n",
    "                                           title='Model accuracy',\n",
    "                                           y_label='Accuracy',\n",
    "                                           x_label='Epoch',\n",
    "                                           legend_descriptors=['Train', 'Val'],\n",
    "                                           figure_dir_path=figures_dir,\n",
    "                                           figure_filename=f\"{training_name}_accuracy.png\")\n",
    "\n",
    "model_utils.plot_and_save_fig_from_history(history,\n",
    "                                           attributes=['loss', 'val_loss'],\n",
    "                                           title='Model loss',\n",
    "                                           y_label='Loss',\n",
    "                                           x_label='Epoch',\n",
    "                                           legend_descriptors=['Train', 'Val'],\n",
    "                                           figure_dir_path=figures_dir,\n",
    "                                           figure_filename=f\"{training_name}_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d903b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_utils.get_best_model_from_checkpoints(model, history,\n",
    "                                                         checkpoints_dir=checkpoints_dir,\n",
    "                                                         checkpoint_filename_template=checkpoint_filename_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.save_model(best_model, model_name=model_name, training_number=training_number, saved_models_dir=constants.SAVED_MODEL_LOCATION, default_model_version=constants.DEFAULT_MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "best_model.evaluate(tf_test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = model_utils.get_class_preds(model, tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86334f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1 = model_utils.get_classification_evaluation_metrics(\n",
    "    class_actual=tokenized_test_dataset['emotions'],\n",
    "    class_preds=class_preds,\n",
    "    average='micro'\n",
    ")\n",
    "\n",
    "print(f\"Precision score: \", precision)\n",
    "print(f\"Recall score: \", recall)\n",
    "print(f\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.print_incorrectly_predicted_texts(texts=raw_dataset['text_pl'],\n",
    "                                              class_actual=raw_dataset['emotions'],\n",
    "                                              class_preds=class_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
