{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T18:41:11.118213700Z",
     "start_time": "2023-10-22T18:41:11.071877500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, DefaultDataCollator, create_optimizer\n",
    "import datasets\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7529904f21909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T17:57:37.227199700Z",
     "start_time": "2023-10-22T17:57:36.275971600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def load_train_val_test_datasets(dataset_path='./../data/datasets/squad'):\n",
    "#     train = pd.read_csv(f'{dataset_path}/train.csv').dropna()\n",
    "#     val = pd.read_csv(f'{dataset_path}/dev.csv').dropna()\n",
    "#     test = pd.read_csv(f'{dataset_path}/test.csv').dropna()\n",
    "#     return train, val, test\n",
    "\n",
    "\n",
    "# def convert_dataframes_to_datasets(dataframes: list):\n",
    "#     return tuple(\n",
    "#         [datasets.Dataset.from_pandas(dataframe, preserve_index=False) for dataframe in\n",
    "#          dataframes])\n",
    "\n",
    "\n",
    "# df_train, df_val, df_test = load_train_val_test_datasets()\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = convert_dataframes_to_datasets([df_train, df_val, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848c00fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/Artur/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d304af79854ec9b7be603470db8cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"squad\")\n",
    "train_dataset = raw_datasets['train']\n",
    "val_dataset = raw_datasets['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd82f21a8585dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T17:57:37.244478800Z",
     "start_time": "2023-10-22T17:57:37.228199Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "     num_rows: 87599\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "     num_rows: 10570\n",
       " }))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db291e0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T17:57:37.632104700Z",
     "start_time": "2023-10-22T17:57:37.244478800Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d177b07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T17:58:31.702548100Z",
     "start_time": "2023-10-22T17:57:37.635106100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a1fea660ff47cb9f343021cf69e221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
      "Loading cached processed dataset at C:\\Users\\Artur\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-7db0a997d2ba11fd.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens in tokenized train dataset:  882\n",
      "Max number of tokens in tokenized val dataset:  833\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sample(sample, max_tokens=None, padding=False):\n",
    "    question = sample['question'].strip()\n",
    "    context = sample['context'].strip()\n",
    "\n",
    "    return tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=max_tokens,\n",
    "        padding=padding\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_sample)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_sample)\n",
    "# tokenized_test_dataset = test_dataset.map(tokenize_sample)\n",
    "\n",
    "print('Max number of tokens in tokenized train dataset: ', len(max(tokenized_train_dataset['input_ids'], key=len)))\n",
    "print('Max number of tokens in tokenized val dataset: ', len(max(tokenized_val_dataset['input_ids'], key=len)))\n",
    "# print('Max number of tokens in tokenized test dataset: ', len(max(tokenized_test_dataset['input_ids'], key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "548ff75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c05295d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]},\n",
       " 'input_ids': [101,\n",
       "  1706,\n",
       "  2292,\n",
       "  1225,\n",
       "  1103,\n",
       "  6567,\n",
       "  2090,\n",
       "  9273,\n",
       "  2845,\n",
       "  1107,\n",
       "  8109,\n",
       "  1107,\n",
       "  10111,\n",
       "  20500,\n",
       "  1699,\n",
       "  136,\n",
       "  102,\n",
       "  22182,\n",
       "  1193,\n",
       "  117,\n",
       "  1103,\n",
       "  1278,\n",
       "  1144,\n",
       "  170,\n",
       "  2336,\n",
       "  1959,\n",
       "  119,\n",
       "  1335,\n",
       "  4184,\n",
       "  1103,\n",
       "  4304,\n",
       "  4334,\n",
       "  112,\n",
       "  188,\n",
       "  2284,\n",
       "  10945,\n",
       "  1110,\n",
       "  170,\n",
       "  5404,\n",
       "  5921,\n",
       "  1104,\n",
       "  1103,\n",
       "  6567,\n",
       "  2090,\n",
       "  119,\n",
       "  13301,\n",
       "  1107,\n",
       "  1524,\n",
       "  1104,\n",
       "  1103,\n",
       "  4304,\n",
       "  4334,\n",
       "  1105,\n",
       "  4749,\n",
       "  1122,\n",
       "  117,\n",
       "  1110,\n",
       "  170,\n",
       "  7335,\n",
       "  5921,\n",
       "  1104,\n",
       "  4028,\n",
       "  1114,\n",
       "  1739,\n",
       "  1146,\n",
       "  14089,\n",
       "  5591,\n",
       "  1114,\n",
       "  1103,\n",
       "  7051,\n",
       "  107,\n",
       "  159,\n",
       "  21462,\n",
       "  1566,\n",
       "  24930,\n",
       "  2508,\n",
       "  152,\n",
       "  1306,\n",
       "  3965,\n",
       "  107,\n",
       "  119,\n",
       "  5893,\n",
       "  1106,\n",
       "  1103,\n",
       "  4304,\n",
       "  4334,\n",
       "  1110,\n",
       "  1103,\n",
       "  19349,\n",
       "  1104,\n",
       "  1103,\n",
       "  11373,\n",
       "  4641,\n",
       "  119,\n",
       "  13301,\n",
       "  1481,\n",
       "  1103,\n",
       "  171,\n",
       "  17506,\n",
       "  9538,\n",
       "  1110,\n",
       "  1103,\n",
       "  144,\n",
       "  10595,\n",
       "  2430,\n",
       "  117,\n",
       "  170,\n",
       "  14789,\n",
       "  1282,\n",
       "  1104,\n",
       "  8070,\n",
       "  1105,\n",
       "  9284,\n",
       "  119,\n",
       "  1135,\n",
       "  1110,\n",
       "  170,\n",
       "  16498,\n",
       "  1104,\n",
       "  1103,\n",
       "  176,\n",
       "  10595,\n",
       "  2430,\n",
       "  1120,\n",
       "  10111,\n",
       "  20500,\n",
       "  117,\n",
       "  1699,\n",
       "  1187,\n",
       "  1103,\n",
       "  6567,\n",
       "  2090,\n",
       "  25153,\n",
       "  1193,\n",
       "  1691,\n",
       "  1106,\n",
       "  2216,\n",
       "  17666,\n",
       "  6397,\n",
       "  3786,\n",
       "  1573,\n",
       "  25422,\n",
       "  13149,\n",
       "  1107,\n",
       "  8109,\n",
       "  119,\n",
       "  1335,\n",
       "  1103,\n",
       "  1322,\n",
       "  1104,\n",
       "  1103,\n",
       "  1514,\n",
       "  2797,\n",
       "  113,\n",
       "  1105,\n",
       "  1107,\n",
       "  170,\n",
       "  2904,\n",
       "  1413,\n",
       "  1115,\n",
       "  8200,\n",
       "  1194,\n",
       "  124,\n",
       "  11739,\n",
       "  1105,\n",
       "  1103,\n",
       "  3487,\n",
       "  17917,\n",
       "  114,\n",
       "  117,\n",
       "  1110,\n",
       "  170,\n",
       "  3014,\n",
       "  117,\n",
       "  2030,\n",
       "  2576,\n",
       "  5921,\n",
       "  1104,\n",
       "  2090,\n",
       "  119,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e53325b1b3a28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T17:59:11.418791900Z",
     "start_time": "2023-10-22T17:58:31.676515800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object filter_samples_below_number_of_tokens.<locals>.<genexpr> at 0x00000232D68DA120> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "max_length = 384\n",
    "\n",
    "\n",
    "def filter_samples_below_number_of_tokens(dataset, max_tokens: int):\n",
    "    indices_to_remove = []\n",
    "\n",
    "    # Find indices of samples where number of tokens exceeds max number of tokens\n",
    "    for index, sample in enumerate(dataset):\n",
    "        tokenized_sample = tokenize_sample(sample)\n",
    "        if len(tokenized_sample['input_ids']) > max_tokens:\n",
    "            indices_to_remove.append(index)\n",
    "\n",
    "    # Keep only samples with number of tokens less or equal than max number of tokens\n",
    "    dataset_indices = range(len(dataset))\n",
    "    filtered_dataset = dataset.select(\n",
    "        index for index in dataset_indices if index not in set(indices_to_remove)\n",
    "    )\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "\n",
    "filtered_train_dataset = filter_samples_below_number_of_tokens(train_dataset, max_tokens=max_length)\n",
    "filtered_val_dataset = filter_samples_below_number_of_tokens(val_dataset, max_tokens=max_length)\n",
    "# filtered_test_dataset = filter_samples_below_number_of_tokens(test_dataset, max_tokens=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1aebcb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T17:59:11.434129300Z",
     "start_time": "2023-10-22T17:59:11.419793800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in tokenized train dataset before filtering:  87599\n",
      "Number of samples in tokenized val dataset before filtering:  10570\n",
      "\n",
      "---------------\n",
      "\n",
      "Number of samples in tokenized train dataset after filtering:  86512\n",
      "Number of samples in tokenized val dataset after filtering:  10353\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples in tokenized train dataset before filtering: ', len(train_dataset))\n",
    "print('Number of samples in tokenized val dataset before filtering: ', len(val_dataset))\n",
    "# print('Number of samples in tokenized test dataset before filtering: ', len(test_dataset))\n",
    "\n",
    "print('\\n---------------\\n')\n",
    "\n",
    "print('Number of samples in tokenized train dataset after filtering: ', len(filtered_train_dataset))\n",
    "print('Number of samples in tokenized val dataset after filtering: ', len(filtered_val_dataset))\n",
    "# print('Number of samples in tokenized test dataset after filtering: ', len(filtered_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb6cdd06c7a27f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:08:00.696127200Z",
     "start_time": "2023-10-22T19:07:02.299178600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Artur\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-8e6dd48790a0de3f.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af84cb601aa44edb80c41212d44e7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "    questions = [q.strip() for q in examples['question']]\n",
    "    contexts = [c.strip() for c in examples['context']]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length'\n",
    "    )\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "    answers = dataset['answers']\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for index, _ in enumerate(dataset):\n",
    "        start_char = answers[index]['answer_start'][0]\n",
    "        end_char = start_char + len(answers[index]['text'][0])\n",
    "\n",
    "        start_positions.append(start_char)\n",
    "        end_positions.append(end_char)\n",
    "\n",
    "    dataset = dataset.add_column('start_positions', start_positions)\n",
    "    dataset = dataset.add_column('end_positions', end_positions)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "tokenized_train_dataset = preprocess_dataset(filtered_train_dataset)\n",
    "tokenized_val_dataset = preprocess_dataset(filtered_val_dataset)\n",
    "# tokenized_test_dataset = preprocess_dataset(filtered_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3f288a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 86512\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40e036e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_dataset['answers'][0]['answer_start'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff10a8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fc093e38a8b9eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:08:11.588608600Z",
     "start_time": "2023-10-22T19:08:00.713638Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokenized train dataset entries have 384 tokens:  True\n",
      "All tokenized val dataset entries have 384 tokens:  True\n"
     ]
    }
   ],
   "source": [
    "print(f'All tokenized train dataset entries have {max_length} tokens: ',\n",
    "      all([len(input_ids) == max_length for input_ids in tokenized_train_dataset['input_ids']]))\n",
    "print(f'All tokenized val dataset entries have {max_length} tokens: ',\n",
    "      all([len(input_ids) == max_length for input_ids in tokenized_val_dataset['input_ids']]))\n",
    "# print(f'All tokenized test dataset entries have {max_length} tokens: ',\n",
    "      # all([len(input_ids) == max_length for input_ids in tokenized_test_dataset['input_ids']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d5bedb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:11:09.188838900Z",
     "start_time": "2023-10-22T19:11:08.245208300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6038e6a163d17a8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:11:09.201367800Z",
     "start_time": "2023-10-22T19:11:09.187333100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67fd75ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[515,\n",
       " 188,\n",
       " 279,\n",
       " 381,\n",
       " 92,\n",
       " 248,\n",
       " 441,\n",
       " 598,\n",
       " 126,\n",
       " 908,\n",
       " 119,\n",
       " 145,\n",
       " 234,\n",
       " 356,\n",
       " 675,\n",
       " 487,\n",
       " 46,\n",
       " 126,\n",
       " 271,\n",
       " 155,\n",
       " 496,\n",
       " 68,\n",
       " 155,\n",
       " 647,\n",
       " 358,\n",
       " 624,\n",
       " 1163,\n",
       " 92,\n",
       " 757,\n",
       " 4,\n",
       " 466,\n",
       " 303,\n",
       " 377,\n",
       " 360,\n",
       " 136,\n",
       " 145,\n",
       " 188,\n",
       " 344,\n",
       " 394,\n",
       " 109,\n",
       " 138,\n",
       " 213,\n",
       " 488,\n",
       " 618,\n",
       " 32,\n",
       " 362,\n",
       " 565,\n",
       " 155,\n",
       " 918,\n",
       " 0,\n",
       " 353,\n",
       " 406,\n",
       " 638,\n",
       " 85,\n",
       " 3,\n",
       " 136,\n",
       " 123,\n",
       " 222,\n",
       " 49,\n",
       " 0,\n",
       " 963,\n",
       " 1049,\n",
       " 1099,\n",
       " 86,\n",
       " 0,\n",
       " 68,\n",
       " 233,\n",
       " 4,\n",
       " 80,\n",
       " 118,\n",
       " 427,\n",
       " 753,\n",
       " 891,\n",
       " 71,\n",
       " 196,\n",
       " 1446,\n",
       " 1588,\n",
       " 49,\n",
       " 6,\n",
       " 136,\n",
       " 350,\n",
       " 32,\n",
       " 368,\n",
       " 73,\n",
       " 197,\n",
       " 331,\n",
       " 1237,\n",
       " 251,\n",
       " 702,\n",
       " 90,\n",
       " 228,\n",
       " 385,\n",
       " 862,\n",
       " 244,\n",
       " 595,\n",
       " 8,\n",
       " 66,\n",
       " 430,\n",
       " 117,\n",
       " 204,\n",
       " 354,\n",
       " 251,\n",
       " 274,\n",
       " 297,\n",
       " 571,\n",
       " 1193,\n",
       " 819,\n",
       " 842,\n",
       " 11,\n",
       " 11,\n",
       " 292,\n",
       " 321,\n",
       " 587,\n",
       " 428,\n",
       " 522,\n",
       " 720,\n",
       " 4,\n",
       " 575,\n",
       " 37,\n",
       " 181,\n",
       " 262,\n",
       " 82,\n",
       " 439,\n",
       " 82,\n",
       " 625,\n",
       " 921,\n",
       " 1199,\n",
       " 141,\n",
       " 64,\n",
       " 314,\n",
       " 403,\n",
       " 576,\n",
       " 191,\n",
       " 6,\n",
       " 68,\n",
       " 138,\n",
       " 488,\n",
       " 596,\n",
       " 162,\n",
       " 202,\n",
       " 349,\n",
       " 474,\n",
       " 730,\n",
       " 56,\n",
       " 73,\n",
       " 157,\n",
       " 284,\n",
       " 535,\n",
       " 120,\n",
       " 336,\n",
       " 398,\n",
       " 613,\n",
       " 1755,\n",
       " 142,\n",
       " 471,\n",
       " 596,\n",
       " 750,\n",
       " 198,\n",
       " 289,\n",
       " 535,\n",
       " 210,\n",
       " 0,\n",
       " 85,\n",
       " 122,\n",
       " 221,\n",
       " 424,\n",
       " 78,\n",
       " 60,\n",
       " 134,\n",
       " 242,\n",
       " 275,\n",
       " 4,\n",
       " 159,\n",
       " 179,\n",
       " 325,\n",
       " 624,\n",
       " 388,\n",
       " 405,\n",
       " 538,\n",
       " 654,\n",
       " 0,\n",
       " 162,\n",
       " 212,\n",
       " 478,\n",
       " 519,\n",
       " 4,\n",
       " 92,\n",
       " 220,\n",
       " 287,\n",
       " 327,\n",
       " 62,\n",
       " 149,\n",
       " 214,\n",
       " 372,\n",
       " 454,\n",
       " 140,\n",
       " 294,\n",
       " 494,\n",
       " 557,\n",
       " 887,\n",
       " 3,\n",
       " 34,\n",
       " 111,\n",
       " 290,\n",
       " 336,\n",
       " 51,\n",
       " 359,\n",
       " 495,\n",
       " 516,\n",
       " 453,\n",
       " 24,\n",
       " 40,\n",
       " 128,\n",
       " 440,\n",
       " 42,\n",
       " 169,\n",
       " 401,\n",
       " 249,\n",
       " 367,\n",
       " 82,\n",
       " 293,\n",
       " 889,\n",
       " 959,\n",
       " 384,\n",
       " 239,\n",
       " 382,\n",
       " 674,\n",
       " 1223,\n",
       " 1398,\n",
       " 50,\n",
       " 223,\n",
       " 392,\n",
       " 420,\n",
       " 657,\n",
       " 74,\n",
       " 142,\n",
       " 509,\n",
       " 715,\n",
       " 441,\n",
       " 0,\n",
       " 362,\n",
       " 457,\n",
       " 506,\n",
       " 562,\n",
       " 166,\n",
       " 245,\n",
       " 594,\n",
       " 480,\n",
       " 424,\n",
       " 222,\n",
       " 173,\n",
       " 149,\n",
       " 411,\n",
       " 677,\n",
       " 267,\n",
       " 344,\n",
       " 513,\n",
       " 410,\n",
       " 40,\n",
       " 185,\n",
       " 278,\n",
       " 384,\n",
       " 937,\n",
       " 1232,\n",
       " 269,\n",
       " 207,\n",
       " 526,\n",
       " 166,\n",
       " 276,\n",
       " 320,\n",
       " 505,\n",
       " 360,\n",
       " 166,\n",
       " 505,\n",
       " 64,\n",
       " 0,\n",
       " 276,\n",
       " 290,\n",
       " 505,\n",
       " 526,\n",
       " 590,\n",
       " 290,\n",
       " 505,\n",
       " 526,\n",
       " 207,\n",
       " 369,\n",
       " 565,\n",
       " 260,\n",
       " 586,\n",
       " 180,\n",
       " 406,\n",
       " 48,\n",
       " 95,\n",
       " 260,\n",
       " 369,\n",
       " 466,\n",
       " 104,\n",
       " 935,\n",
       " 985,\n",
       " 736,\n",
       " 985,\n",
       " 18,\n",
       " 970,\n",
       " 393,\n",
       " 445,\n",
       " 393,\n",
       " 552,\n",
       " 985,\n",
       " 303,\n",
       " 204,\n",
       " 330,\n",
       " 578,\n",
       " 152,\n",
       " 101,\n",
       " 255,\n",
       " 540,\n",
       " 152,\n",
       " 117,\n",
       " 255,\n",
       " 540,\n",
       " 578,\n",
       " 49,\n",
       " 165,\n",
       " 507,\n",
       " 148,\n",
       " 711,\n",
       " 484,\n",
       " 385,\n",
       " 49,\n",
       " 165,\n",
       " 355,\n",
       " 711,\n",
       " 303,\n",
       " 542,\n",
       " 918,\n",
       " 303,\n",
       " 537,\n",
       " 1264,\n",
       " 918,\n",
       " 3,\n",
       " 7,\n",
       " 192,\n",
       " 303,\n",
       " 537,\n",
       " 1126,\n",
       " 215,\n",
       " 848,\n",
       " 1212,\n",
       " 51,\n",
       " 85,\n",
       " 215,\n",
       " 849,\n",
       " 1212,\n",
       " 85,\n",
       " 215,\n",
       " 330,\n",
       " 688,\n",
       " 1212,\n",
       " 169,\n",
       " 320,\n",
       " 714,\n",
       " 194,\n",
       " 396,\n",
       " 714,\n",
       " 110,\n",
       " 149,\n",
       " 714,\n",
       " 110,\n",
       " 37,\n",
       " 216,\n",
       " 348,\n",
       " 793,\n",
       " 557,\n",
       " 593,\n",
       " 115,\n",
       " 378,\n",
       " 593,\n",
       " 628,\n",
       " 1070,\n",
       " 84,\n",
       " 331,\n",
       " 431,\n",
       " 705,\n",
       " 834,\n",
       " 115,\n",
       " 210,\n",
       " 416,\n",
       " 435,\n",
       " 545,\n",
       " 115,\n",
       " 58,\n",
       " 240,\n",
       " 431,\n",
       " 435,\n",
       " 123,\n",
       " 193,\n",
       " 419,\n",
       " 474,\n",
       " 130,\n",
       " 48,\n",
       " 193,\n",
       " 123,\n",
       " 1042,\n",
       " 48,\n",
       " 229,\n",
       " 474,\n",
       " 1042,\n",
       " 696,\n",
       " 513,\n",
       " 1212,\n",
       " 3,\n",
       " 664,\n",
       " 935,\n",
       " 1206,\n",
       " 38,\n",
       " 100,\n",
       " 253,\n",
       " 848,\n",
       " 132,\n",
       " 303,\n",
       " 346,\n",
       " 346,\n",
       " 101,\n",
       " 323,\n",
       " 342,\n",
       " 28,\n",
       " 132,\n",
       " 323,\n",
       " 635,\n",
       " 53,\n",
       " 171,\n",
       " 171,\n",
       " 550,\n",
       " 671,\n",
       " 112,\n",
       " 576,\n",
       " 932,\n",
       " 53,\n",
       " 436,\n",
       " 487,\n",
       " 576,\n",
       " 932,\n",
       " 69,\n",
       " 439,\n",
       " 582,\n",
       " 693,\n",
       " 1101,\n",
       " 439,\n",
       " 703,\n",
       " 724,\n",
       " 940,\n",
       " 69,\n",
       " 439,\n",
       " 594,\n",
       " 703,\n",
       " 51,\n",
       " 242,\n",
       " 352,\n",
       " 457,\n",
       " 517,\n",
       " 51,\n",
       " 372,\n",
       " 352,\n",
       " 517,\n",
       " 242,\n",
       " 51,\n",
       " 242,\n",
       " 352,\n",
       " 517,\n",
       " 60,\n",
       " 60,\n",
       " 300,\n",
       " 60,\n",
       " 74,\n",
       " 143,\n",
       " 244,\n",
       " 18,\n",
       " 74,\n",
       " 168,\n",
       " 244,\n",
       " 3,\n",
       " 367,\n",
       " 486,\n",
       " 313,\n",
       " 596,\n",
       " 9,\n",
       " 3,\n",
       " 313,\n",
       " 495,\n",
       " 137,\n",
       " 31,\n",
       " 367,\n",
       " 469,\n",
       " 51,\n",
       " 371,\n",
       " 617,\n",
       " 719,\n",
       " 42,\n",
       " 74,\n",
       " 640,\n",
       " 51,\n",
       " 24,\n",
       " 42,\n",
       " 74,\n",
       " 562,\n",
       " 719,\n",
       " 3,\n",
       " 91,\n",
       " 71,\n",
       " 176,\n",
       " 3,\n",
       " 71,\n",
       " 124,\n",
       " 161,\n",
       " 3,\n",
       " 71,\n",
       " 91,\n",
       " 176,\n",
       " 161,\n",
       " 81,\n",
       " 689,\n",
       " 1163,\n",
       " 3,\n",
       " 158,\n",
       " 258,\n",
       " 523,\n",
       " 3,\n",
       " 158,\n",
       " 186,\n",
       " 362,\n",
       " 689,\n",
       " 103,\n",
       " 20,\n",
       " 560,\n",
       " 469,\n",
       " 55,\n",
       " 399,\n",
       " 429,\n",
       " 560,\n",
       " 20,\n",
       " 103,\n",
       " 288,\n",
       " 404,\n",
       " 429,\n",
       " 88,\n",
       " 3,\n",
       " 88,\n",
       " 810,\n",
       " 1344,\n",
       " 1471,\n",
       " 3,\n",
       " 440,\n",
       " 784,\n",
       " 974,\n",
       " 108,\n",
       " 283,\n",
       " 364,\n",
       " 770,\n",
       " 108,\n",
       " 283,\n",
       " 770,\n",
       " 77,\n",
       " 364,\n",
       " 770,\n",
       " 770,\n",
       " 77,\n",
       " 108,\n",
       " 283,\n",
       " 364,\n",
       " 770,\n",
       " 140,\n",
       " 154,\n",
       " 3,\n",
       " 101,\n",
       " 140,\n",
       " 116,\n",
       " 3,\n",
       " 140,\n",
       " 447,\n",
       " 825,\n",
       " 617,\n",
       " 62,\n",
       " 332,\n",
       " 447,\n",
       " 736,\n",
       " 825,\n",
       " 94,\n",
       " 332,\n",
       " 447,\n",
       " 617,\n",
       " 912,\n",
       " 40,\n",
       " 360,\n",
       " 535,\n",
       " 35,\n",
       " 417,\n",
       " 616,\n",
       " 719,\n",
       " 92,\n",
       " 35,\n",
       " 92,\n",
       " 535,\n",
       " 719,\n",
       " 216,\n",
       " 160,\n",
       " 54,\n",
       " 74,\n",
       " 160,\n",
       " 54,\n",
       " 457,\n",
       " 3,\n",
       " 54,\n",
       " 160,\n",
       " 367,\n",
       " 457,\n",
       " 880,\n",
       " 112,\n",
       " 398,\n",
       " 700,\n",
       " 840,\n",
       " 112,\n",
       " 112,\n",
       " 186,\n",
       " 458,\n",
       " 700,\n",
       " 29,\n",
       " 514,\n",
       " 29,\n",
       " 38,\n",
       " 514,\n",
       " 445,\n",
       " 586,\n",
       " 365,\n",
       " 514,\n",
       " 44,\n",
       " 374,\n",
       " 191,\n",
       " 313,\n",
       " 3,\n",
       " 125,\n",
       " 218,\n",
       " 374,\n",
       " 44,\n",
       " 125,\n",
       " 214,\n",
       " 191,\n",
       " 23,\n",
       " 132,\n",
       " 23,\n",
       " 186,\n",
       " 28,\n",
       " 42,\n",
       " 415,\n",
       " 546,\n",
       " 28,\n",
       " 453,\n",
       " 714,\n",
       " 883,\n",
       " 28,\n",
       " 333,\n",
       " 630,\n",
       " 710,\n",
       " 29,\n",
       " 60,\n",
       " 307,\n",
       " 417,\n",
       " 516,\n",
       " 29,\n",
       " 267,\n",
       " 307,\n",
       " 369,\n",
       " 29,\n",
       " 307,\n",
       " 516,\n",
       " 431,\n",
       " 521,\n",
       " 338,\n",
       " 153,\n",
       " 309,\n",
       " 376,\n",
       " 564,\n",
       " 210,\n",
       " 376,\n",
       " 564,\n",
       " 205,\n",
       " 132,\n",
       " 436,\n",
       " 656,\n",
       " 3,\n",
       " 221,\n",
       " 587,\n",
       " 221,\n",
       " 92,\n",
       " 128,\n",
       " 260,\n",
       " 631,\n",
       " 14,\n",
       " 67,\n",
       " 14,\n",
       " 589,\n",
       " 14,\n",
       " 534,\n",
       " 14,\n",
       " 14,\n",
       " 358,\n",
       " 404,\n",
       " 534,\n",
       " 4,\n",
       " 134,\n",
       " 399,\n",
       " 109,\n",
       " 418,\n",
       " 211,\n",
       " 134,\n",
       " 195,\n",
       " 68,\n",
       " 588,\n",
       " 144,\n",
       " 68,\n",
       " 196,\n",
       " 567,\n",
       " 642,\n",
       " 251,\n",
       " 57,\n",
       " 144,\n",
       " 431,\n",
       " 621,\n",
       " 53,\n",
       " 216,\n",
       " 238,\n",
       " 3,\n",
       " 53,\n",
       " 53,\n",
       " 347,\n",
       " 53,\n",
       " 53,\n",
       " 91,\n",
       " 216,\n",
       " 343,\n",
       " 36,\n",
       " 445,\n",
       " 36,\n",
       " 87,\n",
       " 484,\n",
       " 393,\n",
       " 87,\n",
       " 445,\n",
       " 139,\n",
       " 378,\n",
       " 501,\n",
       " 712,\n",
       " 243,\n",
       " 679,\n",
       " 475,\n",
       " 456,\n",
       " 389,\n",
       " 542,\n",
       " 41,\n",
       " 88,\n",
       " 389,\n",
       " 497,\n",
       " 389,\n",
       " 389,\n",
       " 543,\n",
       " 88,\n",
       " 389,\n",
       " 543,\n",
       " 242,\n",
       " 43,\n",
       " 62,\n",
       " 154,\n",
       " 228,\n",
       " 339,\n",
       " 154,\n",
       " 208,\n",
       " 236,\n",
       " 357,\n",
       " 13,\n",
       " 154,\n",
       " 170,\n",
       " 443,\n",
       " 134,\n",
       " 535,\n",
       " 188,\n",
       " 404,\n",
       " 535,\n",
       " 535,\n",
       " 551,\n",
       " 0,\n",
       " 83,\n",
       " 321,\n",
       " 4,\n",
       " 87,\n",
       " 4,\n",
       " 87,\n",
       " 184,\n",
       " 158,\n",
       " 237,\n",
       " 252,\n",
       " 3,\n",
       " 111,\n",
       " 237,\n",
       " 249,\n",
       " 237,\n",
       " 158,\n",
       " 213,\n",
       " 80,\n",
       " 108,\n",
       " 335,\n",
       " 615,\n",
       " 436,\n",
       " 33,\n",
       " 108,\n",
       " 335,\n",
       " 386,\n",
       " 505,\n",
       " 215,\n",
       " 700,\n",
       " 1078,\n",
       " 238,\n",
       " 700,\n",
       " 1078,\n",
       " 738,\n",
       " 31,\n",
       " 215,\n",
       " 723,\n",
       " 738,\n",
       " 1078,\n",
       " 292,\n",
       " 385,\n",
       " 562,\n",
       " 552,\n",
       " 292,\n",
       " 10,\n",
       " 501,\n",
       " 292,\n",
       " 358,\n",
       " 385,\n",
       " 501,\n",
       " 517,\n",
       " 19,\n",
       " 225,\n",
       " 304,\n",
       " 959,\n",
       " 1073,\n",
       " 19,\n",
       " 218,\n",
       " 297,\n",
       " 702,\n",
       " 155,\n",
       " 702,\n",
       " 940,\n",
       " 73,\n",
       " 111,\n",
       " 387,\n",
       " 152,\n",
       " 0,\n",
       " 73,\n",
       " 111,\n",
       " 152,\n",
       " 1052,\n",
       " 387,\n",
       " 68,\n",
       " 106,\n",
       " 261,\n",
       " 387,\n",
       " 1048,\n",
       " 16,\n",
       " 159,\n",
       " 231,\n",
       " 586,\n",
       " 949,\n",
       " 16,\n",
       " 231,\n",
       " 306,\n",
       " 705,\n",
       " 16,\n",
       " 231,\n",
       " 247,\n",
       " 756,\n",
       " 24,\n",
       " 172,\n",
       " 206,\n",
       " 535,\n",
       " 36,\n",
       " 101,\n",
       " 191,\n",
       " 210,\n",
       " 24,\n",
       " 171,\n",
       " 206,\n",
       " 437,\n",
       " 24,\n",
       " 0,\n",
       " 247,\n",
       " 577,\n",
       " 750,\n",
       " 247,\n",
       " 452,\n",
       " 535,\n",
       " 654,\n",
       " 172,\n",
       " 255,\n",
       " 247,\n",
       " 654,\n",
       " 450,\n",
       " 28,\n",
       " 433,\n",
       " 168,\n",
       " 236,\n",
       " 28,\n",
       " 28,\n",
       " 109,\n",
       " 168,\n",
       " 267,\n",
       " 136,\n",
       " 209,\n",
       " 299,\n",
       " 698,\n",
       " 153,\n",
       " 706,\n",
       " 75,\n",
       " 153,\n",
       " 123,\n",
       " 299,\n",
       " 3,\n",
       " 230,\n",
       " 3,\n",
       " 105,\n",
       " 763,\n",
       " 129,\n",
       " 274,\n",
       " 230,\n",
       " 717,\n",
       " 12,\n",
       " 218,\n",
       " 408,\n",
       " 670,\n",
       " 834,\n",
       " 12,\n",
       " 91,\n",
       " 205,\n",
       " 572,\n",
       " 12,\n",
       " 526,\n",
       " 51,\n",
       " 741,\n",
       " 294,\n",
       " 258,\n",
       " 360,\n",
       " 638,\n",
       " 32,\n",
       " 159,\n",
       " 360,\n",
       " 690,\n",
       " 570,\n",
       " 110,\n",
       " 250,\n",
       " 147,\n",
       " 126,\n",
       " 287,\n",
       " 110,\n",
       " 147,\n",
       " 52,\n",
       " 6,\n",
       " 191,\n",
       " 321,\n",
       " 61,\n",
       " 190,\n",
       " 225,\n",
       " 65,\n",
       " 190,\n",
       " 311,\n",
       " 24,\n",
       " 356,\n",
       " 781,\n",
       " 253,\n",
       " 322,\n",
       " 849,\n",
       " 57,\n",
       " 24,\n",
       " 322,\n",
       " 781,\n",
       " 280,\n",
       " 412,\n",
       " 1553,\n",
       " 765,\n",
       " 280,\n",
       " 616,\n",
       " 1409,\n",
       " 108,\n",
       " 280,\n",
       " 412,\n",
       " 533,\n",
       " 112,\n",
       " 370,\n",
       " 387,\n",
       " 590,\n",
       " 103,\n",
       " 240,\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset['start_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "301cc9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 86512\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8b3f8196695ff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:11:09.371618800Z",
     "start_time": "2023-10-22T19:11:09.257661100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_train_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    ")\n",
    "tf_val_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_val_dataset,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b3fd7819ecf5aa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:11:10.718737Z",
     "start_time": "2023-10-22T19:11:10.693627900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(8, 384), dtype=tf.int64, name=None), 'token_type_ids': TensorSpec(shape=(8, 384), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(8, 384), dtype=tf.int64, name=None)}, {'start_positions': TensorSpec(shape=(8,), dtype=tf.int64, name=None), 'end_positions': TensorSpec(shape=(8,), dtype=tf.int64, name=None)})>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20ce86d0e18bd573",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# <_PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(16, 384), dtype=tf.int64, name=None), 'token_type_ids': TensorSpec(shape=(16, 384), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 384), dtype=tf.int64, name=None)}, {'start_positions': TensorSpec(shape=(16,), dtype=tf.int64, name=None), 'end_positions': TensorSpec(shape=(16,), dtype=tf.int64, name=None)})>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9266b102c3f216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:05:15.749790200Z",
     "start_time": "2023-10-22T19:05:15.666693500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf_train_dataset = tokenized_train_dataset.to_tf_dataset(\n",
    "#     columns=['input_ids', 'token_type_ids', 'attention_mask'],\n",
    "#     label_cols=['start_positions', 'end_positions'],\n",
    "#     batch_size=8,\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "# tf_val_dataset = tokenized_val_dataset.to_tf_dataset(\n",
    "#     columns=['input_ids', 'token_type_ids', 'attention_mask'],\n",
    "#     label_cols=['start_positions', 'end_positions'],\n",
    "#     batch_size=8,\n",
    "#     shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e85759555d014d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:05:21.415558300Z",
     "start_time": "2023-10-22T19:05:21.362024100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 384), dtype=tf.int64, name=None), 'token_type_ids': TensorSpec(shape=(None, 384), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, 384), dtype=tf.int64, name=None)}, {'start_positions': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'end_positions': TensorSpec(shape=(None,), dtype=tf.int64, name=None)})>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4ec7915adf3b24c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:11:14.571682100Z",
     "start_time": "2023-10-22T19:11:14.551558800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "num_train_epochs = 3\n",
    "num_train_steps = len(tf_train_dataset) * num_train_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3169885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"question\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71609d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"context\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2ac9490f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = tokenizer(train_dataset[\"question\"][0], train_dataset[\"context\"][0], return_tensors=\"tf\")\n",
    "output = model(**input_test)\n",
    "\n",
    "answer_start_index = int(tf.math.argmax(output.start_logits, axis=-1)[0])\n",
    "answer_end_index = int(tf.math.argmax(output.end_logits, axis=-1)[0])\n",
    "\n",
    "predict_answer_tokens = input_test.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d0319c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test = question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
    "\n",
    "input_test = tokenizer(question, text, return_tensors=\"tf\")\n",
    "output = model(**input_test)\n",
    "\n",
    "answer_start_index = int(tf.math.argmax(output.start_logits, axis=-1)[0])\n",
    "answer_end_index = int(tf.math.argmax(output.end_logits, axis=-1)[0])\n",
    "\n",
    "predict_answer_tokens = input_test.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "tokenizer.decode(predict_answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "751915ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 16), dtype=int32, numpy=\n",
       "array([[  101,  2627,  1108,  3104,  1124, 15703,   136,   102,  3104,\n",
       "         1124, 15703,  1108,   170,  3505, 16797,   102]])>, 'token_type_ids': <tf.Tensor: shape=(1, 16), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]])>, 'attention_mask': <tf.Tensor: shape=(1, 16), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "857e57fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFQuestionAnsweringModelOutput(loss=None, start_logits=<tf.Tensor: shape=(1, 16), dtype=float16, numpy=\n",
       "array([[-0.3826 , -0.02153, -0.414  , -0.1685 ,  0.11456, -0.08124,\n",
       "         0.0786 , -0.5254 , -0.00936,  0.328  ,  0.1414 , -0.273  ,\n",
       "        -0.1273 , -0.1489 , -0.2788 , -0.5254 ]], dtype=float16)>, end_logits=<tf.Tensor: shape=(1, 16), dtype=float16, numpy=\n",
       "array([[ 0.7124 , -0.0422 , -0.367  , -0.1194 ,  0.09766, -0.01522,\n",
       "         0.1018 , -0.2605 , -0.09937, -0.1198 , -0.2312 , -0.1819 ,\n",
       "        -0.3196 , -0.1366 ,  0.06235, -0.2605 ]], dtype=float16)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "834832c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'categorical_crossentropy'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "082a376d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.bert.modeling_tf_bert.TFBertForQuestionAnswering at 0x1e93d01b460>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "943d016bd9af345c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T19:11:32.995478700Z",
     "start_time": "2023-10-22T19:11:15.542622600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  278/10814 [..............................] - ETA: 38:39 - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\STUDIA\\IPS\\question-answering\\medical-qa\\notebooks\\squad_bert copy.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/STUDIA/IPS/question-answering/medical-qa/notebooks/squad_bert%20copy.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(tf_train_dataset, validation_data\u001b[39m=\u001b[39;49mtf_val_dataset, epochs\u001b[39m=\u001b[39;49mnum_train_epochs)\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(tf_train_dataset, validation_data=tf_val_dataset, epochs=num_train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46ed3bc04bffb6bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T18:33:36.847962500Z",
     "start_time": "2023-10-22T18:33:36.809822400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108891648 \n",
      "_________________________________________________________________\n",
      "qa_outputs (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 108,893,186\n",
      "Trainable params: 108,893,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722438ab47c3a76b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
