{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model trained on contaxts being original_code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T17:43:01.672130100Z",
     "start_time": "2023-11-06T17:42:50.404300500Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForQuestionAnswering,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    keras_callbacks,\n",
    "    TFAutoModelForSeq2SeqLM,\n",
    "    TFEncoderDecoderModel,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import notebook_login\n",
    "from question_answering.constants import constants\n",
    "from question_answering.utils import core_qa_utils, generative_qa_utils\n",
    "from question_answering.paths import generative_qa_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = core_qa_utils.load_train_val_test_datasets(\n",
    "    generative_qa_paths.python_dataset_dir\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = core_qa_utils.convert_dataframes_to_datasets(\n",
    "    [df_train, df_val, df_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>code</th>\n",
       "      <th>original_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What does the code make ?</td>\n",
       "      <td>a suite</td>\n",
       "      <td>def Make Suite From Dict d label None suite Su...</td>\n",
       "      <td>def MakeSuiteFromDict d label None suite Suite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Does the code make a suite ?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>def Make Suite From Dict d label None suite Su...</td>\n",
       "      <td>def MakeSuiteFromDict d label None suite Suite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Does the code receive a message from a pull su...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>def receive message topic name subscription na...</td>\n",
       "      <td>def receive_message topic_name subscription_na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What does the code receive from a pull subscri...</td>\n",
       "      <td>a message</td>\n",
       "      <td>def receive message topic name subscription na...</td>\n",
       "      <td>def receive_message topic_name subscription_na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What be an explicit budget used only ?</td>\n",
       "      <td>to create the campaign</td>\n",
       "      <td>def Create Shared Budget client budget service...</td>\n",
       "      <td>def CreateSharedBudget client budget_service c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56080</th>\n",
       "      <td>56080</td>\n",
       "      <td>What compiles the file filename ?</td>\n",
       "      <td>bytecode</td>\n",
       "      <td>def save pyc filename cfile '%sc' % filename p...</td>\n",
       "      <td>def save_pyc filename cfile '%sc' % filename p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56081</th>\n",
       "      <td>56081</td>\n",
       "      <td>What will this function spawn ?</td>\n",
       "      <td>a thread</td>\n",
       "      <td>def with timeout func args kwargs {} class Res...</td>\n",
       "      <td>def with_timeout func args kwargs {} class Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56082</th>\n",
       "      <td>56082</td>\n",
       "      <td>What do this function run using the args ?</td>\n",
       "      <td>the given function</td>\n",
       "      <td>def with timeout func args kwargs {} class Res...</td>\n",
       "      <td>def with_timeout func args kwargs {} class Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56083</th>\n",
       "      <td>56083</td>\n",
       "      <td>How do this function run the given function ?</td>\n",
       "      <td>using the args</td>\n",
       "      <td>def with timeout func args kwargs {} class Res...</td>\n",
       "      <td>def with_timeout func args kwargs {} class Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56084</th>\n",
       "      <td>56084</td>\n",
       "      <td>What does the code get from the filename or th...</td>\n",
       "      <td>the file</td>\n",
       "      <td>def get Alteration File file Name settings Alt...</td>\n",
       "      <td>def getAlterationFile fileName settingsAlterat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56080 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                          questions  \\\n",
       "0          0                          What does the code make ?   \n",
       "1          1                       Does the code make a suite ?   \n",
       "2          2  Does the code receive a message from a pull su...   \n",
       "3          3  What does the code receive from a pull subscri...   \n",
       "4          4             What be an explicit budget used only ?   \n",
       "...      ...                                                ...   \n",
       "56080  56080                  What compiles the file filename ?   \n",
       "56081  56081                    What will this function spawn ?   \n",
       "56082  56082         What do this function run using the args ?   \n",
       "56083  56083      How do this function run the given function ?   \n",
       "56084  56084  What does the code get from the filename or th...   \n",
       "\n",
       "                      answers  \\\n",
       "0                     a suite   \n",
       "1                         Yes   \n",
       "2                         Yes   \n",
       "3                   a message   \n",
       "4      to create the campaign   \n",
       "...                       ...   \n",
       "56080                bytecode   \n",
       "56081                a thread   \n",
       "56082      the given function   \n",
       "56083          using the args   \n",
       "56084                the file   \n",
       "\n",
       "                                                    code  \\\n",
       "0      def Make Suite From Dict d label None suite Su...   \n",
       "1      def Make Suite From Dict d label None suite Su...   \n",
       "2      def receive message topic name subscription na...   \n",
       "3      def receive message topic name subscription na...   \n",
       "4      def Create Shared Budget client budget service...   \n",
       "...                                                  ...   \n",
       "56080  def save pyc filename cfile '%sc' % filename p...   \n",
       "56081  def with timeout func args kwargs {} class Res...   \n",
       "56082  def with timeout func args kwargs {} class Res...   \n",
       "56083  def with timeout func args kwargs {} class Res...   \n",
       "56084  def get Alteration File file Name settings Alt...   \n",
       "\n",
       "                                           original_code  \n",
       "0      def MakeSuiteFromDict d label None suite Suite...  \n",
       "1      def MakeSuiteFromDict d label None suite Suite...  \n",
       "2      def receive_message topic_name subscription_na...  \n",
       "3      def receive_message topic_name subscription_na...  \n",
       "4      def CreateSharedBudget client budget_service c...  \n",
       "...                                                  ...  \n",
       "56080  def save_pyc filename cfile '%sc' % filename p...  \n",
       "56081  def with_timeout func args kwargs {} class Res...  \n",
       "56082  def with_timeout func args kwargs {} class Res...  \n",
       "56083  def with_timeout func args kwargs {} class Res...  \n",
       "56084  def getAlterationFile fileName settingsAlterat...  \n",
       "\n",
       "[56080 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint = \"t5-small\"\n",
    "model_checkpoint = \"facebook/bart-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a7a4fd34eb4ca7bc32051283cc6de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460c7802502e4f109e3b0217e900b5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009a9f76e6c7456eafb66205831cdd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens in tokenized train dataset:  9244\n",
      "Max number of tokens in tokenized val dataset:  575\n",
      "Max number of tokens in tokenized test dataset:  901\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sample(sample, max_tokens=None, padding=False):\n",
    "    question = sample[\"questions\"].strip()\n",
    "    context = sample[\"original_code\"].strip()\n",
    "\n",
    "    question_context = context + ' - ' + question\n",
    "\n",
    "    return tokenizer(question, context, max_length=max_tokens, padding=padding)\n",
    "    # return tokenizer(question_context, max_length=max_tokens, padding=padding)\n",
    "\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_sample)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_sample)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_sample)\n",
    "\n",
    "print(\n",
    "    \"Max number of tokens in tokenized train dataset: \",\n",
    "    len(max(tokenized_train_dataset[\"input_ids\"], key=len)),\n",
    ")\n",
    "print(\n",
    "    \"Max number of tokens in tokenized val dataset: \",\n",
    "    len(max(tokenized_val_dataset[\"input_ids\"], key=len)),\n",
    ")\n",
    "print(\n",
    "    \"Max number of tokens in tokenized test dataset: \",\n",
    "    len(max(tokenized_test_dataset[\"input_ids\"], key=len)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object filter_samples_below_number_of_tokens.<locals>.<genexpr> at 0x000001B6D228B610> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "max_length = 256\n",
    "\n",
    "\n",
    "def filter_samples_below_number_of_tokens(dataset, max_tokens: int):\n",
    "    indices_to_remove = []\n",
    "\n",
    "    # Find indices of samples where number of tokens exceeds max number of tokens\n",
    "    for index, sample in enumerate(dataset):\n",
    "        tokenized_sample = tokenize_sample(sample)\n",
    "        if len(tokenized_sample[\"input_ids\"]) > max_tokens:\n",
    "            indices_to_remove.append(index)\n",
    "\n",
    "    # Keep only samples with number of tokens less or equal than max number of tokens\n",
    "    dataset_indices = range(len(dataset))\n",
    "    filtered_dataset = dataset.select(\n",
    "        index for index in dataset_indices if index not in set(indices_to_remove)\n",
    "    )\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "\n",
    "filtered_train_dataset = filter_samples_below_number_of_tokens(\n",
    "    train_dataset, max_tokens=max_length\n",
    ")\n",
    "filtered_val_dataset = filter_samples_below_number_of_tokens(\n",
    "    val_dataset, max_tokens=max_length\n",
    ")\n",
    "filtered_test_dataset = filter_samples_below_number_of_tokens(\n",
    "    test_dataset, max_tokens=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in tokenized train dataset before filtering:  56080\n",
      "Number of samples in tokenized val dataset before filtering:  7000\n",
      "Number of samples in tokenized test dataset before filtering:  7000\n",
      "\n",
      "---------------\n",
      "\n",
      "Number of samples in tokenized train dataset after filtering:  54930\n",
      "Number of samples in tokenized val dataset after filtering:  6828\n",
      "Number of samples in tokenized test dataset after filtering:  6854\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of samples in tokenized train dataset before filtering: \",\n",
    "    len(train_dataset),\n",
    ")\n",
    "print(\"Number of samples in tokenized val dataset before filtering: \", len(val_dataset))\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset before filtering: \", len(test_dataset)\n",
    ")\n",
    "\n",
    "print(\"\\n---------------\\n\")\n",
    "\n",
    "print(\n",
    "    \"Number of samples in tokenized train dataset after filtering: \",\n",
    "    len(filtered_train_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized val dataset after filtering: \",\n",
    "    len(filtered_val_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset after filtering: \",\n",
    "    len(filtered_test_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_question_and_context(dataset_row):\n",
    "#     context_question = dataset_row['original_code'] + ' - ' + dataset_row['questions']\n",
    "#     dataset_row['context_question'] = context_question\n",
    "#     return dataset_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_train_dataset = filtered_train_dataset.map(combine_question_and_context)\n",
    "# filtered_val_dataset = filtered_val_dataset.map(combine_question_and_context)\n",
    "# filtered_test_dataset = filtered_test_dataset.map(combine_question_and_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_train_dataset['context_question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    questions = [q.strip() for q in dataset[\"questions\"]]\n",
    "    contexts = [c.strip() for c in dataset[\"original_code\"]]\n",
    "    answers = [c.strip() for c in dataset[\"answers\"]]\n",
    "\n",
    "    # question_context = [cq.strip() for cq in dataset[\"context_question\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        # question_context,\n",
    "        text_target=answers,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd4474c6a9640218565ed5379232722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54930 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe08e24e8c947d3b33b7528194d1c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6828 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dde1326a44643d5adabf89ebc12c4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6854 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = filtered_train_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_train_dataset.column_names,\n",
    ")\n",
    "tokenized_val_dataset = filtered_val_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_val_dataset.column_names,\n",
    ")\n",
    "tokenized_test_dataset = filtered_test_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_test_dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokenized train dataset entries have 256 tokens:  True\n",
      "All tokenized val dataset entries have 256 tokens:  True\n",
      "All tokenized test dataset entries have 256 tokens:  True\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"All tokenized train dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_train_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    f\"All tokenized val dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_val_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    f\"All tokenized test dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_test_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "training_number = 5\n",
    "\n",
    "model_name = \"python-bart-uncased\"\n",
    "full_model_name = f\"{model_name}-{training_number}\"\n",
    "\n",
    "# Checkpoints\n",
    "checkpoint_filename_template = constants.checkpoint_filename_template\n",
    "checkpoints_path = (\n",
    "    generative_qa_paths.training_checkpoints_dir\n",
    "    / full_model_name\n",
    "    / checkpoint_filename_template\n",
    ")\n",
    "\n",
    "# Hub\n",
    "hub_path = generative_qa_paths.hub_models_location / full_model_name\n",
    "\n",
    "# Saved models\n",
    "saved_models_path = generative_qa_paths.saved_models_dir / full_model_name\n",
    "\n",
    "# Figures\n",
    "figures_dir = generative_qa_paths.figures_dir / full_model_name\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "train_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForConditionalGeneration: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "- This IS expected if you are initializing TFBartForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load model for fine-tuning\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# Dataset preparation\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = core_qa_utils.prepare_tf_dataset(\n",
    "    model=model,\n",
    "    hf_dataset=tokenized_train_dataset,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "tf_val_dataset = core_qa_utils.prepare_tf_dataset(\n",
    "    model=model,\n",
    "    hf_dataset=tokenized_val_dataset,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "tf_test_dataset = core_qa_utils.prepare_tf_dataset(\n",
    "    model=model,\n",
    "    hf_dataset=tokenized_test_dataset,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoints_path, verbose=1, save_weights_only=True\n",
    ")\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "# push_to_hub = keras_callbacks.PushToHubCallback(\n",
    "#     output_dir=full_model_name, tokenizer=tokenizer\n",
    "# )\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint_cb,\n",
    "    early_stop_cb,\n",
    "    # push_to_hub\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "num_train_steps = len(tf_train_dataset) * train_epochs\n",
    "\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# Compile\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# metrics = [\"accuracy\"]\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "# model.compile(optimizer=optimizer, metrics=metrics)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bart_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFBartMainLayer)     multiple                  139420416 \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 50265     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,470,681\n",
      "Trainable params: 139,420,416\n",
      "Non-trainable params: 50,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6866/6866 [==============================] - ETA: 0s - loss: 2.6914\n",
      "Epoch 1: saving model to e:\\STUDIA\\IPS\\question-answering\\generative-qa\\training-checkpoints\\python-bart-uncased-5\\cp-01.ckpt\n",
      "6866/6866 [==============================] - 1500s 216ms/step - loss: 2.6914 - val_loss: 2.7224\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the new data\n",
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_val_dataset,\n",
    "    epochs=train_epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best version of the model\n",
    "best_model, best_epoch = core_qa_utils.get_best_model_from_checkpoints(\n",
    "    model, history, model_name=full_model_name, remove_checkpoints=True, model_type=\"generative\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model's weights\n",
    "generative_qa_utils.save_model(best_model, model_name=full_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python-bart-uncased-5'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "loaded_model = generative_qa_utils.load_model(\n",
    "    model_checkpoint, model_name=full_model_name\n",
    ")\n",
    "loaded_model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_weights_model = generative_qa_utils.load_weights_into_model(\n",
    "    model=model, \n",
    "    model_name=full_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/857 [==============================] - 74s 73ms/step - loss: 2.6827\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the best model\n",
    "loaded_model_evaluation = loaded_model.evaluate(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_with_xla(batch):\n",
    "    return loaded_weights_model.generate(\n",
    "        input_ids=batch[\"input_ids\"],\n",
    "        attention_mask=batch[\"attention_mask\"],\n",
    "        max_new_tokens=max_length,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_dataset2 = tokenized_test_dataset.train_test_split(test_size=0.001)['test']\n",
    "len(tokenized_test_dataset2[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>How does the code add a user in the given buckets default object access control list?</s></s>def add_bucket_default_owner bucket_name user_email storage_client storage Client bucket storage_client bucket bucket_name bucket acl reload bucket default_object_acl user user_email grant_owner bucket default_object_acl save print 'Addeduser{}asanownerinthedefaultaclonbucket{}'format user_email bucket_name</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_test_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>What will they have?</s></s>def add_course_author user course global_admin AdminFactory for role in CourseStaffRole CourseInstructorRole auth add_users global_admin role course id user</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_test_dataset2[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>What will they have?</s></s>def add_course_author user course global_admin AdminFactory for role in CourseStaffRole CourseInstructorRole auth add_users global_admin role course id user</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_test_dataset2[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>the permissions to see it in studio</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_test_dataset2[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bart_for_conditional_generation_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFBartMainLayer)     multiple                  139420416 \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 50265     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,470,681\n",
      "Trainable params: 139,420,416\n",
      "Non-trainable params: 50,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bart_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFBartMainLayer)     multiple                  139420416 \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 50265     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,470,681\n",
      "Trainable params: 139,420,416\n",
      "Non-trainable params: 50,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_dataset2 = core_qa_utils.prepare_tf_dataset(\n",
    "    model=loaded_weights_model,\n",
    "    hf_dataset=tokenized_test_dataset2,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), 'decoder_input_ids': TensorSpec(shape=(None, 256), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 256), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(None, 256), dtype=tf.int64, name=None), 'decoder_input_ids': TensorSpec(shape=(None, 256), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 256), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.13s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_labels2 = []\n",
    "something = []\n",
    "something2 = []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for batch, labels in tqdm(tf_test_dataset2):\n",
    "    predictions = generate_with_xla(batch)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = labels.numpy()\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    all_preds.extend(decoded_preds)\n",
    "    all_labels.extend(decoded_labels)\n",
    "    all_labels2.extend(tokenizer.batch_decode(labels, skip_special_tokens=True))\n",
    "    something.extend(tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True))\n",
    "    something2.extend(tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True))\n",
    "    data = {\n",
    "        'qc': tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True),\n",
    "        'labels': decoded_labels,\n",
    "        'preds': decoded_preds\n",
    "    }\n",
    "    df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['access to the course',\n",
       "  'with the given part',\n",
       "  'the event loop',\n",
       "  'the hamming loss',\n",
       "  'a kaiserformula',\n",
       "  'a function',\n",
       "  'with the given authz'],\n",
       " [['the permissions to see it in studio'],\n",
       "  ['in the form of a key / value pair separated by a colon'],\n",
       "  ['the qt4 event loop'],\n",
       "  ['the average hamming loss'],\n",
       "  ['a kaiser window'],\n",
       "  ['skip if a test is executed under travis testing environment'],\n",
       "  ['with their translations']],\n",
       " ['the permissions to see it in studio',\n",
       "  'in the form of a key / value pair separated by a colon',\n",
       "  'the qt4 event loop',\n",
       "  'the average hamming loss',\n",
       "  'a kaiser window',\n",
       "  'skip if a test is executed under travis testing environment',\n",
       "  'with their translations'],\n",
       " ['What will they have?def add_course_author user course global_admin AdminFactory for role in CourseStaffRole CourseInstructorRole auth add_users global_admin role course id user',\n",
       "  \"How does the code take a query?def parse_query_part part query_classes {} prefixes {} default_class query SubstringQuery part part strip match PARSE_QUERY_PART_REGEX match part assert matchkey match group 1 term match group 2 replace '\\\\\\\\\\\\\\\\'''for pre query_class in prefixes items if term startswith pre return key term[len pre ] query_class query_class query_classes get key default_class return key term query_class\",\n",
       "  \"What does the code start in a consistent manner?def start_event_loop_qt4 app None if app is None app get_app_qt4 [''] if not is_event_loop_running_qt4 app app _in_event_loop Trueapp exec_ app _in_event_loop Falseelse app _in_event_loop True\",\n",
       "  'What does the code compute?def hamming_loss y_true y_pred labels None sample_weight None classes None if classes is not None warnings warn \"\\'classes\\'wasrenamedto\\'labels\\'inversion0 18andwillberemovedin0 20 \" DeprecationWarning labels classes y_type y_true y_pred _check_targets y_true y_pred if labels is None labels unique_labels y_true y_pred else labels np asarray labels if sample_weight is None weight_average 1 0else weight_average np mean sample_weight if y_type startswith\\'multilabel\\' n_differences count_nonzero y_true - y_pred sample_weight sample_weight return n_differences / y_true shape[0] * len labels * weight_average elif y_type in [\\'binary\\'\\'multiclass\\'] return _weighted_sum y_true y_pred sample_weight normalize True else raise ValueError \\'{0}isnotsupported\\' format y_type',\n",
       "  \"What limits ripple and width of transition region?def kaiserord ripple width A abs ripple if A < 8 raise ValueError 'Requestedmaximumrippleattentuation%fistoosmallfortheKaiserformula'% A beta kaiser_beta A numtaps A - 7 95 / 2 285 / np pi * width + 1 return int ceil numtaps beta\",\n",
       "  \"What could be used as a decorator or unparametrized in the code?def skip_under_travis fn None if _travisTesting skip msg pytest skip 'CannotbetestedunderTravis-CI' if fn is not None def _inner skip msg _inner __name__ fn __name__return _innerelse skip msg else return fn\",\n",
       "  'How do a dict of available roles return?@core_helperdef roles_translated return authz roles_trans'],\n",
       " ['What will they have?def add_course_author user course global_admin AdminFactory for role in CourseStaffRole CourseInstructorRole auth add_users global_admin role course id user',\n",
       "  \"How does the code take a query?def parse_query_part part query_classes {} prefixes {} default_class query SubstringQuery part part strip match PARSE_QUERY_PART_REGEX match part assert matchkey match group 1 term match group 2 replace '\\\\\\\\\\\\\\\\'''for pre query_class in prefixes items if term startswith pre return key term[len pre ] query_class query_class query_classes get key default_class return key term query_class\",\n",
       "  \"What does the code start in a consistent manner?def start_event_loop_qt4 app None if app is None app get_app_qt4 [''] if not is_event_loop_running_qt4 app app _in_event_loop Trueapp exec_ app _in_event_loop Falseelse app _in_event_loop True\",\n",
       "  'What does the code compute?def hamming_loss y_true y_pred labels None sample_weight None classes None if classes is not None warnings warn \"\\'classes\\'wasrenamedto\\'labels\\'inversion0 18andwillberemovedin0 20 \" DeprecationWarning labels classes y_type y_true y_pred _check_targets y_true y_pred if labels is None labels unique_labels y_true y_pred else labels np asarray labels if sample_weight is None weight_average 1 0else weight_average np mean sample_weight if y_type startswith\\'multilabel\\' n_differences count_nonzero y_true - y_pred sample_weight sample_weight return n_differences / y_true shape[0] * len labels * weight_average elif y_type in [\\'binary\\'\\'multiclass\\'] return _weighted_sum y_true y_pred sample_weight normalize True else raise ValueError \\'{0}isnotsupported\\' format y_type',\n",
       "  \"What limits ripple and width of transition region?def kaiserord ripple width A abs ripple if A < 8 raise ValueError 'Requestedmaximumrippleattentuation%fistoosmallfortheKaiserformula'% A beta kaiser_beta A numtaps A - 7 95 / 2 285 / np pi * width + 1 return int ceil numtaps beta\",\n",
       "  \"What could be used as a decorator or unparametrized in the code?def skip_under_travis fn None if _travisTesting skip msg pytest skip 'CannotbetestedunderTravis-CI' if fn is not None def _inner skip msg _inner __name__ fn __name__return _innerelse skip msg else return fn\",\n",
       "  'How do a dict of available roles return?@core_helperdef roles_translated return authz roles_trans'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds, all_labels, all_labels2, something, something2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qc</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What will they have?def add_course_author user...</td>\n",
       "      <td>[the permissions to see it in studio]</td>\n",
       "      <td>access to the course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the code take a query?def parse_query...</td>\n",
       "      <td>[in the form of a key / value pair separated b...</td>\n",
       "      <td>with the given part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does the code start in a consistent manne...</td>\n",
       "      <td>[the qt4 event loop]</td>\n",
       "      <td>the event loop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the code compute?def hamming_loss y_...</td>\n",
       "      <td>[the average hamming loss]</td>\n",
       "      <td>the hamming loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What limits ripple and width of transition reg...</td>\n",
       "      <td>[a kaiser window]</td>\n",
       "      <td>a kaiserformula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What could be used as a decorator or unparamet...</td>\n",
       "      <td>[skip if a test is executed under travis testi...</td>\n",
       "      <td>a function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do a dict of available roles return?@core_...</td>\n",
       "      <td>[with their translations]</td>\n",
       "      <td>with the given authz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  qc  \\\n",
       "0  What will they have?def add_course_author user...   \n",
       "1  How does the code take a query?def parse_query...   \n",
       "2  What does the code start in a consistent manne...   \n",
       "3  What does the code compute?def hamming_loss y_...   \n",
       "4  What limits ripple and width of transition reg...   \n",
       "5  What could be used as a decorator or unparamet...   \n",
       "6  How do a dict of available roles return?@core_...   \n",
       "\n",
       "                                              labels                 preds  \n",
       "0              [the permissions to see it in studio]  access to the course  \n",
       "1  [in the form of a key / value pair separated b...   with the given part  \n",
       "2                               [the qt4 event loop]        the event loop  \n",
       "3                         [the average hamming loss]      the hamming loss  \n",
       "4                                  [a kaiser window]       a kaiserformula  \n",
       "5  [skip if a test is executed under travis testi...            a function  \n",
       "6                          [with their translations]  with the given authz  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'qc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\question_answering\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'qc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\STUDIA\\IPS\\question-answering\\generative-qa\\notebooks\\python\\python_bart-uncased_1 copy.ipynb Cell 43\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/STUDIA/IPS/question-answering/generative-qa/notebooks/python/python_bart-uncased_1%20copy.ipynb#Y100sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m contexts \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/STUDIA/IPS/question-answering/generative-qa/notebooks/python/python_bart-uncased_1%20copy.ipynb#Y100sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/STUDIA/IPS/question-answering/generative-qa/notebooks/python/python_bart-uncased_1%20copy.ipynb#Y100sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     questions\u001b[39m.\u001b[39mappend(row[\u001b[39m'\u001b[39;49m\u001b[39mqc\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m?\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m?\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/STUDIA/IPS/question-answering/generative-qa/notebooks/python/python_bart-uncased_1%20copy.ipynb#Y100sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     contexts\u001b[39m.\u001b[39mappend(row[\u001b[39m'\u001b[39m\u001b[39mqc\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m?\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m1\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/STUDIA/IPS/question-answering/generative-qa/notebooks/python/python_bart-uncased_1%20copy.ipynb#Y100sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mquestions\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m questions\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\question_answering\\lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m   1042\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\question_answering\\lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1158\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\Artur\\.conda\\envs\\question_answering\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'qc'"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "contexts = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    questions.append(row['qc'].split('?')[0] + '?')\n",
    "    contexts.append(row['qc'].split('?')[1])\n",
    "\n",
    "df['questions'] = questions\n",
    "df['contexts'] = contexts\n",
    "labels = df['labels']\n",
    "preds = df['preds']\n",
    "df = df.drop(['qc', 'labels', 'preds'], axis=1)\n",
    "df['labels'] = labels\n",
    "df['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>contexts</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What will they have?</td>\n",
       "      <td>def add_course_author user course global_admin...</td>\n",
       "      <td>[the permissions to see it in studio]</td>\n",
       "      <td>access to the course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the code take a query?</td>\n",
       "      <td>def parse_query_part part query_classes {} pre...</td>\n",
       "      <td>[in the form of a key / value pair separated b...</td>\n",
       "      <td>with the given part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does the code start in a consistent manner?</td>\n",
       "      <td>def start_event_loop_qt4 app None if app is No...</td>\n",
       "      <td>[the qt4 event loop]</td>\n",
       "      <td>the event loop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the code compute?</td>\n",
       "      <td>def hamming_loss y_true y_pred labels None sam...</td>\n",
       "      <td>[the average hamming loss]</td>\n",
       "      <td>the hamming loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What limits ripple and width of transition reg...</td>\n",
       "      <td>def kaiserord ripple width A abs ripple if A &lt;...</td>\n",
       "      <td>[a kaiser window]</td>\n",
       "      <td>a kaiserformula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What could be used as a decorator or unparamet...</td>\n",
       "      <td>def skip_under_travis fn None if _travisTestin...</td>\n",
       "      <td>[skip if a test is executed under travis testi...</td>\n",
       "      <td>a function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do a dict of available roles return?</td>\n",
       "      <td>@core_helperdef roles_translated return authz ...</td>\n",
       "      <td>[with their translations]</td>\n",
       "      <td>with the given authz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0                               What will they have?   \n",
       "1                    How does the code take a query?   \n",
       "2   What does the code start in a consistent manner?   \n",
       "3                        What does the code compute?   \n",
       "4  What limits ripple and width of transition reg...   \n",
       "5  What could be used as a decorator or unparamet...   \n",
       "6           How do a dict of available roles return?   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  def add_course_author user course global_admin...   \n",
       "1  def parse_query_part part query_classes {} pre...   \n",
       "2  def start_event_loop_qt4 app None if app is No...   \n",
       "3  def hamming_loss y_true y_pred labels None sam...   \n",
       "4  def kaiserord ripple width A abs ripple if A <...   \n",
       "5  def skip_under_travis fn None if _travisTestin...   \n",
       "6  @core_helperdef roles_translated return authz ...   \n",
       "\n",
       "                                              labels                 preds  \n",
       "0              [the permissions to see it in studio]  access to the course  \n",
       "1  [in the form of a key / value pair separated b...   with the given part  \n",
       "2                               [the qt4 event loop]        the event loop  \n",
       "3                         [the average hamming loss]      the hamming loss  \n",
       "4                                  [a kaiser window]       a kaiserformula  \n",
       "5  [skip if a test is executed under travis testi...            a function  \n",
       "6                          [with their translations]  with the given authz  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>contexts</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What could be used as a decorator or unparamet...</td>\n",
       "      <td>def skip_under_travis fn None if _travisTestin...</td>\n",
       "      <td>[skip if a test is executed under travis testi...</td>\n",
       "      <td>a function</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "5  What could be used as a decorator or unparamet...   \n",
       "\n",
       "                                            contexts  \\\n",
       "5  def skip_under_travis fn None if _travisTestin...   \n",
       "\n",
       "                                              labels       preds  \n",
       "5  [skip if a test is executed under travis testi...  a function  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [0.5454545454545454, 0.13333333333333333, 0.0, 0.0],\n",
       " 'brevity_penalty': 0.36787944117144233,\n",
       " 'length_ratio': 0.5,\n",
       " 'translation_length': 22,\n",
       " 'reference_length': 44}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = metric.compute(predictions=all_preds, references=all_labels)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "question_answering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
