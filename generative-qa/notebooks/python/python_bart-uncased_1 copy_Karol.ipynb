{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model trained on contaxts being original_code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T17:43:01.672130100Z",
     "start_time": "2023-11-06T17:42:50.404300500Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BartTokenizerFast,\n",
    "    TFAutoModelForQuestionAnswering,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    keras_callbacks,\n",
    "    TFAutoModelForSeq2SeqLM,\n",
    "    TFEncoderDecoderModel,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import notebook_login\n",
    "from question_answering.constants import constants\n",
    "from question_answering.utils import core_qa_utils, generative_qa_utils\n",
    "from question_answering.paths import generative_qa_paths\n",
    "from question_answering.keras_callbacks.time_measure_callback import TimeMeasureCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = core_qa_utils.load_train_val_test_datasets(\n",
    "    generative_qa_paths.python_dataset_dir\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = core_qa_utils.convert_dataframes_to_datasets(\n",
    "    [df_train, df_val, df_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/bart-base\"\n",
    "tokenizer = BartTokenizerFast.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTokenizerFast(name_or_path='facebook/bart-base', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b925f72528413996ffc806872d6059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d9203ed0e74ff6894c165230e418c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b342f8fed0be4f4782e758270c92c7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens in tokenized train dataset:  9244\n",
      "Max number of tokens in tokenized val dataset:  575\n",
      "Max number of tokens in tokenized test dataset:  901\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sample(sample, max_tokens=None, padding=False):\n",
    "    question = sample[\"questions\"].strip()\n",
    "    context = sample[\"original_code\"].strip()\n",
    "\n",
    "    return tokenizer(question, context, max_length=max_tokens, padding=padding)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_sample)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_sample)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_sample)\n",
    "\n",
    "print(\n",
    "    \"Max number of tokens in tokenized train dataset: \",\n",
    "    len(max(tokenized_train_dataset[\"input_ids\"], key=len)),\n",
    ")\n",
    "print(\n",
    "    \"Max number of tokens in tokenized val dataset: \",\n",
    "    len(max(tokenized_val_dataset[\"input_ids\"], key=len)),\n",
    ")\n",
    "print(\n",
    "    \"Max number of tokens in tokenized test dataset: \",\n",
    "    len(max(tokenized_test_dataset[\"input_ids\"], key=len)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object filter_samples_below_number_of_tokens.<locals>.<genexpr> at 0x00000214C3F3B140> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "max_length = 256\n",
    "\n",
    "\n",
    "def filter_samples_below_number_of_tokens(dataset, max_tokens: int):\n",
    "    indices_to_remove = []\n",
    "\n",
    "    # Find indices of samples where number of tokens exceeds max number of tokens\n",
    "    for index, sample in enumerate(dataset):\n",
    "        tokenized_sample = tokenize_sample(sample)\n",
    "        if len(tokenized_sample[\"input_ids\"]) > max_tokens:\n",
    "            indices_to_remove.append(index)\n",
    "\n",
    "    # Keep only samples with number of tokens less or equal than max number of tokens\n",
    "    dataset_indices = range(len(dataset))\n",
    "    filtered_dataset = dataset.select(\n",
    "        index for index in dataset_indices if index not in set(indices_to_remove)\n",
    "    )\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "\n",
    "filtered_train_dataset = filter_samples_below_number_of_tokens(\n",
    "    train_dataset, max_tokens=max_length\n",
    ")\n",
    "filtered_val_dataset = filter_samples_below_number_of_tokens(\n",
    "    val_dataset, max_tokens=max_length\n",
    ")\n",
    "filtered_test_dataset = filter_samples_below_number_of_tokens(\n",
    "    test_dataset, max_tokens=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in tokenized train dataset before filtering:  56080\n",
      "Number of samples in tokenized val dataset before filtering:  7000\n",
      "Number of samples in tokenized test dataset before filtering:  7000\n",
      "\n",
      "---------------\n",
      "\n",
      "Number of samples in tokenized train dataset after filtering:  54930\n",
      "Number of samples in tokenized val dataset after filtering:  6828\n",
      "Number of samples in tokenized test dataset after filtering:  6854\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of samples in tokenized train dataset before filtering: \",\n",
    "    len(train_dataset),\n",
    ")\n",
    "print(\"Number of samples in tokenized val dataset before filtering: \", len(val_dataset))\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset before filtering: \", len(test_dataset)\n",
    ")\n",
    "\n",
    "print(\"\\n---------------\\n\")\n",
    "\n",
    "print(\n",
    "    \"Number of samples in tokenized train dataset after filtering: \",\n",
    "    len(filtered_train_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized val dataset after filtering: \",\n",
    "    len(filtered_val_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset after filtering: \",\n",
    "    len(filtered_test_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    questions = [q.strip() for q in dataset[\"questions\"]]\n",
    "    contexts = [c.strip() for c in dataset[\"original_code\"]]\n",
    "    answers = [c.strip() for c in dataset[\"answers\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        # question_context,\n",
    "        text_target=answers,\n",
    "        max_length=max_length,\n",
    "        truncation=True\n",
    "        # padding=\"max_length\",\n",
    "        # return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166ab8f4d5294da4a69fbf5b93cd2431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54930 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361cfb7052c54c17a42b42f2b7580a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6828 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffe7a2d00174659ba1b1fe5e5baa1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6854 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = filtered_train_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_train_dataset.column_names,\n",
    ")\n",
    "tokenized_val_dataset = filtered_val_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_val_dataset.column_names,\n",
    ")\n",
    "tokenized_test_dataset = filtered_test_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_test_dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokenized train dataset entries have 256 tokens:  False\n",
      "All tokenized val dataset entries have 256 tokens:  False\n",
      "All tokenized test dataset entries have 256 tokens:  False\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"All tokenized train dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_train_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    f\"All tokenized val dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_val_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    f\"All tokenized test dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_test_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "training_number = 5\n",
    "\n",
    "model_name = \"python-bart-uncased\"\n",
    "full_model_name = f\"{model_name}-{training_number}\"\n",
    "\n",
    "# Checkpoints\n",
    "checkpoint_filename_template = constants.checkpoint_filename_template\n",
    "checkpoints_path = (\n",
    "    generative_qa_paths.training_checkpoints_dir\n",
    "    / full_model_name\n",
    "    / checkpoint_filename_template\n",
    ")\n",
    "\n",
    "# Hub\n",
    "hub_path = generative_qa_paths.hub_models_location / full_model_name\n",
    "\n",
    "# Saved models\n",
    "saved_models_path = generative_qa_paths.saved_models_dir / full_model_name\n",
    "\n",
    "# Evaluation\n",
    "model_evaluation_dir = generative_qa_paths.model_evaluation_dir / full_model_name\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "train_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForConditionalGeneration: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "- This IS expected if you are initializing TFBartForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load model for fine-tuning\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# Dataset preparation\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = core_qa_utils.prepare_tf_dataset(\n",
    "    model=model,\n",
    "    hf_dataset=tokenized_train_dataset,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "tf_val_dataset = core_qa_utils.prepare_tf_dataset(\n",
    "    model=model,\n",
    "    hf_dataset=tokenized_val_dataset,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "tf_test_dataset = core_qa_utils.prepare_tf_dataset(\n",
    "    model=model,\n",
    "    hf_dataset=tokenized_test_dataset,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator.label_pad_token_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 4, 6, 3, 5, 6, 3, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelLengths = [len(tokenized_train_dataset[i]['labels']) for i in range(1, 10)]\n",
    "labelLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 109, 108, 125, 128, 126, 33, 36, 251]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputIdsLengths = [len(tokenized_train_dataset[i]['input_ids']) for i in range(1, 10)]\n",
    "inputIdsLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_train_dataset[i] for i in range(1, 10)])\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Yes</s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_train_dataset['labels'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([   0, 9904,    2, -100, -100, -100])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTokenizerFast(name_or_path='facebook/bart-base', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(251,), dtype=int32, numpy=\n",
       "array([    0, 27847,     5,  3260,   146,    10, 10606, 17487,     2,\n",
       "           2,  9232,  5293, 20689,  1459,  7605,   495, 11726,   385,\n",
       "        6929,  9291, 10606, 13810,  6929,  6929, 10606,  8504,   495,\n",
       "       11726,   385, 10606, 26411,  2072,   671, 10606,     2,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\STUDIA\\IPS\\question-answering\\generative-qa\\notebooks\\python\\python-bart-uncased-5 is already a clone of https://huggingface.co/nlp-polish/python-bart-uncased-5. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoints_path, verbose=1, save_weights_only=True\n",
    ")\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "push_to_hub = keras_callbacks.PushToHubCallback(\n",
    "    output_dir=full_model_name, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "time_measure_cb = TimeMeasureCallback()\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint_cb,\n",
    "    early_stop_cb,\n",
    "    # push_to_hub,\n",
    "    time_measure_cb\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "num_train_steps = len(tf_train_dataset) * train_epochs\n",
    "\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# Compile\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# metrics = [\"accuracy\"]\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "# model.compile(optimizer=optimizer, metrics=metrics)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bart_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFBartMainLayer)     multiple                  139420416 \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 50265     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,470,681\n",
      "Trainable params: 139,420,416\n",
      "Non-trainable params: 50,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the new data\n",
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_val_dataset,\n",
    "    epochs=train_epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best version of the model\n",
    "best_model, best_epoch = core_qa_utils.get_best_model_from_checkpoints(\n",
    "    model, history, model_name=full_model_name, remove_checkpoints=True, model_type=\"generative\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model's weights\n",
    "generative_qa_utils.save_model(best_model, model_name=full_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_weights_model = generative_qa_utils.load_weights_into_model(\n",
    "    model=model, \n",
    "    model_name=full_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/857 [==============================] - 72s 84ms/step - loss: 2.7252\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the best model\n",
    "loaded_model_evaluation = loaded_weights_model.evaluate(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Artur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Artur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Artur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "meteor_metric = evaluate.load(\"meteor\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "sacrebleu_metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_with_xla(batch):\n",
    "    return loaded_weights_model.generate(\n",
    "        input_ids=batch[\"input_ids\"],\n",
    "        attention_mask=batch[\"attention_mask\"],\n",
    "        max_new_tokens=max_length,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_dataset2 = tokenized_test_dataset.train_test_split(test_size=0.01)['test']\n",
    "len(tokenized_test_dataset2[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_dataset2 = core_qa_utils.prepare_tf_dataset(\n",
    "    model=loaded_weights_model,\n",
    "    hf_dataset=tokenized_test_dataset2,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 6179,\n",
       " 109,\n",
       " 5,\n",
       " 5473,\n",
       " 9399,\n",
       " 6756,\n",
       " 422,\n",
       " 17487,\n",
       " 2,\n",
       " 2,\n",
       " 9232,\n",
       " 9493,\n",
       " 405,\n",
       " 6756,\n",
       " 18134,\n",
       " 6460,\n",
       " 1215,\n",
       " 31002,\n",
       " 114,\n",
       " 6756,\n",
       " 16,\n",
       " 45,\n",
       " 9291,\n",
       " 6756,\n",
       " 14018,\n",
       " 9493,\n",
       " 405,\n",
       " 114,\n",
       " 34,\n",
       " 44156,\n",
       " 6756,\n",
       " 15019,\n",
       " 10416,\n",
       " 128,\n",
       " 1215,\n",
       " 261,\n",
       " 1215,\n",
       " 34886,\n",
       " 108,\n",
       " 6756,\n",
       " 15019,\n",
       " 10416,\n",
       " 18134,\n",
       " 261,\n",
       " 1215,\n",
       " 34886,\n",
       " 114,\n",
       " 34,\n",
       " 44156,\n",
       " 6756,\n",
       " 5032,\n",
       " 35934,\n",
       " 128,\n",
       " 1215,\n",
       " 261,\n",
       " 1215,\n",
       " 34886,\n",
       " 108,\n",
       " 6756,\n",
       " 5032,\n",
       " 35934,\n",
       " 18134,\n",
       " 261,\n",
       " 1215,\n",
       " 34886,\n",
       " 2]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_dataset2[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>How do the gevent hub run?</s></s>def reinit hub _get_hub if hub is not None hub loop reinit if hasattr hub threadpool '_on_fork' hub threadpool _on_fork if hasattr hub resolver '_on_fork' hub resolver _on_fork</s>\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_test_dataset2[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:56<00:00,  6.25s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "question_contexts_list = []\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for batch, labels in tqdm(tf_test_dataset2):\n",
    "    predictions = generate_with_xla(batch)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = labels.numpy()\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "    all_preds.extend(decoded_preds)\n",
    "    all_labels.extend(decoded_labels)\n",
    "    question_contexts_list.extend(tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True))\n",
    "\n",
    "    data = {\n",
    "        'question_contexts': tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True),\n",
    "        'labels': decoded_labels,\n",
    "        'preds': decoded_preds\n",
    "    }\n",
    "    df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['in reverse order',\n",
       "  'a dna',\n",
       "  'a list of default keys for the given type',\n",
       "  'a node',\n",
       "  'data to be sent to cherrypy',\n",
       "  'a custom user token',\n",
       "  'a string',\n",
       "  'to create a custom attribute',\n",
       "  'a 2d interpolation',\n",
       "  'a dict of sub keys',\n",
       "  'a qtbot editor stack',\n",
       "  'a base64 string',\n",
       "  'for the given bot',\n",
       "  'the maximum flow value of a graph',\n",
       "  'a service',\n",
       "  'the x intersections',\n",
       "  'the given api',\n",
       "  'a specific service command',\n",
       "  'a jpeg',\n",
       "  'the test directory',\n",
       "  'by tput',\n",
       "  'the dialog dialog',\n",
       "  'with the given content',\n",
       "  'using passthrough options',\n",
       "  'for a vm',\n",
       "  'a vm with a name',\n",
       "  'the given format',\n",
       "  'a trap',\n",
       "  'samelines',\n",
       "  'an editor stack',\n",
       "  'recording directories',\n",
       "  'until it is ready to receive',\n",
       "  'for a deepcopy',\n",
       "  'a dir tree of the given kind',\n",
       "  'the largest root in the system',\n",
       "  'the type of the entity',\n",
       "  'the zwave platform',\n",
       "  'a svg file',\n",
       "  'Yes',\n",
       "  'a pid file',\n",
       "  'from the given directory',\n",
       "  'for the given context',\n",
       "  'in a dict',\n",
       "  'for ssh',\n",
       "  'the given condition',\n",
       "  'permission',\n",
       "  'the localAndroid directory',\n",
       "  'the total size of a directory',\n",
       "  'a new class constructor',\n",
       "  'in a',\n",
       "  'channel fw',\n",
       "  'a pretty depth',\n",
       "  'a lock',\n",
       "  'the remaining data size',\n",
       "  'preferred output encoding for the specified locale',\n",
       "  'a year',\n",
       "  'the doc for a site',\n",
       "  'a list of user_contributions',\n",
       "  'schemes',\n",
       "  'order source modules',\n",
       "  'No',\n",
       "  'stdicon',\n",
       "  'a python script',\n",
       "  'this',\n",
       "  'Yes',\n",
       "  'the cluster - flocker - cli example',\n",
       "  'all classes',\n",
       "  'a record object',\n",
       "  'a polygon'],\n",
       " ['in a new process',\n",
       "  'a dna sequence',\n",
       "  'new keys for fused tasks',\n",
       "  'a host : port string',\n",
       "  'that the hypermedia_in tool has already been run',\n",
       "  'a secure token for the given i d',\n",
       "  'a regexp or a string',\n",
       "  'to specify a customattribute for a type or method',\n",
       "  'an actual interpolation of values',\n",
       "  'a new dict containing only a subset of the items of an existing dict',\n",
       "  'some python code',\n",
       "  'a file from the file system',\n",
       "  'for the bridge to initialise example format in config',\n",
       "  'the value of maximum single - commodity flow',\n",
       "  'the root_service',\n",
       "  'the subtracttable',\n",
       "  'the support ui',\n",
       "  'partial functions that generate commands for the current init command',\n",
       "  'the unix file implementation',\n",
       "  'the absolute path of biopythons tests directory',\n",
       "  'using tput',\n",
       "  'the splodge dialog',\n",
       "  'using the pep 0263 rules search',\n",
       "  'with the given options',\n",
       "  'to define a libvirt storage volume',\n",
       "  'some filtering',\n",
       "  'special params',\n",
       "  'the trap app',\n",
       "  'the same lines',\n",
       "  'codeeditor',\n",
       "  'a data folder or any folder',\n",
       "  'until receives a msg addressed to share or timeout return msg or none',\n",
       "  'to prevent deepcopy ( ) on anonymous user object that now contains reference to request',\n",
       "  'nodes of the given kind from a directory tree structure',\n",
       "  'the largest node in the tree',\n",
       "  'the kind of the entity',\n",
       "  'the z - wave platform',\n",
       "  'svg file',\n",
       "  'No',\n",
       "  'a file with the process i d written in it',\n",
       "  'a dict with keys home',\n",
       "  'to target_shape',\n",
       "  'in the aliases file in this format',\n",
       "  'for ssh to pass custom known hosts and key',\n",
       "  'the given condition',\n",
       "  'permission or wiki',\n",
       "  'the current local path',\n",
       "  'the total size',\n",
       "  'new _ _ on and old - class passing in new - classes',\n",
       "  'on the other',\n",
       "  'the preferred channels safe for work status',\n",
       "  'an opencv image',\n",
       "  'a package lock',\n",
       "  'how much data is remaining in the buffer',\n",
       "  'encoding that should be used for printing strings',\n",
       "  'the second piece',\n",
       "  'diagnostic info about background workers',\n",
       "  'the domain object',\n",
       "  'which uris',\n",
       "  'a list of configured order source modifier module instances',\n",
       "  'No',\n",
       "  'standard platform icon call show_std_icons ( ) for details',\n",
       "  'a wrapper script for a compiler',\n",
       "  'the prefix',\n",
       "  'No',\n",
       "  'the flocker cli package',\n",
       "  'all the sem compliant tools that should have wrappers created for them',\n",
       "  'a record constant',\n",
       "  'a convex polygon'],\n",
       " [\"How do the gevent hub run?def reinit hub _get_hub if hub is not None hub loop reinit if hasattr hub threadpool '_on_fork' hub threadpool _on_fork if hasattr hub resolver '_on_fork' hub resolver _on_fork\",\n",
       "  \"What does the code transcribe into rna?def transcribe dna if isinstance dna Seq return dna transcribe elif isinstance dna MutableSeq return dna toseq transcribe else return dna replace 'T' 'U' replace 't' 'u'\",\n",
       "  \"What does the code create?def default_fused_keys_renamer keys typ type keys[0] if typ is str or typ is unicode names [key_split x for x in keys[ 0 -1 ]]names append keys[0] return '-' join names elif typ is tuple and len keys[0] > 0 and isinstance keys[0][0] str unicode names [key_split x for x in keys[ 0 -1 ]]names append keys[0][0] return '-' join names + keys[0][1 ] else return None\",\n",
       "  \"What splits into ( host?def partition_node node host nodeport 27017idx node rfind'' if idx -1 host port node[ idx] int node[ idx + 1 ] if host startswith '[' host host[1 -1 ]return host port\",\n",
       "  \"What does this tool require?def lowdata_fmt if cherrypy request method upper 'POST' returndata cherrypy request unserialized_dataif data and isinstance data collections Mapping if 'arg' in data and not isinstance data['arg'] list data['arg'] [data['arg']]cherrypy request lowstate [data]else cherrypy serving request lowstate data\",\n",
       "  \"What does the code create?def create_custom_token uid valid_minutes 60 client_email app_identity get_service_account_name now int time time payload base64 b64encode json dumps {'iss' client_email'sub' client_email 'aud' _IDENTITY_ENDPOINT 'uid' uid 'iat' now 'exp' now + valid_minutes * 60 } header base64 b64encode json dumps {'typ' 'JWT' 'alg' 'RS256'} to_sign '{} {}' format header payload return '{} {}' format to_sign base64 b64encode app_identity sign_blob to_sign [1]\",\n",
       "  \"What does this function take?def regexp2pattern string if type string is REGEXP_T flags string flagsstring string patternif string startswith '^' string string[1 ]else string'*' + string if string endswith '$' string string[ -1 ]else string +'*'return string flags else return re escape string 0\",\n",
       "  'What is this decorator used?def attribute attrib_type def make_decorator *args **kwargs return CustomAttributeDecorator attrib_type *args **kwargs return make_decorator',\n",
       "  \"What does the code perform?def interpolate_2d values method 'pad' axis 0 limit None fill_value None dtype None transf lambda x x if axis 0 else lambda x x T ndim values ndimif values ndim 1 if axis 0 raise AssertionError 'cannotinterpolateonandim 1withaxis 0' values values reshape tuple 1 + values shape if fill_value is None mask Noneelse mask mask_missing transf values fill_value method clean_fill_method method if method 'pad' values transf pad_2d transf values limit limit mask mask dtype dtype else values transf backfill_2d transf values limit limit mask mask dtype dtype if ndim 1 values values[0]return values\",\n",
       "  'What does the code create?def sub keys d return dict [ k d[k] for k in keys]',\n",
       "  \"What do codeeditor contain?def setup_editor qtbot text 'a 1\\\\\\\\nprint a \\\\\\\\n\\\\\\\\nx 2'editorStack EditorStack None [] editorStack set_introspector Mock editorStack set_find_widget Mock editorStack set_io_actions Mock Mock Mock Mock finfo editorStack new 'foo py' 'utf-8' text qtbot addWidget editorStack return editorStack finfo editor\",\n",
       "  \"What did the code read?def base64_encodefile fname encoded_f StringIO StringIO with open fname 'rb' as f base64 encode f encoded_f encoded_f seek 0 return encoded_f read\",\n",
       "  'For what purpose must config key \" sample bridges be defined?def _initialise bot BridgeInstance bot\\'samplebridge\\' IncomingMessages',\n",
       "  \"What does the code find?def maximum_flow_value G s t capacity 'capacity' flow_func None **kwargs if flow_func is None if kwargs raise nx NetworkXError 'Youhavetoexplicitlysetaflow_funcifyouneedtopassparametersviakwargs'flow_func default_flow_funcif not callable flow_func raise nx NetworkXError 'flow_funchastobecallable'R flow_func G s t capacity capacity value_only True **kwargs return R graph['flow_value']\",\n",
       "  \"What does the code update?def org_service_root_service service_id db current dbtable current s3db org_servicerecord db table id service_id select table id table root_service table parent first try parent record parentcurrent_root record root_serviceexcept AttributeError current log error 'Cannotfindrecordwithservice_id %s' % service_id raiseif parent if parent service_id raise KeyError 'Service#%sshowingwithparent#%s' % service_id parent new_root org_service_root_service parent else new_root service_idif current_root new_root def descendants ids rows db table parent belongs ids select table id children set row id for row in rows if children children descendants children return ids children else return idsnodes descendants set [service_id] db table id belongs nodes update root_service new_root return new_root\",\n",
       "  'What does the code subtract from the subtractfromtable?def subtractXIntersectionsTable subtractFromTable subtractTable subtractFromTableKeys subtractFromTable keys subtractFromTableKeys sort for subtractFromTableKey in subtractFromTableKeys xIntersectionIndexList []addXIntersectionIndexesFromXIntersections -1 xIntersectionIndexList subtractFromTable[subtractFromTableKey] if subtractFromTableKey in subtractTable addXIntersectionIndexesFromXIntersections 0 xIntersectionIndexList subtractTable[subtractFromTableKey] xIntersections getXIntersectionsFromIntersections xIntersectionIndexList if len xIntersections > 0 subtractFromTable[subtractFromTableKey] xIntersectionselse del subtractFromTable[subtractFromTableKey]',\n",
       "  \"What do the user use?def require_support_permission func @wraps func def inner request *args **kwargs if has_access request user'support' 'global' return func request *args **kwargs else return HttpResponseForbidden return login_required inner\",\n",
       "  \"What will a class create?def _auto_create_specific_service_command_generator run utils run command_generator _command_generators[get_name_of_init run ]command_list [c for c in COMMANDS if c not in ['list''set_target'] ]return _ServiceCommandGenerator command_generator command_list\",\n",
       "  \"What uses the magic bytes?def _wider_test_jpeg data if data[ 2] '\\\\\\\\xff\\\\\\\\xd8' return 'jpeg'\",\n",
       "  \"What does the code find?def find_test_dir start_dir None if not start_dir start_dir''target os path abspath start_dir while True if os path isdir os path join target 'Bio' and os path isdir os path join target 'Tests' return os path abspath os path join target 'Tests' new tmp os path split target if target new breaktarget newraise ValueError 'NotwithinBiopythonsourcetree %r' % os path abspath start_dir\",\n",
       "  \"How does the code get terminal size?def _get_terminal_size_tput try cols int subprocess check_call shlex split 'tputcols' rows int subprocess check_call shlex split 'tputlines' return cols rows except pass\",\n",
       "  \"What does the code display?def main if len sys argv > 1 writeOutput '' join sys argv[1 ] else settings startMainLoopFromConstructor getNewRepository\",\n",
       "  \"How do the encoding of the file get?def get_file_encoding content encoding Nonetry lines_to_check content split u'\\\\\\\\n' 2 for index in range 2 if len lines_to_check > index line_encoding _search_coding_line lines_to_check[index] if line_encoding encoding line_encodingbreakexcept UnicodeDecodeError as error print errorif encoding is None encoding u'UTF-8'return encoding\",\n",
       "  \"How does bokchoytestsuite run?def run_bokchoy options passthrough_options test_suite BokChoyTestSuite 'bok-choy' passthrough_options passthrough_options **options msg colorize 'green' 'Runningtestsusing{default_store}modulestore'format default_store test_suite default_store print msgtest_suite run\",\n",
       "  \"For what purpose does the code generate the xml string?def _gen_vol_xml vmname diskname size hypervisor **kwargs size int size * 1024 disk_info _get_image_info hypervisor vmname **kwargs context {'name' vmname 'filename' '{0} {1}' format diskname disk_info['disktype'] 'volname' diskname 'disktype' disk_info['disktype']'size' str size 'pool' disk_info['pool']}fn_ 'libvirt_volume jinja'try template JINJA get_template fn_ except jinja2 exceptions TemplateNotFound log error 'Couldnotloadtemplate{0}' format fn_ return ''return template render **context\",\n",
       "  'What does this require since proxmox works based op ids rather than names as identifiers to retrieve the required information?def _get_vm_by_name name allDetails False vms get_resources_vms includeConfig allDetails if name in vms return vms[name]log info \\'VMwithname\"{0}\"couldnotbefound\\'format name return False',\n",
       "  'What do bing require?def bingify s return \"\\'{}\\'\" format s',\n",
       "  'What does contextmanager install?@contextmanagerdef set_trap app trap Trap prev_tls _state _tls_state set_default_app trap class NonTLS object current_app trap_state _tls NonTLS yield _state _tls prev_tls',\n",
       "  'What does text1 and text2 have?def assert_samelines testcase text1 text2 msg None testcase assertEqual text1 splitlines text2 splitlines msg',\n",
       "  \"What is containing some python code?def setup_editor qtbot text 'a 1\\\\\\\\nprint a \\\\\\\\n\\\\\\\\nx 2'editorStack EditorStack None [] editorStack set_introspector Mock editorStack set_find_widget Mock editorStack set_io_actions Mock Mock Mock Mock finfo editorStack new 'foo py' 'utf-8' text qtbot addWidget editorStack return editorStack finfo editor\",\n",
       "  \"What can you supply in order to make a visualization?def get_recording_dirs data_dir filtered_recording_dirs []if is_pupil_rec_dir data_dir filtered_recording_dirs append data_dir for root dirs files in os walk data_dir filtered_recording_dirs + [os path join root d for d in dirs if not d startswith'' and is_pupil_rec_dir os path join root d ]logger debug 'FilteredRecordingDirs {}' format filtered_recording_dirs return filtered_recording_dirs\",\n",
       "  'Till when is blocks sleep time if timed out delay?def wait share timeout 0 0 delay 0 01 start time time while True msg receive share if msg return msgtime sleep delay if timeout > 0 0 and time time - start > timeout return None',\n",
       "  'For what purpose is this necessary?def dummy_deepcopy *arg return None',\n",
       "  \"What does the code find?def dir_tree_find tree kind nodes []if isinstance tree list for t in tree nodes + dir_tree_find t kind else if tree['block'] kind nodes append tree for child in tree['children'] nodes + dir_tree_find child kind return nodes\",\n",
       "  'What does the code find?def findBiggest root if root right is None return rootelse return findBiggest root right',\n",
       "  'What does the code return?def get_entity_kind key_path if isinstance key_path entity_pb EntityProto key_path key_path key return key_path path element_list [ -1 ] type',\n",
       "  'What does the code setup?def setup_platform hass config add_devices discovery_info None if discovery_info is None or zwave NETWORK is None returnnode zwave NETWORK nodes[discovery_info[zwave const ATTR_NODE_ID]]value node values[discovery_info[zwave const ATTR_VALUE_ID]]if not node has_command_class zwave const COMMAND_CLASS_SWITCH_BINARY returnif value type zwave const TYPE_BOOL or value genre zwave const GENRE_USER returnvalue set_change_verified False add_devices [ZwaveSwitch value ]',\n",
       "  \"What does the code remove?def removeSVGFile svgFilePath if archive getEndsWithList svgFilePath ['_bottom svg' '_carve svg' '_chop svg' '_cleave svg' '_scale svg' '_vectorwrite svg'] os remove svgFilePath print'removeGeneratedFilesdeleted' + svgFilePath\",\n",
       "  \"Does the system have the isoinfo executable?def has_isoinfo return has_userland_tool 'isoinfo'\",\n",
       "  \"What does the code create?def setup_pid_file config odoo tools configif not odoo evented and config['pidfile'] pid os getpid with open config['pidfile'] 'w' as fd fd write str pid atexit register rm_pid_file pid\",\n",
       "  \"What does the code locate the cuda environment on the system return?def locate_cuda if 'CUDAHOME' in os environ home os environ['CUDAHOME']nvcc pjoin home 'bin' 'nvcc' else default_path pjoin os sep 'usr' 'local' 'cuda' 'bin' nvcc find_in_path 'nvcc' os environ['PATH'] + os pathsep + default_path if nvcc is None raise EnvironmentError 'Thenvccbinarycouldnotbelocatedinyour$PATH Eitheraddittoyourpath orset$CUDAHOME' home os path dirname os path dirname nvcc cudaconfig {'home' home 'nvcc' nvcc 'include' pjoin home 'include' 'lib64' pjoin home 'lib64' }for k v in cudaconfig iteritems if not os path exists v raise EnvironmentError 'TheCUDA%spathcouldnotbelocatedin%s' % k v return cudaconfig\",\n",
       "  \"For what purpose did shapes and strides broadcast?def _bc_adjust_shape_strides context builder shapes strides target_shape bc_shapes []bc_strides []zero context get_constant types uintp 0 one context get_constant types uintp 1 mismatch [builder icmp_signed'' tar old for tar old in zip target_shape shapes ]src_is_one [builder icmp_signed'' old one for old in shapes]preds [builder and_ x y for x y in zip mismatch src_is_one ]bc_shapes [builder select p tar old for p tar old in zip preds target_shape shapes ]bc_strides [builder select p zero old for p old in zip preds strides ]return bc_shapes bc_strides\",\n",
       "  'Where did the aliases find?def list_aliases ret dict alias target for alias target comment in __parse_aliases if alias return ret',\n",
       "  \"For what purpose does wrapper create?def create_ssh_wrapper ssh_wrapper ssh_file SSH_WRAPPER with open ssh_wrapper u'w' as handle handle write SSH_WRAPPER_TEMPLATE format known_hosts ssh_file KNOWN_HOSTS identity ssh_file RSA_KEY os chmod ssh_wrapper 493\",\n",
       "  'What do whose keys satisfy?def remove_items headers condition removed {}keys filter condition headers removed update key headers pop key for key in keys return removed',\n",
       "  \"What has user write?def must_have_write_permission_or_public_wiki func @functools wraps func def wrapped *args **kwargs _inject_nodes kwargs wiki kwargs['node'] get_addon 'wiki' if wiki and wiki is_publicly_editable return func *args **kwargs else return must_have_permission 'write' func *args **kwargs return wrapped\",\n",
       "  \"What returns for saving data locally create folder if not exists?def getLocalAndroidPath client args localPath os path join args localOutputFolder '{0}-{1}' format client conn modules['pupydroid utils'] getAndroidID client desc['user'] if not os path exists localPath logging info 'Creating{0}folderlocally' format localPath os makedirs localPath return localPath\",\n",
       "  'What does the code calculate?def dir_size start_path total_size 0for dirpath dirnames filenames in os walk start_path for f in filenames fp os path join dirpath f if not os path islink fp total_size + os path getsize fp return total_size',\n",
       "  \"What does the code call?def test_oldclass_newclass_construction class nc object passclass oc passnewType type oc __new__ type oc 'foo' nc oc {} AreEqual type newType type\",\n",
       "  'Where does knowledge of one not change computations?def independent a b return not dependent a b',\n",
       "  \"What does the code get?@commands u'getsafeforwork' u'getsfw' @example u' getsfw[channel]' def get_channel_sfw bot trigger channel trigger group 2 if not channel channel trigger senderif channel is_nick return bot say u' getsfwwithnochannelparamisonlypermittedinchannels' channel channel strip sfw bot db get_channel_value channel u'sfw' if sfw bot say u'%sisflaggedasSFW' % channel else bot say u'%sisflaggedasNSFW' % channel\",\n",
       "  'What s datatype?def pretty_depth_cv depth import cvdepth pretty_depth depth image cv CreateImageHeader depth shape[1] depth shape[0] cv IPL_DEPTH_8U 1 cv SetData image depth tostring depth dtype itemsize * depth shape[1] return image',\n",
       "  \"What does the code add?def add_lock packages **kwargs locks list_locks added []try packages list __salt__['pkg_resource parse_targets'] packages [0] keys except MinionError as exc raise CommandExecutionError exc for pkg in packages if not locks get pkg added append pkg if added __zypper__ call 'al' *added return {'added' len added 'packages' added}\",\n",
       "  'What does the code compute?def _RemainingDataSize input_buffer current_position input_buffer tell input_buffer seek 0 2 remaining_data_size input_buffer tell - current_position input_buffer seek current_position return remaining_data_size',\n",
       "  \"What does the code get?def get_preferred_output_encoding if hasattr locale u'LC_MESSAGES' return locale getlocale locale LC_MESSAGES [1] or locale getdefaultlocale [1] or u'ascii' return locale getdefaultlocale [1] or u'ascii'\",\n",
       "  \"What do we take then?def get_year book return int book['date'] split [1]\",\n",
       "  \"What does the code get?@click command u'doctor' @click option u'--site' help u'sitename' def doctor site None from frappe utils doctor import doctor as _doctorreturn _doctor site site\",\n",
       "  \"What does the code return?def create_user_contributions user_id created_exploration_ids edited_exploration_ids user_contributions get_user_contributions user_id strict False if user_contributions raise Exception 'Usercontributionsmodelforuser%salreadyexists'% user_id else user_contributions UserContributions user_id created_exploration_ids edited_exploration_ids _save_user_contributions user_contributions return user_contributions\",\n",
       "  'What can we support actually from provided whitelist?def supported_uri_schemes uri_schemes supported_schemes set registry Gst Registry get for factory in registry get_feature_list Gst ElementFactory for uri in factory get_uri_protocols if uri in uri_schemes supported_schemes add uri return supported_schemes',\n",
       "  \"What does the code get?def get_order_source_modifier_modules return load_module_instances u'SHUUP_ORDER_SOURCE_MODIFIER_MODULES' u'order_source_modifier_module'\",\n",
       "  \"Does the validation contain a traceback?def assert_no_validation_errors validation if hasattr validation 'task_error' error validation task_errorelse error validation['error']if error print '-' * 70 print errorprint '-' * 70 raise AssertionError 'Unexpectedtaskerror %s' % error rstrip split '\\\\\\\\n' [ -1 ]\",\n",
       "  \"What does the code get?def get_std_icon name size None if not name startswith 'SP_' name 'SP_' + name icon QWidget style standardIcon getattr QStyle name if size is None return iconelse return QIcon icon pixmap size size\",\n",
       "  \"What does the code create?def makescript filename compiler dirname os path split filename [0]if not os access dirname os X_OK os mkdir dirname 493 fp open filename 'w' fp write SCRIPT % compiler fp close os chmod filename 493 print 'fixapplepython23 Created' filename\",\n",
       "  'What raises condaenvironmentnotfounderror if the prefix is invalid?def get_prefix ctx args search True if getattr args u\\'name\\' None if u\\'/\\' in args name raise CondaValueError u\"\\'/\\'notallowedinenvironmentname %s\" % args name getattr args u\\'json\\' False if args name ROOT_ENV_NAME return ctx root_dirif search return locate_prefix_by_name ctx args name else return join ctx envs_dirs[0] args name elif getattr args u\\'prefix\\' None return abspath expanduser args prefix else return ctx default_prefix',\n",
       "  'Does the test harness use lmsfieldstorage apparently?def inject_field_overrides blocks course user OverrideFieldData provider_classes Nonefor block in blocks block _field_data OverrideFieldData wrap user course block _field_data',\n",
       "  \"What does the code install?def task_cli_pkg_install distribution package_source PackageSource commands task_package_install 'clusterhq-flocker-cli' distribution package_source return sequence [ Effect Sudo command e intent command log_command_filter e intent log_command_filter if isinstance e intent Run else e for e in commands intent effects]\",\n",
       "  \"What does modules_list contain?def generate_all_classes modules_list [] launcher [] redirect_x False mipav_hacks False all_code {}for module in modules_list print u''* 80 print u'GeneratingDefinitionformodule{0}' format module print u'^' * 80 package code module generate_class module launcher redirect_x redirect_x mipav_hacks mipav_hacks cur_package all_codemodule_name package strip split u'' [0] split u''[ -1 ]for package in package strip split u'' [0] split u''[ -1 ] if package not in cur_package cur_package[package] {}cur_package cur_package[package]if module_name not in cur_package cur_package[module_name] {}cur_package[module_name][module] codeif os path exists u'__init__ py' os unlink u'__init__ py' crawl_code_struct all_code os getcwd\",\n",
       "  'What does the code create?@lower_constant types Record def constant_record context builder ty pyval lty ir ArrayType ir IntType 8 pyval nbytes val lty bytearray pyval tostring return cgutils alloca_once_value builder val',\n",
       "  'What do 2-tuples define?def contains_point poly point n len poly c Falsei 0j n - 1 while i < n if poly[i][0] > point[0] poly[j][0] > point[0] and point[1] < poly[j][1] - poly[i][1] * point[0] - poly[i][0] / poly[j][0] - poly[i][0] + poly[i][1] c not c j ii + 1return c'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds, all_labels, question_contexts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_contexts</th>\n",
       "      <th>preds</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does the code clean?def __clean_tmp sfn i...</td>\n",
       "      <td>the tempfile</td>\n",
       "      <td>a template temp file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does the code introspect to grab defined ...</td>\n",
       "      <td>the given context</td>\n",
       "      <td>a rebulk instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What represents a conflict in the database?def...</td>\n",
       "      <td>a string</td>\n",
       "      <td>the specified exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the code run?def run_discovery entry...</td>\n",
       "      <td>a discovery</td>\n",
       "      <td>the default discovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does the code create?def make_assert erro...</td>\n",
       "      <td>an opensl error</td>\n",
       "      <td>an assert function that uses : func : exceptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What does the code take?def generate_video v p...</td>\n",
       "      <td>a video object</td>\n",
       "      <td>a video object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When does this handler look at s3 requests?def...</td>\n",
       "      <td>when the specified host is not specified</td>\n",
       "      <td>just before they are signed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What computes in k[x_0?def _LC f ring f ringk ...</td>\n",
       "      <td>lcf</td>\n",
       "      <td>the leading coefficient of a multivariate poly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What has the code give if the user has all rig...</td>\n",
       "      <td>a list of page ids</td>\n",
       "      <td>a list of page where the user has delete right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What does the code remove all duplicates?def o...</td>\n",
       "      <td>the ordered set</td>\n",
       "      <td>from the input iterable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What does a decorator assert?def returns_None ...</td>\n",
       "      <td>that a function returns none</td>\n",
       "      <td>that the decorated function returns none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What does the code compute?def rogerstanimoto ...</td>\n",
       "      <td>the rogerstanimoto</td>\n",
       "      <td>the rogers - tanimoto dissimilarity between tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What does the code generate?def buf_lookup_str...</td>\n",
       "      <td>a string with the given name and offset</td>\n",
       "      <td>a buffer lookup function for the right number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Where do injectors inject the provided keys?de...</td>\n",
       "      <td>in k</td>\n",
       "      <td>at different levels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    question_contexts  \\\n",
       "0   What does the code clean?def __clean_tmp sfn i...   \n",
       "1   What does the code introspect to grab defined ...   \n",
       "2   What represents a conflict in the database?def...   \n",
       "3   What does the code run?def run_discovery entry...   \n",
       "4   What does the code create?def make_assert erro...   \n",
       "5   What does the code take?def generate_video v p...   \n",
       "6   When does this handler look at s3 requests?def...   \n",
       "7   What computes in k[x_0?def _LC f ring f ringk ...   \n",
       "8   What has the code give if the user has all rig...   \n",
       "9   What does the code remove all duplicates?def o...   \n",
       "10  What does a decorator assert?def returns_None ...   \n",
       "11  What does the code compute?def rogerstanimoto ...   \n",
       "12  What does the code generate?def buf_lookup_str...   \n",
       "13  Where do injectors inject the provided keys?de...   \n",
       "\n",
       "                                       preds  \\\n",
       "0                               the tempfile   \n",
       "1                          the given context   \n",
       "2                                   a string   \n",
       "3                                a discovery   \n",
       "4                            an opensl error   \n",
       "5                             a video object   \n",
       "6   when the specified host is not specified   \n",
       "7                                        lcf   \n",
       "8                         a list of page ids   \n",
       "9                            the ordered set   \n",
       "10              that a function returns none   \n",
       "11                        the rogerstanimoto   \n",
       "12   a string with the given name and offset   \n",
       "13                                      in k   \n",
       "\n",
       "                                               labels  \n",
       "0                                a template temp file  \n",
       "1                                   a rebulk instance  \n",
       "2                             the specified exception  \n",
       "3                               the default discovery  \n",
       "4   an assert function that uses : func : exceptio...  \n",
       "5                                      a video object  \n",
       "6                         just before they are signed  \n",
       "7   the leading coefficient of a multivariate poly...  \n",
       "8   a list of page where the user has delete right...  \n",
       "9                             from the input iterable  \n",
       "10           that the decorated function returns none  \n",
       "11  the rogers - tanimoto dissimilarity between tw...  \n",
       "12  a buffer lookup function for the right number ...  \n",
       "13                                at different levels  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(list(zip(question_contexts_list, all_preds, all_labels)),\n",
    "               columns =['question_contexts', 'preds', 'labels'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "contexts = []\n",
    "\n",
    "if 'question_contexts' in df:\n",
    "    for index, row in df.iterrows():\n",
    "        questions.append(row['question_contexts'].split('?')[0] + '?')\n",
    "        contexts.append(row['question_contexts'].split('?')[1])\n",
    "\n",
    "    data = {\n",
    "        'questions': questions,\n",
    "        'contexts': contexts,\n",
    "        'labels': df['labels'],\n",
    "        'preds': df['preds']\n",
    "    }\n",
    "    df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>contexts</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What has the code give if the user has all rig...</td>\n",
       "      <td>def get_delete_id_list user site check_global ...</td>\n",
       "      <td>a list of page where the user has delete right...</td>\n",
       "      <td>a list of page ids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does the code remove all duplicates?</td>\n",
       "      <td>def orderedSet iterable res []for el in iterab...</td>\n",
       "      <td>from the input iterable</td>\n",
       "      <td>the ordered set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does a decorator assert?</td>\n",
       "      <td>def returns_None function def call_and_assert ...</td>\n",
       "      <td>that the decorated function returns none</td>\n",
       "      <td>that a function returns none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the code compute?</td>\n",
       "      <td>def rogerstanimoto u v u _validate_vector u v ...</td>\n",
       "      <td>the rogers - tanimoto dissimilarity between tw...</td>\n",
       "      <td>the rogerstanimoto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does the code generate?</td>\n",
       "      <td>def buf_lookup_strided_code proto defin name n...</td>\n",
       "      <td>a buffer lookup function for the right number ...</td>\n",
       "      <td>a string with the given name and offset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Where do injectors inject the provided keys?</td>\n",
       "      <td>def inject **k return InjectionFactory k</td>\n",
       "      <td>at different levels</td>\n",
       "      <td>in k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  What has the code give if the user has all rig...   \n",
       "1          What does the code remove all duplicates?   \n",
       "2                      What does a decorator assert?   \n",
       "3                        What does the code compute?   \n",
       "4                       What does the code generate?   \n",
       "5       Where do injectors inject the provided keys?   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  def get_delete_id_list user site check_global ...   \n",
       "1  def orderedSet iterable res []for el in iterab...   \n",
       "2  def returns_None function def call_and_assert ...   \n",
       "3  def rogerstanimoto u v u _validate_vector u v ...   \n",
       "4  def buf_lookup_strided_code proto defin name n...   \n",
       "5           def inject **k return InjectionFactory k   \n",
       "\n",
       "                                              labels  \\\n",
       "0  a list of page where the user has delete right...   \n",
       "1                            from the input iterable   \n",
       "2           that the decorated function returns none   \n",
       "3  the rogers - tanimoto dissimilarity between tw...   \n",
       "4  a buffer lookup function for the right number ...   \n",
       "5                                at different levels   \n",
       "\n",
       "                                     preds  \n",
       "0                       a list of page ids  \n",
       "1                          the ordered set  \n",
       "2             that a function returns none  \n",
       "3                       the rogerstanimoto  \n",
       "4  a string with the given name and offset  \n",
       "5                                     in k  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [0.5263157894736842, 0.25, 0.16666666666666666, 0.0],\n",
       " 'brevity_penalty': 0.6227038648477501,\n",
       " 'length_ratio': 0.6785714285714286,\n",
       " 'translation_length': 19,\n",
       " 'reference_length': 28}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_result = bleu_metric.compute(predictions=all_preds, references=all_labels)\n",
    "bleu_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.46734693877551026,\n",
       " 'rouge2': 0.1285714285714286,\n",
       " 'rougeL': 0.4625850340136055,\n",
       " 'rougeLsum': 0.4680272108843538}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rogue_result = rouge_metric.compute(predictions=all_preds, references=all_labels)\n",
    "rogue_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meteor': 0.2960018704699556}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteor_result = meteor_metric.compute(predictions=all_preds, references=all_labels)\n",
    "meteor_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee859419cb764c0f98883640a0b9dab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36c9ebafefb4eb482ff18a80c4f684b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3ebd6815b7447592dea7222289d404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c272bbb95a4a7d908417bd14eab27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8938b23e94134f86aa0d8fbe96b9d590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.8852345943450928,\n",
       "  1.000000238418579,\n",
       "  0.8785045146942139,\n",
       "  0.952263593673706,\n",
       "  0.8838106393814087,\n",
       "  0.9287854433059692,\n",
       "  0.9260398745536804],\n",
       " 'recall': [0.8251450061798096,\n",
       "  1.000000238418579,\n",
       "  0.8626241087913513,\n",
       "  0.9275587201118469,\n",
       "  0.8552083969116211,\n",
       "  0.8669842481613159,\n",
       "  0.8938043117523193],\n",
       " 'f1': [0.854134202003479,\n",
       "  1.000000238418579,\n",
       "  0.8704918622970581,\n",
       "  0.9397488236427307,\n",
       "  0.8692743182182312,\n",
       "  0.8968214392662048,\n",
       "  0.9096365571022034],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.35.0)'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore_result = bertscore_metric.compute(predictions=all_preds, references=all_labels, lang='en')\n",
    "bertscore_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 16.94436713288991,\n",
       " 'counts': [10, 3, 1, 0],\n",
       " 'totals': [19, 12, 6, 2],\n",
       " 'precisions': [52.63157894736842, 25.0, 16.666666666666668, 25.0],\n",
       " 'bp': 0.6227038648477501,\n",
       " 'sys_len': 19,\n",
       " 'ref_len': 28}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sacrebleu_result = sacrebleu_metric.compute(predictions=all_preds, references=all_labels)\n",
    "sacrebleu_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprojroot import find_root, has_dir\n",
    "\n",
    "root = find_root(has_dir(\".git\"))\n",
    "generative_qa_dir = root / \"generative-qa\"\n",
    "model_evaluation_dir = generative_qa_dir / \"model-evaluation\" / full_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('e:/STUDIA/IPS/question-answering/generative-qa/model-evaluation/python-bart-uncased-5')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all relevant training and evaluation metrics to a json file.\n",
    "evaluation_data = {\n",
    "    \"training\": {\n",
    "        \"metrics\": 'history.history',\n",
    "        \"attempted_epochs\": train_epochs,\n",
    "        \"best_epoch\": 'best_epoch',\n",
    "        \"training_time\": \"time_measure_cb.total_training_time()\",\n",
    "        \"gpu\": core_qa_utils.get_gpu_name(),\n",
    "    },\n",
    "    \"test_set\": {\n",
    "        \"loss\": loaded_model_evaluation,\n",
    "        \"bleu\": bleu_result,\n",
    "        \"rogue\": rogue_result,\n",
    "        \"meteor\": meteor_result,\n",
    "        \"bertscore\": bertscore_result,\n",
    "        \"sacrebleu\": sacrebleu_result,\n",
    "    },\n",
    "}\n",
    "\n",
    "core_qa_utils.save_dict_as_json(\n",
    "    evaluation_data, dir_path=model_evaluation_dir, filename=\"evaluation_data.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>contexts</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does the code get?</td>\n",
       "      <td>def simple_paginate request queryset per_page ...</td>\n",
       "      <td>a simplepaginator page</td>\n",
       "      <td>a simple paginator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does the code handle?</td>\n",
       "      <td>def _len_guards M if int M M or M &lt; 0 raise Va...</td>\n",
       "      <td>small or incorrect window lengths</td>\n",
       "      <td>the current windowlength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does the code setup?</td>\n",
       "      <td>def setup_platform hass config add_devices dis...</td>\n",
       "      <td>the digital ocean droplet switch</td>\n",
       "      <td>the digital ocean switch platform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    questions  \\\n",
       "0     What does the code get?   \n",
       "1  What does the code handle?   \n",
       "2   What does the code setup?   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  def simple_paginate request queryset per_page ...   \n",
       "1  def _len_guards M if int M M or M < 0 raise Va...   \n",
       "2  def setup_platform hass config add_devices dis...   \n",
       "\n",
       "                              labels                              preds  \n",
       "0             a simplepaginator page                 a simple paginator  \n",
       "1  small or incorrect window lengths           the current windowlength  \n",
       "2   the digital ocean droplet switch  the digital ocean switch platform  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_for_manual_check = 3\n",
    "\n",
    "predictions_for_manual_check = df.sample(n = samples_for_manual_check).reset_index(drop=True)\n",
    "predictions_for_manual_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    model_evaluation_dir / \"test_set_sample_generation.csv\", index=True, index_label=\"index\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "question_answering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
