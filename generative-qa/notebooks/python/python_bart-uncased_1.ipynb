{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model trained on contaxts being original_code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:18:35.738935Z",
     "start_time": "2023-11-22T23:18:26.117466700Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    BartTokenizerFast,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    keras_callbacks,\n",
    "    TFAutoModelForSeq2SeqLM,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import concatenate_datasets\n",
    "from question_answering.constants import constants\n",
    "from question_answering.utils import core_qa_utils, generative_qa_utils\n",
    "from question_answering.paths import generative_qa_paths\n",
    "from question_answering.keras_callbacks.time_measure_callback import TimeMeasureCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:18:36.525259800Z",
     "start_time": "2023-11-22T23:18:35.738935Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = core_qa_utils.load_datasets_from_csv(\n",
    "    generative_qa_paths.python_dataset_dir\n",
    ")\n",
    "\n",
    "df_train = pd.concat([df_train, df_val], ignore_index=True)\n",
    "\n",
    "train_dataset, test_dataset = core_qa_utils.convert_dataframes_to_datasets(\n",
    "    [df_train, df_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:18:44.876571100Z",
     "start_time": "2023-11-22T23:18:43.766612100Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/bart-base\"\n",
    "tokenizer = BartTokenizerFast.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:19:31.220919Z",
     "start_time": "2023-11-22T23:18:45.884916100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91990e2ec2014b52b3b935d279d296a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/63080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25ba44f5a834ee38cc853a815998c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens in tokenized train dataset:  9244\n",
      "Max number of tokens in tokenized test dataset:  901\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sample(sample, max_tokens=None, padding=False):\n",
    "    question = sample[\"questions\"].strip()\n",
    "    context = sample[\"original_code\"].strip()\n",
    "\n",
    "    return tokenizer(question, context, max_length=max_tokens, padding=padding)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_sample)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_sample)\n",
    "\n",
    "print(\n",
    "    \"Max number of tokens in tokenized train dataset: \",\n",
    "    len(max(tokenized_train_dataset[\"input_ids\"], key=len)),\n",
    ")\n",
    "print(\n",
    "    \"Max number of tokens in tokenized test dataset: \",\n",
    "    len(max(tokenized_test_dataset[\"input_ids\"], key=len)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:20:04.290690200Z",
     "start_time": "2023-11-22T23:19:31.220919Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object filter_samples_below_number_of_tokens.<locals>.<genexpr> at 0x000001CFB2F63220> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "max_length = 256\n",
    "\n",
    "\n",
    "def filter_samples_below_number_of_tokens(dataset, max_tokens: int):\n",
    "    indices_to_remove = []\n",
    "\n",
    "    # Find indices of samples where number of tokens exceeds max number of tokens\n",
    "    for index, sample in enumerate(dataset):\n",
    "        tokenized_sample = tokenize_sample(sample)\n",
    "        if len(tokenized_sample[\"input_ids\"]) > max_tokens:\n",
    "            indices_to_remove.append(index)\n",
    "\n",
    "    # Keep only samples with number of tokens less or equal than max number of tokens\n",
    "    dataset_indices = range(len(dataset))\n",
    "    filtered_dataset = dataset.select(\n",
    "        index for index in dataset_indices if index not in set(indices_to_remove)\n",
    "    )\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "\n",
    "filtered_train_dataset = filter_samples_below_number_of_tokens(\n",
    "    train_dataset, max_tokens=max_length\n",
    ")\n",
    "filtered_test_dataset = filter_samples_below_number_of_tokens(\n",
    "    test_dataset, max_tokens=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:20:04.306016300Z",
     "start_time": "2023-11-22T23:20:04.290690200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in tokenized train dataset before filtering:  63080\n",
      "Number of samples in tokenized test dataset before filtering:  7000\n",
      "\n",
      "---------------\n",
      "\n",
      "Number of samples in tokenized train dataset after filtering:  61758\n",
      "Number of samples in tokenized test dataset after filtering:  6854\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of samples in tokenized train dataset before filtering: \",\n",
    "    len(train_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset before filtering: \", len(test_dataset)\n",
    ")\n",
    "\n",
    "print(\"\\n---------------\\n\")\n",
    "\n",
    "print(\n",
    "    \"Number of samples in tokenized train dataset after filtering: \",\n",
    "    len(filtered_train_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset after filtering: \",\n",
    "    len(filtered_test_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:20:04.368998200Z",
     "start_time": "2023-11-22T23:20:04.306016300Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    questions = [q.strip() for q in dataset[\"questions\"]]\n",
    "    contexts = [c.strip() for c in dataset[\"original_code\"]]\n",
    "    answers = [c.strip() for c in dataset[\"answers\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        text_target=answers,\n",
    "        max_length=max_length,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:20:19.357521400Z",
     "start_time": "2023-11-22T23:20:04.353377900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af546bd42d346d6867f032e40251ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61758 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a33ca756e21405eaf0880c549198859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6854 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = filtered_train_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_train_dataset.column_names,\n",
    ")\n",
    "tokenized_test_dataset = filtered_test_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_test_dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:20:19.382423200Z",
     "start_time": "2023-11-22T23:20:19.357521400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "training_number = 1\n",
    "\n",
    "model_name = \"python-bart-uncased\"\n",
    "full_model_name = f\"{model_name}-{training_number}\"\n",
    "\n",
    "# Checkpoints\n",
    "checkpoint_filename_template = constants.checkpoint_filename_template\n",
    "checkpoints_path = (\n",
    "    generative_qa_paths.training_checkpoints_dir\n",
    "    / full_model_name\n",
    "    / checkpoint_filename_template\n",
    ")\n",
    "\n",
    "# Hub\n",
    "hub_path = generative_qa_paths.hub_models_location / full_model_name\n",
    "\n",
    "# Saved models\n",
    "saved_models_path = generative_qa_paths.saved_models_dir / full_model_name\n",
    "\n",
    "# Evaluation\n",
    "model_evaluation_dir = generative_qa_paths.model_evaluation_dir / full_model_name\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "train_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:20:29.980365800Z",
     "start_time": "2023-11-22T23:20:19.380423Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForConditionalGeneration: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']\n",
      "- This IS expected if you are initializing TFBartForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBartForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load model for fine-tuning\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:20:31.369012800Z",
     "start_time": "2023-11-22T23:20:29.996021500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# Dataset preparation\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = core_qa_utils.prepare_tf_dataset(\n",
    "    model=model,\n",
    "    hf_dataset=tokenized_train_dataset,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "tf_test_dataset = core_qa_utils.prepare_tf_dataset(\n",
    "    model=model,\n",
    "    hf_dataset=tokenized_test_dataset,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:22:18.790936200Z",
     "start_time": "2023-11-22T23:22:18.775292700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoints_path, verbose=1, save_weights_only=True\n",
    ")\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "# push_to_hub = keras_callbacks.PushToHubCallback(\n",
    "#     output_dir=full_model_name, tokenizer=tokenizer\n",
    "# )\n",
    "\n",
    "time_measure_cb = TimeMeasureCallback()\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint_cb,\n",
    "    early_stop_cb,\n",
    "    # push_to_hub,\n",
    "    time_measure_cb\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:22:19.514518200Z",
     "start_time": "2023-11-22T23:22:19.272315700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "num_train_steps = len(tf_train_dataset) * train_epochs\n",
    "\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:22:20.767076800Z",
     "start_time": "2023-11-22T23:22:20.637596100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bart_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFBartMainLayer)     multiple                  139420416 \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 50265     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,470,681\n",
      "Trainable params: 139,420,416\n",
      "Non-trainable params: 50,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7719/7719 [==============================] - ETA: 0s - loss: 2.7319\n",
      "Epoch 1: saving model to e:\\STUDIA\\IPS\\question-answering\\generative-qa\\training-checkpoints\\python-bart-uncased-1\\cp-01.ckpt\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "7719/7719 [==============================] - 994s 125ms/step - loss: 2.7319\n",
      "Epoch 2/3\n",
      "7719/7719 [==============================] - ETA: 0s - loss: 2.0270\n",
      "Epoch 2: saving model to e:\\STUDIA\\IPS\\question-answering\\generative-qa\\training-checkpoints\\python-bart-uncased-1\\cp-02.ckpt\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "7719/7719 [==============================] - 957s 124ms/step - loss: 2.0270\n",
      "Epoch 3/3\n",
      "7719/7719 [==============================] - ETA: 0s - loss: 1.6172\n",
      "Epoch 3: saving model to e:\\STUDIA\\IPS\\question-answering\\generative-qa\\training-checkpoints\\python-bart-uncased-1\\cp-03.ckpt\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "7719/7719 [==============================] - 948s 123ms/step - loss: 1.6172\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the new data\n",
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    epochs=train_epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best version of the model\n",
    "best_model, best_epoch = core_qa_utils.get_best_model_from_checkpoints(\n",
    "    model, history, model_name=full_model_name, metric=\"loss\", remove_checkpoints=True, model_type=\"generative\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model's weights\n",
    "generative_qa_utils.save_model(best_model, model_name=full_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:24:23.686144Z",
     "start_time": "2023-11-22T23:24:13.544955600Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_weights_model = generative_qa_utils.load_weights_into_model(\n",
    "    model=model, \n",
    "    model_name=full_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T23:22:41.006129700Z",
     "start_time": "2023-11-22T23:22:40.990474400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857/857 [==============================] - 52s 53ms/step - loss: 2.6401\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the best model\n",
    "loaded_model_evaluation = loaded_weights_model.evaluate(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Artur\\.conda\\envs\\question_answering\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.55it/s]\n"
     ]
    }
   ],
   "source": [
    "parts_number = 100\n",
    "\n",
    "test_dataset_pandas = tokenized_test_dataset.to_pandas()\n",
    "test_dataset_array = np.array_split(test_dataset_pandas, parts_number)\n",
    "\n",
    "test_datasets_list = []\n",
    "\n",
    "for row in tqdm(test_dataset_array):\n",
    "    test_datasets_list.append(core_qa_utils.prepare_tf_dataset(\n",
    "        model=model,\n",
    "        hf_dataset=Dataset.from_pandas(row),\n",
    "        collator=data_collator,\n",
    "        batch_size=batch_size,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_and_answers_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:53<00:00,  5.94s/it]\n",
      "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dataframe_with_predictions = generative_qa_utils.get_dataset_dataframe_with_predictions(\n",
    "    model=loaded_weights_model, tokenizer=tokenizer, tf_dataset_list=test_datasets_list, dataframe=questions_and_answers_df, max_length=max_length, index_to_start_from=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>contexts</th>\n",
       "      <th>labels</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What d i d download for given image?</td>\n",
       "      <td>def get_image_files_json image_id files_json g...</td>\n",
       "      <td>the specified layer</td>\n",
       "      <td>image files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What contain the key word?</td>\n",
       "      <td>def has_key k trie return _retrive_branch k tr...</td>\n",
       "      <td>trie</td>\n",
       "      <td>all words in k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do trie contain?</td>\n",
       "      <td>def has_key k trie return _retrive_branch k tr...</td>\n",
       "      <td>the key word</td>\n",
       "      <td>key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the code create?</td>\n",
       "      <td>def create_api_key name description enabled Tr...</td>\n",
       "      <td>an api key given name and description</td>\n",
       "      <td>an api key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What did by loadobjects use the code?</td>\n",
       "      <td>def defaultFactoryMethod rowClass data kw newO...</td>\n",
       "      <td>to create rowobject instances</td>\n",
       "      <td>to set the default factory method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>What does the code convert into an int64index ...</td>\n",
       "      <td>def _dt_to_epoch_ns dt_series index pd to_date...</td>\n",
       "      <td>a timeseries</td>\n",
       "      <td>a datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>What converts into a python list of integers?</td>\n",
       "      <td>def positive_int_list argument if'' in argumen...</td>\n",
       "      <td>a space- or comma - separated list of values</td>\n",
       "      <td>a list of integers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>What does a space- or comma - separated list o...</td>\n",
       "      <td>def positive_int_list argument if'' in argumen...</td>\n",
       "      <td>into a python list of integers</td>\n",
       "      <td>to a positive integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>What do the current user run?</td>\n",
       "      <td>def is_current_user_capable api_name user get_...</td>\n",
       "      <td>a certain api args</td>\n",
       "      <td>the given api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>What does the code make?</td>\n",
       "      <td>def make_fastq_single in_fasta quals out_fp la...</td>\n",
       "      <td>a single fastq file with all the data</td>\n",
       "      <td>a fastq single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            questions  \\\n",
       "0                What d i d download for given image?   \n",
       "1                          What contain the key word?   \n",
       "2                               What do trie contain?   \n",
       "3                          What does the code create?   \n",
       "4               What did by loadobjects use the code?   \n",
       "..                                                ...   \n",
       "63  What does the code convert into an int64index ...   \n",
       "64      What converts into a python list of integers?   \n",
       "65  What does a space- or comma - separated list o...   \n",
       "66                      What do the current user run?   \n",
       "67                           What does the code make?   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   def get_image_files_json image_id files_json g...   \n",
       "1   def has_key k trie return _retrive_branch k tr...   \n",
       "2   def has_key k trie return _retrive_branch k tr...   \n",
       "3   def create_api_key name description enabled Tr...   \n",
       "4   def defaultFactoryMethod rowClass data kw newO...   \n",
       "..                                                ...   \n",
       "63  def _dt_to_epoch_ns dt_series index pd to_date...   \n",
       "64  def positive_int_list argument if'' in argumen...   \n",
       "65  def positive_int_list argument if'' in argumen...   \n",
       "66  def is_current_user_capable api_name user get_...   \n",
       "67  def make_fastq_single in_fasta quals out_fp la...   \n",
       "\n",
       "                                          labels  \\\n",
       "0                            the specified layer   \n",
       "1                                           trie   \n",
       "2                                   the key word   \n",
       "3          an api key given name and description   \n",
       "4                  to create rowobject instances   \n",
       "..                                           ...   \n",
       "63                                  a timeseries   \n",
       "64  a space- or comma - separated list of values   \n",
       "65                into a python list of integers   \n",
       "66                            a certain api args   \n",
       "67         a single fastq file with all the data   \n",
       "\n",
       "                          predictions  \n",
       "0                         image files  \n",
       "1                      all words in k  \n",
       "2                                 key  \n",
       "3                          an api key  \n",
       "4   to set the default factory method  \n",
       "..                                ...  \n",
       "63                         a datetime  \n",
       "64                 a list of integers  \n",
       "65              to a positive integer  \n",
       "66                      the given api  \n",
       "67                     a fastq single  \n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dataframe_with_predictions = generative_qa_utils.split_questions_and_contexts_into_two_columns(dataframe=dataset_dataframe_with_predictions)\n",
    "dataset_dataframe_with_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Artur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Artur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Artur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU:\n",
      " {'bleu': 0.06883854647761965, 'precisions': [0.37727272727272726, 0.15789473684210525, 0.0989010989010989, 0.06382978723404255], 'brevity_penalty': 0.49433322011463077, 'length_ratio': 0.5866666666666667, 'translation_length': 220, 'reference_length': 375} \n",
      "ROGUE:\n",
      " {'rouge1': 0.28053910958322725, 'rouge2': 0.10156889678948502, 'rougeL': 0.2785424116945856, 'rougeLsum': 0.2808231658934983} \n",
      "METEOR:\n",
      " {'meteor': 0.1893512777495596} \n",
      "VERTSCORE:\n",
      " {'precision': [0.8593517541885376, 0.8372496366500854, 0.8991413712501526, 0.9680740833282471, 0.8955209851264954, 0.8728666305541992, 0.8574054837226868, 0.9993814826011658, 0.8920223712921143, 0.9037001729011536, 0.8135514855384827, 0.8349941968917847, 0.9011490941047668, 0.8364732265472412, 0.8376576900482178, 0.8579943180084229, 0.8714290857315063, 0.8299556374549866, 0.9360508918762207, 0.8897707462310791, 0.8863735198974609, 0.8985435962677002, 0.9773555397987366, 0.8346676230430603, 0.8371437191963196, 0.8616835474967957, 0.9598776698112488, 0.9006274938583374, 0.845384955406189, 0.8683315515518188, 0.9212056994438171, 0.7887544631958008, 0.9767535924911499, 0.8769915103912354, 0.8691477179527283, 0.8903490900993347, 0.8648339509963989, 0.9183142185211182, 0.8554022312164307, 0.868155300617218, 0.856937050819397, 0.9185781478881836, 1.0, 0.878899097442627, 0.8465604782104492, 0.8886601328849792, 1.0, 0.8565078377723694, 0.9036709666252136, 0.9174512028694153, 0.8674650192260742, 0.9123052954673767, 0.928578794002533, 0.9288774132728577, 0.8684216141700745, 0.8838220238685608, 0.8531366586685181, 0.8630903959274292, 0.9356205463409424, 0.7960876226425171, 0.8535125851631165, 0.9288078546524048, 0.9015109539031982, 0.8511720895767212, 0.9088727831840515, 0.914991021156311, 0.9264172315597534, 0.887832522392273], 'recall': [0.8299373984336853, 0.8267759084701538, 0.7950611114501953, 0.8824965953826904, 0.9002687931060791, 0.8853532671928406, 0.8441605567932129, 0.9993814826011658, 0.8331125974655151, 0.9285393953323364, 0.8214436769485474, 0.7853129506111145, 0.8363166451454163, 0.8564386367797852, 0.8533532023429871, 0.8602563142776489, 0.8130615949630737, 0.8268154859542847, 0.9187420010566711, 0.8837839365005493, 0.883825421333313, 0.8313966989517212, 0.9554844498634338, 0.8698939085006714, 0.846394419670105, 0.8601984977722168, 0.9107732176780701, 0.8948682546615601, 0.8504427671432495, 0.8397971391677856, 0.8669025301933289, 0.794230580329895, 0.9423469305038452, 0.8250539898872375, 0.8386808037757874, 0.8676639795303345, 0.7898733615875244, 0.8920794129371643, 0.8618463277816772, 0.8613329529762268, 0.8328409194946289, 0.8131642937660217, 1.0, 0.929397702217102, 0.7822669148445129, 0.8623049855232239, 1.0, 0.8546414971351624, 0.8332909345626831, 0.902221143245697, 0.8830366134643555, 0.9083882570266724, 0.8893831968307495, 0.9336082935333252, 0.8962918519973755, 0.9230642914772034, 0.8135843873023987, 0.8689708709716797, 0.903965175151825, 0.759819746017456, 0.8325663805007935, 0.9172403812408447, 0.9096381068229675, 0.8436465263366699, 0.8094572424888611, 0.8946397304534912, 0.9180039763450623, 0.8571550250053406], 'f1': [0.844388484954834, 0.8319798111915588, 0.8439043164253235, 0.9233066439628601, 0.8978886604309082, 0.8790655732154846, 0.8507314920425415, 0.9993814826011658, 0.86156165599823, 0.9159513711929321, 0.8174785375595093, 0.8093918561935425, 0.8675233125686646, 0.8463382124900818, 0.8454325795173645, 0.8591238260269165, 0.8412341475486755, 0.8283825516700745, 0.9273157119750977, 0.8867672085762024, 0.8850976228713989, 0.8636670112609863, 0.9662962555885315, 0.8519167900085449, 0.8417436480522156, 0.8609403371810913, 0.9346809387207031, 0.8977386355400085, 0.8479063510894775, 0.8538259863853455, 0.8932295441627502, 0.7914830446243286, 0.9592418074607849, 0.85023033618927, 0.8536425232887268, 0.8788601756095886, 0.8256556987762451, 0.9050067663192749, 0.8586122393608093, 0.864730715751648, 0.8447172045707703, 0.8626629114151001, 1.0, 0.9034432768821716, 0.813144862651825, 0.8752842545509338, 1.0, 0.8555736541748047, 0.8670551180839539, 0.9097724556922913, 0.8751815557479858, 0.9103425741195679, 0.9085584878921509, 0.9312368631362915, 0.8821366429328918, 0.9030170440673828, 0.8328911662101746, 0.866020679473877, 0.9195204973220825, 0.7775309681892395, 0.8429093360900879, 0.9229878783226013, 0.9055562615394592, 0.8473926186561584, 0.8562890887260437, 0.9047009348869324, 0.9221914410591125, 0.8722241520881653], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.35.0)'} \n",
      "SCRABLEU:\n",
      " {'score': 6.883854647761964, 'counts': [83, 24, 9, 3], 'totals': [220, 152, 91, 47], 'precisions': [37.72727272727273, 15.789473684210526, 9.89010989010989, 6.382978723404255], 'bp': 0.49433322011463077, 'sys_len': 220, 'ref_len': 375}\n"
     ]
    }
   ],
   "source": [
    "bleu_result, rogue_result, meteor_result, bertscore_result, sacrebleu_result = generative_qa_utils.get_metrics(dataset_dataframe_with_predictions)\n",
    "print(\n",
    "    \"BLEU:\\n\",\n",
    "    bleu_result,\n",
    "    \"\\nROGUE:\\n\",\n",
    "    rogue_result,\n",
    "    \"\\nMETEOR:\\n\",\n",
    "    meteor_result,\n",
    "    \"\\nVERTSCORE:\\n\",\n",
    "    bertscore_result,\n",
    "    \"\\nSCRABLEU:\\n\",\n",
    "    sacrebleu_result,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all relevant training and evaluation metrics to a json file.\n",
    "evaluation_data = {\n",
    "    \"training\": {\n",
    "        \"metrics\": 'history.history',\n",
    "        \"attempted_epochs\": 'train_epochs',\n",
    "        \"best_epoch\": 'best_epoch',\n",
    "        \"training_time\": 'time_measure_cb.total_training_time()',\n",
    "        \"gpu\": core_qa_utils.get_gpu_name(),\n",
    "    },\n",
    "    \"test_set\": {\n",
    "        \"loss\": 'loaded_model_evaluation',\n",
    "        \"bleu\": bleu_result,\n",
    "        \"rogue\": rogue_result,\n",
    "        \"meteor\": meteor_result,\n",
    "        \"bertscore\": bertscore_result,\n",
    "        \"sacrebleu\": sacrebleu_result,\n",
    "    },\n",
    "}\n",
    "\n",
    "core_qa_utils.save_dict_as_json(\n",
    "    evaluation_data, dir_path=model_evaluation_dir, filename=\"evaluation_data.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>contexts</th>\n",
       "      <th>labels</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does the code designate?</td>\n",
       "      <td>def set_time_server time_server 'time apple co...</td>\n",
       "      <td>a network time server</td>\n",
       "      <td>the correct time server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does this function create as defined in t...</td>\n",
       "      <td>def keyboard_role name rawtext text lineno inl...</td>\n",
       "      <td>an inline console input block</td>\n",
       "      <td>a keyboard role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does the code remove?</td>\n",
       "      <td>def subtract d1 d2 warnings warn 'deprecated' ...</td>\n",
       "      <td>all items from d1 whose key occurs in d2</td>\n",
       "      <td>all keys from d1 from d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the code return?</td>\n",
       "      <td>def get_http_expiry _Expirestype _num if _Expi...</td>\n",
       "      <td>the future date</td>\n",
       "      <td>an http expire date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does the tokenize ( ) function accept?</td>\n",
       "      <td>def tokenize readline tokeneater printtoken tr...</td>\n",
       "      <td>two parameters : one representing the input st...</td>\n",
       "      <td>a readline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What does the code build?</td>\n",
       "      <td>def get_dynamic_link_map for_delete False if g...</td>\n",
       "      <td>a map of all dynamically linked tables</td>\n",
       "      <td>a dynamic link map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What does the code rebuild from the file system?</td>\n",
       "      <td>def Rebuild verbose 1 clsidToTypelib clear inf...</td>\n",
       "      <td>the cache indexes</td>\n",
       "      <td>the cache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When did returns use luns?</td>\n",
       "      <td>def _get_used_lun_ids_for_mappings mappings us...</td>\n",
       "      <td>when provided with mappings</td>\n",
       "      <td>when mappings are used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the docs build?</td>\n",
       "      <td>def build_pdf branch os chdir os path join git...</td>\n",
       "      <td>using sphinx in the buildenv virtualenv</td>\n",
       "      <td>using sphinx - build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What does this function perform on cpu?</td>\n",
       "      <td>def svd a full_matrices 1 compute_uv 1 return ...</td>\n",
       "      <td>the svd</td>\n",
       "      <td>svd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What does the code prepare?</td>\n",
       "      <td>@event u'manager startup' def init_parsers man...</td>\n",
       "      <td>our list of parsing plugins and default parsers</td>\n",
       "      <td>the list of valid parser types</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Where did the first element find?</td>\n",
       "      <td>def find predicate seq for element in seq if p...</td>\n",
       "      <td>in the sequence that meets the predicate</td>\n",
       "      <td>in seq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What used to create rowobject instances the code?</td>\n",
       "      <td>def defaultFactoryMethod rowClass data kw newO...</td>\n",
       "      <td>by loadobjects</td>\n",
       "      <td>the default factory method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What does the code add?</td>\n",
       "      <td>def get_http_expiry _Expirestype _num if _Expi...</td>\n",
       "      <td>the given number of days on to the current date</td>\n",
       "      <td>an http expire date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What does the code restore at the location giv...</td>\n",
       "      <td>@taskdef mongorestore ctx path drop False db s...</td>\n",
       "      <td>the running osf database</td>\n",
       "      <td>the mongore store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How does application run?</td>\n",
       "      <td>def capture_output environ start_response appl...</td>\n",
       "      <td>with environ and start_response</td>\n",
       "      <td>in a wsgi - compatible environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>When do function implement matlabs imresize fu...</td>\n",
       "      <td>def imresize img cropped_width cropped_height ...</td>\n",
       "      <td>when scaling down the image</td>\n",
       "      <td>at runtime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Where does this function perform the svd?</td>\n",
       "      <td>def svd a full_matrices 1 compute_uv 1 return ...</td>\n",
       "      <td>on cpu</td>\n",
       "      <td>on a matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What did by loadobjects use the code?</td>\n",
       "      <td>def defaultFactoryMethod rowClass data kw newO...</td>\n",
       "      <td>to create rowobject instances</td>\n",
       "      <td>to set the default factory method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What do remaining queens place?</td>\n",
       "      <td>def place board queens r c d g if not queens s...</td>\n",
       "      <td>remaining rows</td>\n",
       "      <td>the board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How are all nodes nt processed?</td>\n",
       "      <td>def initial_has_dependencies tree to_process h...</td>\n",
       "      <td>up front</td>\n",
       "      <td>in to_process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What contains multiple relation types when?</td>\n",
       "      <td>@pytest mark django_dbdef test_cross_sell_plug...</td>\n",
       "      <td>shop</td>\n",
       "      <td>a product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What does a space- or comma - separated list o...</td>\n",
       "      <td>def positive_int_list argument if'' in argumen...</td>\n",
       "      <td>into a python list of integers</td>\n",
       "      <td>to a positive integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Where did the docs version string report?</td>\n",
       "      <td>def get_rtd_version version None version_str g...</td>\n",
       "      <td>in the rtd site</td>\n",
       "      <td>in the latest version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What does the code convert into an int64index ...</td>\n",
       "      <td>def _dt_to_epoch_ns dt_series index pd to_date...</td>\n",
       "      <td>a timeseries</td>\n",
       "      <td>a datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What places remaining rows?</td>\n",
       "      <td>def place board queens r c d g if not queens s...</td>\n",
       "      <td>remaining queens</td>\n",
       "      <td>a board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What d i d download for given image?</td>\n",
       "      <td>def get_image_files_json image_id files_json g...</td>\n",
       "      <td>the specified layer</td>\n",
       "      <td>image files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What are painted an rgb image?</td>\n",
       "      <td>def label2rgb label image None colors None alp...</td>\n",
       "      <td>color - coded labels</td>\n",
       "      <td>label and color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What does the code determine from an ismaster ...</td>\n",
       "      <td>def _get_server_type doc if not doc get 'ok' r...</td>\n",
       "      <td>the server type</td>\n",
       "      <td>the server type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What have dependencies to_process : set of nod...</td>\n",
       "      <td>def initial_has_dependencies tree to_process h...</td>\n",
       "      <td>all nodes that are nt processed up front stll</td>\n",
       "      <td>n nodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What converts into a python list of integers?</td>\n",
       "      <td>def positive_int_list argument if'' in argumen...</td>\n",
       "      <td>a space- or comma - separated list of values</td>\n",
       "      <td>a list of integers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Where does the code run an esxcli command dire...</td>\n",
       "      <td>@depends HAS_ESX_CLI def esxcli_cmd cmd_str ho...</td>\n",
       "      <td>on the host or list of hosts</td>\n",
       "      <td>in a vmware environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What defined in this package?</td>\n",
       "      <td>def load_base_library library dict library upd...</td>\n",
       "      <td>load style library</td>\n",
       "      <td>the base library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What do the current user run?</td>\n",
       "      <td>def is_current_user_capable api_name user get_...</td>\n",
       "      <td>a certain api args</td>\n",
       "      <td>the given api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What does the code create?</td>\n",
       "      <td>def create_normal_player session name password...</td>\n",
       "      <td>a player with the given name and password</td>\n",
       "      <td>a normal player</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>What do function implement when scaling down t...</td>\n",
       "      <td>def imresize img cropped_width cropped_height ...</td>\n",
       "      <td>matlabs imresize functionality default behavio...</td>\n",
       "      <td>immediate scaling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Where do sphinx use?</td>\n",
       "      <td>def build_pdf branch os chdir os path join git...</td>\n",
       "      <td>in the buildenv virtualenv</td>\n",
       "      <td>on a local branch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What is using in the buildenv virtualenv?</td>\n",
       "      <td>def build_pdf branch os chdir os path join git...</td>\n",
       "      <td>sphinx</td>\n",
       "      <td>latexpdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>How does the code determine the server type?</td>\n",
       "      <td>def _get_server_type doc if not doc get 'ok' r...</td>\n",
       "      <td>from an ismaster response</td>\n",
       "      <td>by doc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What does the code run on the host or list of ...</td>\n",
       "      <td>@depends HAS_ESX_CLI def esxcli_cmd cmd_str ho...</td>\n",
       "      <td>an esxcli command</td>\n",
       "      <td>the esxcli command</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>What does the code get?</td>\n",
       "      <td>def get_random_user_agent return random choice...</td>\n",
       "      <td>a random user agent string</td>\n",
       "      <td>a random user agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>What accepts two parameters : one representing...</td>\n",
       "      <td>def tokenize readline tokeneater printtoken tr...</td>\n",
       "      <td>the tokenize ( ) function</td>\n",
       "      <td>a loop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What does shop contain when?</td>\n",
       "      <td>@pytest mark django_dbdef test_cross_sell_plug...</td>\n",
       "      <td>multiple relation types</td>\n",
       "      <td>crosssell plugin type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What does the code compare for tests?</td>\n",
       "      <td>def subrange_exercise mult lb ub m MultisetPar...</td>\n",
       "      <td>filter - based and more optimized subrange imp...</td>\n",
       "      <td>the subrange exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Where did load style library define?</td>\n",
       "      <td>def load_base_library library dict library upd...</td>\n",
       "      <td>in this package</td>\n",
       "      <td>in base library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What does the code create?</td>\n",
       "      <td>def create_api_key name description enabled Tr...</td>\n",
       "      <td>an api key given name and description</td>\n",
       "      <td>an api key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What does the code get from the filename in th...</td>\n",
       "      <td>def getAlterationLines fileName return archive...</td>\n",
       "      <td>the text lines</td>\n",
       "      <td>the text lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Where does the code restore the running osf da...</td>\n",
       "      <td>@taskdef mongorestore ctx path drop False db s...</td>\n",
       "      <td>at the location given its argument</td>\n",
       "      <td>on the mongore server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>What does the code create?</td>\n",
       "      <td>def createURLs urls []for x in range 0 randint...</td>\n",
       "      <td>some urls</td>\n",
       "      <td>a list of urls for the debug api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>When did restful crud controller need?</td>\n",
       "      <td>def skill if auth permission format 'popup' re...</td>\n",
       "      <td>when skill add form embedded in default / pers...</td>\n",
       "      <td>previously</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            questions  \\\n",
       "0                       What does the code designate?   \n",
       "1   What does this function create as defined in t...   \n",
       "2                          What does the code remove?   \n",
       "3                          What does the code return?   \n",
       "4         What does the tokenize ( ) function accept?   \n",
       "5                           What does the code build?   \n",
       "6    What does the code rebuild from the file system?   \n",
       "7                          When did returns use luns?   \n",
       "8                            How does the docs build?   \n",
       "9             What does this function perform on cpu?   \n",
       "10                        What does the code prepare?   \n",
       "11                  Where did the first element find?   \n",
       "12  What used to create rowobject instances the code?   \n",
       "13                            What does the code add?   \n",
       "14  What does the code restore at the location giv...   \n",
       "15                          How does application run?   \n",
       "16  When do function implement matlabs imresize fu...   \n",
       "17          Where does this function perform the svd?   \n",
       "18              What did by loadobjects use the code?   \n",
       "19                    What do remaining queens place?   \n",
       "20                    How are all nodes nt processed?   \n",
       "21        What contains multiple relation types when?   \n",
       "22  What does a space- or comma - separated list o...   \n",
       "23          Where did the docs version string report?   \n",
       "24  What does the code convert into an int64index ...   \n",
       "25                        What places remaining rows?   \n",
       "26               What d i d download for given image?   \n",
       "27                     What are painted an rgb image?   \n",
       "28  What does the code determine from an ismaster ...   \n",
       "29  What have dependencies to_process : set of nod...   \n",
       "30      What converts into a python list of integers?   \n",
       "31  Where does the code run an esxcli command dire...   \n",
       "32                      What defined in this package?   \n",
       "33                      What do the current user run?   \n",
       "34                         What does the code create?   \n",
       "35  What do function implement when scaling down t...   \n",
       "36                               Where do sphinx use?   \n",
       "37          What is using in the buildenv virtualenv?   \n",
       "38       How does the code determine the server type?   \n",
       "39  What does the code run on the host or list of ...   \n",
       "40                            What does the code get?   \n",
       "41  What accepts two parameters : one representing...   \n",
       "42                       What does shop contain when?   \n",
       "43              What does the code compare for tests?   \n",
       "44               Where did load style library define?   \n",
       "45                         What does the code create?   \n",
       "46  What does the code get from the filename in th...   \n",
       "47  Where does the code restore the running osf da...   \n",
       "48                         What does the code create?   \n",
       "49             When did restful crud controller need?   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   def set_time_server time_server 'time apple co...   \n",
       "1   def keyboard_role name rawtext text lineno inl...   \n",
       "2   def subtract d1 d2 warnings warn 'deprecated' ...   \n",
       "3   def get_http_expiry _Expirestype _num if _Expi...   \n",
       "4   def tokenize readline tokeneater printtoken tr...   \n",
       "5   def get_dynamic_link_map for_delete False if g...   \n",
       "6   def Rebuild verbose 1 clsidToTypelib clear inf...   \n",
       "7   def _get_used_lun_ids_for_mappings mappings us...   \n",
       "8   def build_pdf branch os chdir os path join git...   \n",
       "9   def svd a full_matrices 1 compute_uv 1 return ...   \n",
       "10  @event u'manager startup' def init_parsers man...   \n",
       "11  def find predicate seq for element in seq if p...   \n",
       "12  def defaultFactoryMethod rowClass data kw newO...   \n",
       "13  def get_http_expiry _Expirestype _num if _Expi...   \n",
       "14  @taskdef mongorestore ctx path drop False db s...   \n",
       "15  def capture_output environ start_response appl...   \n",
       "16  def imresize img cropped_width cropped_height ...   \n",
       "17  def svd a full_matrices 1 compute_uv 1 return ...   \n",
       "18  def defaultFactoryMethod rowClass data kw newO...   \n",
       "19  def place board queens r c d g if not queens s...   \n",
       "20  def initial_has_dependencies tree to_process h...   \n",
       "21  @pytest mark django_dbdef test_cross_sell_plug...   \n",
       "22  def positive_int_list argument if'' in argumen...   \n",
       "23  def get_rtd_version version None version_str g...   \n",
       "24  def _dt_to_epoch_ns dt_series index pd to_date...   \n",
       "25  def place board queens r c d g if not queens s...   \n",
       "26  def get_image_files_json image_id files_json g...   \n",
       "27  def label2rgb label image None colors None alp...   \n",
       "28  def _get_server_type doc if not doc get 'ok' r...   \n",
       "29  def initial_has_dependencies tree to_process h...   \n",
       "30  def positive_int_list argument if'' in argumen...   \n",
       "31  @depends HAS_ESX_CLI def esxcli_cmd cmd_str ho...   \n",
       "32  def load_base_library library dict library upd...   \n",
       "33  def is_current_user_capable api_name user get_...   \n",
       "34  def create_normal_player session name password...   \n",
       "35  def imresize img cropped_width cropped_height ...   \n",
       "36  def build_pdf branch os chdir os path join git...   \n",
       "37  def build_pdf branch os chdir os path join git...   \n",
       "38  def _get_server_type doc if not doc get 'ok' r...   \n",
       "39  @depends HAS_ESX_CLI def esxcli_cmd cmd_str ho...   \n",
       "40  def get_random_user_agent return random choice...   \n",
       "41  def tokenize readline tokeneater printtoken tr...   \n",
       "42  @pytest mark django_dbdef test_cross_sell_plug...   \n",
       "43  def subrange_exercise mult lb ub m MultisetPar...   \n",
       "44  def load_base_library library dict library upd...   \n",
       "45  def create_api_key name description enabled Tr...   \n",
       "46  def getAlterationLines fileName return archive...   \n",
       "47  @taskdef mongorestore ctx path drop False db s...   \n",
       "48  def createURLs urls []for x in range 0 randint...   \n",
       "49  def skill if auth permission format 'popup' re...   \n",
       "\n",
       "                                               labels  \\\n",
       "0                               a network time server   \n",
       "1                       an inline console input block   \n",
       "2            all items from d1 whose key occurs in d2   \n",
       "3                                     the future date   \n",
       "4   two parameters : one representing the input st...   \n",
       "5              a map of all dynamically linked tables   \n",
       "6                                   the cache indexes   \n",
       "7                         when provided with mappings   \n",
       "8             using sphinx in the buildenv virtualenv   \n",
       "9                                             the svd   \n",
       "10    our list of parsing plugins and default parsers   \n",
       "11           in the sequence that meets the predicate   \n",
       "12                                     by loadobjects   \n",
       "13    the given number of days on to the current date   \n",
       "14                           the running osf database   \n",
       "15                    with environ and start_response   \n",
       "16                        when scaling down the image   \n",
       "17                                             on cpu   \n",
       "18                      to create rowobject instances   \n",
       "19                                     remaining rows   \n",
       "20                                           up front   \n",
       "21                                               shop   \n",
       "22                     into a python list of integers   \n",
       "23                                    in the rtd site   \n",
       "24                                       a timeseries   \n",
       "25                                   remaining queens   \n",
       "26                                the specified layer   \n",
       "27                               color - coded labels   \n",
       "28                                    the server type   \n",
       "29      all nodes that are nt processed up front stll   \n",
       "30       a space- or comma - separated list of values   \n",
       "31                       on the host or list of hosts   \n",
       "32                                 load style library   \n",
       "33                                 a certain api args   \n",
       "34          a player with the given name and password   \n",
       "35  matlabs imresize functionality default behavio...   \n",
       "36                         in the buildenv virtualenv   \n",
       "37                                             sphinx   \n",
       "38                          from an ismaster response   \n",
       "39                                  an esxcli command   \n",
       "40                         a random user agent string   \n",
       "41                          the tokenize ( ) function   \n",
       "42                            multiple relation types   \n",
       "43  filter - based and more optimized subrange imp...   \n",
       "44                                    in this package   \n",
       "45              an api key given name and description   \n",
       "46                                     the text lines   \n",
       "47                 at the location given its argument   \n",
       "48                                          some urls   \n",
       "49  when skill add form embedded in default / pers...   \n",
       "\n",
       "                           predictions  \n",
       "0              the correct time server  \n",
       "1                      a keyboard role  \n",
       "2             all keys from d1 from d2  \n",
       "3                  an http expire date  \n",
       "4                           a readline  \n",
       "5                   a dynamic link map  \n",
       "6                            the cache  \n",
       "7               when mappings are used  \n",
       "8                 using sphinx - build  \n",
       "9                                  svd  \n",
       "10      the list of valid parser types  \n",
       "11                              in seq  \n",
       "12          the default factory method  \n",
       "13                 an http expire date  \n",
       "14                   the mongore store  \n",
       "15  in a wsgi - compatible environment  \n",
       "16                          at runtime  \n",
       "17                         on a matrix  \n",
       "18   to set the default factory method  \n",
       "19                           the board  \n",
       "20                       in to_process  \n",
       "21                           a product  \n",
       "22               to a positive integer  \n",
       "23               in the latest version  \n",
       "24                          a datetime  \n",
       "25                             a board  \n",
       "26                         image files  \n",
       "27                     label and color  \n",
       "28                     the server type  \n",
       "29                             n nodes  \n",
       "30                  a list of integers  \n",
       "31             in a vmware environment  \n",
       "32                    the base library  \n",
       "33                       the given api  \n",
       "34                     a normal player  \n",
       "35                   immediate scaling  \n",
       "36                   on a local branch  \n",
       "37                            latexpdf  \n",
       "38                              by doc  \n",
       "39                  the esxcli command  \n",
       "40                 a random user agent  \n",
       "41                              a loop  \n",
       "42               crosssell plugin type  \n",
       "43               the subrange exercise  \n",
       "44                     in base library  \n",
       "45                          an api key  \n",
       "46                      the text lines  \n",
       "47               on the mongore server  \n",
       "48    a list of urls for the debug api  \n",
       "49                          previously  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_for_manual_check = 50\n",
    "\n",
    "predictions_for_manual_check = dataset_dataframe_with_predictions.sample(n = samples_for_manual_check).reset_index(drop=True)\n",
    "predictions_for_manual_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dataframe_with_predictions.to_csv(\n",
    "    model_evaluation_dir / \"test_set_sample_generation.csv\", index=True, index_label=\"index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "question_answering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
