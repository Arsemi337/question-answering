{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model details\n",
    "***Used base model***: bert-base-uncased\n",
    "***Used dataset***: SQuAD\n",
    "***Batch size***: 4\n",
    "***Early stopping patience***: 2\n",
    "***Early stopping monitor***: val loss\n",
    "***Datasets***: Train: original 80k train samples, Val: remaining 7599 samples, Test: original 10570 samples\n",
    "***Loss function***: Sparse categorical crossentropy\n",
    "***Attempted train epochs***: 10\n",
    "***Initial learning rate***: 2e-5\n",
    "***End learning rate***: 0\n",
    "***Additional info***: Makes use of stride mechanism, smart evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83cff6ac1d025261"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForQuestionAnswering,\n",
    "    DefaultDataCollator,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from question_answering.constants import constants\n",
    "from question_answering.utils import core_qa_utils\n",
    "from question_answering.utils.extractive_qa import model_management\n",
    "from question_answering.paths import extractive_qa_paths\n",
    "import ipynbname\n",
    "from question_answering.keras_callbacks.time_measure_callback import TimeMeasureCallback\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T20:51:54.022317400Z",
     "start_time": "2023-11-23T20:51:53.997812Z"
    }
   },
   "id": "143ae7b201b745c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "319fae1ec8d8aeca"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "raw_train_dataset, raw_test_dataset = core_qa_utils.load_datasets_from_json(\n",
    "    dataset_path=extractive_qa_paths.squad_dataset_dir,\n",
    "    filenames=[\"original_train.json\", \"original_test.json\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T17:50:33.036248500Z",
     "start_time": "2023-11-23T17:50:33.004310500Z"
    }
   },
   "id": "da69620bc10a6a32"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_dataset = raw_train_dataset.select(range(80000))\n",
    "val_dataset = raw_train_dataset.select(range(80000, 87599))\n",
    "test_dataset = raw_test_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T17:51:25.072803100Z",
     "start_time": "2023-11-23T17:51:25.037297200Z"
    }
   },
   "id": "ed5d0ed8c5547f57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da3e7b5af4497f6"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:18.699077900Z",
     "start_time": "2023-11-23T18:53:18.140433300Z"
    }
   },
   "id": "edf9671bd665638c"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:18.716269800Z",
     "start_time": "2023-11-23T18:53:18.701152200Z"
    }
   },
   "id": "4f6a4517ce584313"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def preprocess_training_dataset(dataset):\n",
    "    questions = [q.strip() for q in dataset[\"question\"]]\n",
    "    contexts = [c.strip() for c in dataset[\"context\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answer_starts = dataset[\"answer_start\"]\n",
    "    answer_texts = dataset[\"answer_text\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer_start = answer_starts[sample_idx][0]\n",
    "        answer_text = answer_texts[sample_idx][0]\n",
    "        start_char = answer_start\n",
    "        end_char = start_char + len(answer_text)\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end TOKEN positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:18.958550200Z",
     "start_time": "2023-11-23T18:53:18.929078500Z"
    }
   },
   "id": "cad8f242d0b50eed"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def preprocess_test_samples(dataset):\n",
    "    questions = [q.strip() for q in dataset[\"question\"]]\n",
    "    contexts = [c.strip() for c in dataset[\"context\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(dataset[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:19.435344500Z",
     "start_time": "2023-11-23T18:53:19.423829600Z"
    }
   },
   "id": "b359e7b481a7d4ce"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/7599 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "735ab783a38b431a935d49c75a881f81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(\n",
    "    preprocess_training_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names)\n",
    "tokenized_val_dataset = val_dataset.map(\n",
    "    preprocess_training_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=val_dataset.column_names\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:22.926005100Z",
     "start_time": "2023-11-23T18:53:20.291254200Z"
    }
   },
   "id": "113ae6969c1a6d73"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "tokenized_test_dataset = test_dataset.map(\n",
    "    preprocess_test_samples,\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:22.959067700Z",
     "start_time": "2023-11-23T18:53:22.929003700Z"
    }
   },
   "id": "c3bc78b775df21d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e24ae61de94eec67"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "full_model_name = \"-\".join(ipynbname.name().split(\"_\"))\n",
    "\n",
    "# Checkpoints\n",
    "checkpoint_filename_template = constants.checkpoint_filename_template\n",
    "checkpoints_path = (\n",
    "        extractive_qa_paths.training_checkpoints_dir\n",
    "        / full_model_name\n",
    "        / checkpoint_filename_template\n",
    ")\n",
    "\n",
    "# Saved models\n",
    "saved_models_path = extractive_qa_paths.saved_models_dir / full_model_name\n",
    "\n",
    "# Evaluation\n",
    "model_evaluation_dir = extractive_qa_paths.model_evaluation_dir / full_model_name\n",
    "figures_dir = model_evaluation_dir / constants.figures_dir_name\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "train_epochs = 10\n",
    "initial_learning_rate = 2e-5\n",
    "end_learning_rate = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:23.053302800Z",
     "start_time": "2023-11-23T18:53:23.027428900Z"
    }
   },
   "id": "9d6bd90e1524acce"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = core_qa_utils.convert_to_tf_dataset(\n",
    "    hf_dataset=tokenized_train_dataset,\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"start_positions\", \"end_positions\"],\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "tf_val_dataset = core_qa_utils.convert_to_tf_dataset(\n",
    "    hf_dataset=tokenized_val_dataset,\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"start_positions\", \"end_positions\"],\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "tf_test_dataset = core_qa_utils.convert_to_tf_dataset(\n",
    "    hf_dataset=tokenized_test_dataset,\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
    "    label_cols=None,\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:23.987265800Z",
     "start_time": "2023-11-23T18:53:23.902740300Z"
    }
   },
   "id": "6c30c4974fcda728"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:28.998712800Z",
     "start_time": "2023-11-23T18:53:27.055355700Z"
    }
   },
   "id": "96b41a5ca6e91330"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoints_path, verbose=1, save_weights_only=True\n",
    ")\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "time_measure_cb = TimeMeasureCallback()\n",
    "\n",
    "callbacks = [checkpoint_cb, early_stop_cb, time_measure_cb]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:30.182094900Z",
     "start_time": "2023-11-23T18:53:30.163076Z"
    }
   },
   "id": "321427476036efa6"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "num_train_steps = len(tf_train_dataset) * train_epochs\n",
    "\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    end_learning_rate=end_learning_rate,\n",
    "    decay_steps=num_train_steps,\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:30.540552200Z",
     "start_time": "2023-11-23T18:53:30.514019100Z"
    }
   },
   "id": "af6bf40a502b652"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T18:53:31.780269Z",
     "start_time": "2023-11-23T18:53:31.758015Z"
    }
   },
   "id": "636433b6af725ae2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7584f9b5183dda1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_val_dataset,\n",
    "    epochs=train_epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3421408a9601d02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "core_qa_utils.save_dict_as_json(\n",
    "    dictionary=history.history,\n",
    "    dir_path=model_evaluation_dir,\n",
    "    filename=\"history.json\"\n",
    ")\n",
    "\n",
    "history = core_qa_utils.read_json_as_dict(model_evaluation_dir / \"history.json\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b91fb9ae4750328"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot training figures\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"start_logits_accuracy\", \"val_start_logits_accuracy\"],\n",
    "    title=\"Model start logits accuracy\",\n",
    "    y_label=\"Accuracy\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_start_accuracy.png\",\n",
    ")\n",
    "\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"end_logits_accuracy\", \"val_end_logits_accuracy\"],\n",
    "    title=\"Model end logits accuracy\",\n",
    "    y_label=\"Accuracy\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_end_accuracy.png\",\n",
    ")\n",
    "\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"loss\", \"val_loss\"],\n",
    "    title=\"Model loss\",\n",
    "    y_label=\"Loss\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_loss.png\",\n",
    ")\n",
    "\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"start_logits_loss\", \"val_start_logits_loss\"],\n",
    "    title=\"Model start logits loss\",\n",
    "    y_label=\"Loss\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_start_loss.png\",\n",
    ")\n",
    "\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"end_logits_loss\", \"val_end_logits_loss\"],\n",
    "    title=\"Model end logits loss\",\n",
    "    y_label=\"Loss\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_end_loss.png\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed9d224003cfa179"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving model's best version"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19df1984512a2af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_epoch = core_qa_utils.get_best_epoch(\n",
    "    history=history,\n",
    "    metric=\"val_loss\",\n",
    "    metric_evaluator=\"min\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39192c814285200c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get best version of the model\n",
    "best_model = model_management.load_best_model_from_checkpoints(\n",
    "    model=model,\n",
    "    model_name=full_model_name,\n",
    "    epoch=best_epoch,\n",
    "    remove_checkpoints=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7db0c3601d62f0b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save best model's weights\n",
    "model_management.save_model(model=best_model, model_name=full_model_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed523f8f2ba9175e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3c183e0c102b94c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model = model_management.load_model(\n",
    "    model_checkpoint=model_checkpoint,\n",
    "    model_name=full_model_name\n",
    ")\n",
    "loaded_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a01dda5287e73c95"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2696/2696 [==============================] - 113s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(tf_test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T19:00:00.347749500Z",
     "start_time": "2023-11-23T18:58:05.494127300Z"
    }
   },
   "id": "6fb13aca7282421"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "output_start_logits = output[\"start_logits\"]\n",
    "output_end_logits = output[\"end_logits\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T20:35:50.229743300Z",
     "start_time": "2023-11-23T20:35:50.213227500Z"
    }
   },
   "id": "5bb21fb01d231066"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def convert_predictions_to_texts(start_logits, end_logits, features, examples):\n",
    "    example_to_features = defaultdict(list)\n",
    "\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_id = feature[\"example_id\"]\n",
    "        example_to_features[example_id].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            best_start_indices = np.argsort(start_logit)[-1: -n_best - 1: -1].tolist()\n",
    "            best_end_indices = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "            for start_index in best_start_indices:\n",
    "                for end_index in best_end_indices:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                            end_index < start_index\n",
    "                            or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[\n",
    "                                offsets[start_index][0]: offsets[end_index][1]\n",
    "                                ],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(best_answer[\"text\"])\n",
    "        else:\n",
    "            predicted_answers.append(\"\")\n",
    "\n",
    "    return predicted_answers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T20:35:50.848629200Z",
     "start_time": "2023-11-23T20:35:50.826348500Z"
    }
   },
   "id": "a5dfe95acf09ae16"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10570 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6006e74fe2384ec7b701eaa86dc09cfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_texts = convert_predictions_to_texts(\n",
    "    start_logits=output_start_logits,\n",
    "    end_logits=output_end_logits,\n",
    "    features=tokenized_test_dataset,\n",
    "    examples=test_dataset\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T20:36:13.488297600Z",
     "start_time": "2023-11-23T20:35:51.748817200Z"
    }
   },
   "id": "1fe661a180176dad"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "model_predictions = test_dataset.add_column(\"prediction_text\", predicted_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T20:36:13.532084900Z",
     "start_time": "2023-11-23T20:36:13.503312400Z"
    }
   },
   "id": "72649cd6567ff0fc"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "{'exact_match': 16.575212866603596, 'f1': 25.251050518649045}"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_squad_exact_match(ids: list[str], answers: list[dict], predicted_texts: list[str]):\n",
    "    metric = evaluate.load(\"squad\")\n",
    "\n",
    "    predictions = []\n",
    "    references = []\n",
    "    for i, example_id in enumerate(ids):\n",
    "        predictions.append({\"id\": example_id, \"prediction_text\": predicted_texts[i]})\n",
    "        references.append({\"id\": example_id, \"answers\": answers[i]})\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "\n",
    "calculate_squad_exact_match(\n",
    "    ids=model_predictions['id'],\n",
    "    answers=model_predictions['answers'],\n",
    "    predicted_texts=predicted_texts\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T20:38:47.737785900Z",
     "start_time": "2023-11-23T20:36:13.703139400Z"
    }
   },
   "id": "e2d2d939bb831246"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10570 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb22789b1a0041df8bf305de23944113"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'exact_match': 13.604541154210029, 'f1': 23.46810143445196}"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    metric = evaluate.load(\"squad\")\n",
    "\n",
    "    example_to_features = defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_id = feature[\"example_id\"]\n",
    "        example_to_features[example_id].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            best_start_indices = np.argsort(start_logit)[-1: -n_best - 1: -1].tolist()\n",
    "            best_start_indices = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "            for start_index in best_start_indices:\n",
    "                for end_index in best_start_indices:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                            end_index < start_index\n",
    "                            or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[\n",
    "                                offsets[start_index][0]: offsets[end_index][1]\n",
    "                                ],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [\n",
    "        {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples\n",
    "    ]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)\n",
    "\n",
    "\n",
    "compute_metrics(\n",
    "    output_start_logits,\n",
    "    output_end_logits,\n",
    "    tokenized_test_dataset,\n",
    "    test_dataset,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T20:35:34.554215500Z",
     "start_time": "2023-11-23T20:32:15.511525300Z"
    }
   },
   "id": "81e2e45ad231f3a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c0bccaffd9c00666"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
