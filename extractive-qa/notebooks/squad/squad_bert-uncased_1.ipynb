{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model details\n",
    "***Used base model***: bert-base-uncased\n",
    "***Used dataset***: SQuAD\n",
    "***Batch size***: 8\n",
    "***Early stopping patience***: 1\n",
    "***Early stopping monitor***: val loss\n",
    "***Attempted train epochs***: 10\n",
    "***Initial learning rate***: 2e-5\n",
    "***End learning rate***: 0\n",
    "***Additional info***: Filtered out samples with number of tokens exceeding 384, stride mechanism isn't used"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6033b022e272db7b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:55:32.667104500Z",
     "start_time": "2023-10-30T16:55:28.974930100Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForQuestionAnswering,\n",
    "    DefaultDataCollator,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from question_answering.constants import constants\n",
    "from question_answering.utils import core_qa_utils, extractive_qa_utils\n",
    "from question_answering.paths import extractive_qa_paths\n",
    "import ipynbname\n",
    "from question_answering.keras_callbacks.time_measure_callback import TimeMeasureCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading, analyzing and preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b077f95b9c1b3921"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load SQuAD dataset\n",
    "df_train, df_val, df_test = core_qa_utils.load_train_val_test_datasets(\n",
    "    extractive_qa_paths.squad_dataset_dir\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = core_qa_utils.convert_dataframes_to_datasets(\n",
    "    [df_train, df_val, df_test]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4d5582762271c20"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db291e0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:55:34.310328600Z",
     "start_time": "2023-10-30T16:55:33.761176600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the base model and load its tokenizer\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e53325b1b3a28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:03.091160600Z",
     "start_time": "2023-10-30T16:56:26.167624100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object filter_samples_below_number_of_tokens.<locals>.<genexpr> at 0x0000014E0938CC80> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "# Filter samples that are too long for model to handle\n",
    "max_length = 384\n",
    "\n",
    "\n",
    "def tokenize_sample(sample, max_tokens=None, padding=False):\n",
    "    question = sample[\"question\"].strip()\n",
    "    context = sample[\"context\"].strip()\n",
    "\n",
    "    return tokenizer(question, context, max_length=max_tokens, padding=padding)\n",
    "\n",
    "\n",
    "def filter_samples_below_number_of_tokens(dataset, max_tokens: int):\n",
    "    indices_to_remove = []\n",
    "\n",
    "    # Find indices of samples where number of tokens exceeds max number of tokens\n",
    "    for index, sample in enumerate(dataset):\n",
    "        tokenized_sample = tokenize_sample(sample)\n",
    "        if len(tokenized_sample[\"input_ids\"]) > max_tokens:\n",
    "            indices_to_remove.append(index)\n",
    "\n",
    "    # Keep only samples with number of tokens less or equal than max number of tokens\n",
    "    dataset_indices = range(len(dataset))\n",
    "    filtered_dataset = dataset.select(\n",
    "        index for index in dataset_indices if index not in set(indices_to_remove)\n",
    "    )\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "\n",
    "filtered_train_dataset = filter_samples_below_number_of_tokens(\n",
    "    train_dataset, max_tokens=max_length\n",
    ")\n",
    "filtered_val_dataset = filter_samples_below_number_of_tokens(\n",
    "    val_dataset, max_tokens=max_length\n",
    ")\n",
    "filtered_test_dataset = filter_samples_below_number_of_tokens(\n",
    "    test_dataset, max_tokens=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1aebcb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:03.108191900Z",
     "start_time": "2023-10-30T16:57:03.093160900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in tokenized train dataset before filtering:  68716\n",
      "Number of samples in tokenized val dataset before filtering:  14724\n",
      "Number of samples in tokenized test dataset before filtering:  14725\n",
      "\n",
      "---------------\n",
      "\n",
      "Number of samples in tokenized train dataset after filtering:  67964\n",
      "Number of samples in tokenized val dataset after filtering:  14573\n",
      "Number of samples in tokenized test dataset after filtering:  14552\n"
     ]
    }
   ],
   "source": [
    "# Check how much samples were there before filtering too long samples and how much are there now\n",
    "print(\n",
    "    \"Number of samples in tokenized train dataset before filtering: \",\n",
    "    len(train_dataset),\n",
    ")\n",
    "print(\"Number of samples in tokenized val dataset before filtering: \", len(val_dataset))\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset before filtering: \", len(test_dataset)\n",
    ")\n",
    "\n",
    "print(\"\\n---------------\\n\")\n",
    "\n",
    "print(\n",
    "    \"Number of samples in tokenized train dataset after filtering: \",\n",
    "    len(filtered_train_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized val dataset after filtering: \",\n",
    "    len(filtered_val_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset after filtering: \",\n",
    "    len(filtered_test_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6cdd06c7a27f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:03.154193300Z",
     "start_time": "2023-10-30T16:57:03.109193100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function for preprocessing the dataset\n",
    "def preprocess_dataset(dataset):\n",
    "    questions = [q.strip() for q in dataset[\"question\"]]\n",
    "    contexts = [c.strip() for c in dataset[\"context\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "\n",
    "    answer_start_indices = dataset[\"answer_start\"]\n",
    "    answer_texts = dataset[\"answer_text\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for index, offset in enumerate(offset_mapping):\n",
    "        start_char = answer_start_indices[index]\n",
    "        end_char = start_char + len(answer_texts[index])\n",
    "        sequence_ids = inputs.sequence_ids(index)\n",
    "\n",
    "        # Find the start and end token indices of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        idx = context_start\n",
    "        while idx <= context_end and offset[idx][0] <= start_char:\n",
    "            idx += 1\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "        idx = context_end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:\n",
    "            idx -= 1\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b72cf37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:26.949334800Z",
     "start_time": "2023-10-30T16:57:03.125194800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0696a72a55c46d8a5451738d2005dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f237b0f3664856964b879e15b329c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14573 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a893bacc37964b509d36d361dbd7af1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14552 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "tokenized_train_dataset = filtered_train_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=[\"index\"],\n",
    ")\n",
    "tokenized_val_dataset = filtered_val_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=[\"index\"],\n",
    ")\n",
    "tokenized_test_dataset = filtered_test_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=[\"index\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc093e38a8b9eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:37.472560500Z",
     "start_time": "2023-10-30T16:57:26.950336Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokenized train dataset entries have 384 tokens:  True\n",
      "All tokenized val dataset entries have 384 tokens:  True\n",
      "All tokenized test dataset entries have 384 tokens:  True\n"
     ]
    }
   ],
   "source": [
    "# Check that all tokenized samples have max length of tokens\n",
    "print(\n",
    "    f\"All tokenized train dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_train_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    f\"All tokenized val dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_val_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    f\"All tokenized test dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_test_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e1f89c3dcff7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:37.485628Z",
     "start_time": "2023-10-30T16:57:37.474562Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "full_model_name = \"-\".join(ipynbname.name().split(\"_\"))\n",
    "\n",
    "# Checkpoints\n",
    "checkpoint_filename_template = constants.checkpoint_filename_template\n",
    "checkpoints_path = (\n",
    "    extractive_qa_paths.training_checkpoints_dir\n",
    "    / full_model_name\n",
    "    / checkpoint_filename_template\n",
    ")\n",
    "\n",
    "# Saved models\n",
    "saved_models_path = extractive_qa_paths.saved_models_dir / full_model_name\n",
    "\n",
    "# Evaluation\n",
    "model_evaluation_dir = extractive_qa_paths.model_evaluation_dir / full_model_name\n",
    "figures_dir = model_evaluation_dir / constants.figures_dir_name\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "train_epochs = 10\n",
    "initial_learning_rate = 2e-5\n",
    "end_learning_rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = core_qa_utils.convert_to_tf_dataset(\n",
    "    hf_dataset=tokenized_train_dataset,\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"start_positions\", \"end_positions\"],\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "tf_val_dataset = core_qa_utils.convert_to_tf_dataset(\n",
    "    hf_dataset=tokenized_val_dataset,\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"start_positions\", \"end_positions\"],\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "tf_test_dataset = core_qa_utils.convert_to_tf_dataset(\n",
    "    hf_dataset=tokenized_test_dataset,\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"start_positions\", \"end_positions\"],\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d241c07ca33fae70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63303d41902b0202"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d5bedb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:39.968658400Z",
     "start_time": "2023-10-30T16:57:37.487627800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model for fine-tuning\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9266b102c3f216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:40.175069100Z",
     "start_time": "2023-10-30T16:57:39.942660400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoints_path, verbose=1, save_weights_only=True\n",
    ")\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "time_measure_cb = TimeMeasureCallback()\n",
    "\n",
    "callbacks = [checkpoint_cb, early_stop_cb, time_measure_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4ec7915adf3b24c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:40.223080500Z",
     "start_time": "2023-10-30T16:57:40.208081400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "num_train_steps = len(tf_train_dataset) * train_epochs\n",
    "\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    end_learning_rate=end_learning_rate,\n",
    "    decay_steps=num_train_steps,\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# Compile\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [\"accuracy\"]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ed3bc04bffb6bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:40.278080100Z",
     "start_time": "2023-10-30T16:57:40.224080200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108891648 \n",
      "                                                                 \n",
      " qa_outputs (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,893,186\n",
      "Trainable params: 108,893,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d016bd9af345c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:58:02.542718600Z",
     "start_time": "2023-10-30T16:57:40.257080200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the model on the new data\n",
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_val_dataset,\n",
    "    epochs=train_epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot training figures\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"start_logits_accuracy\", \"val_start_logits_accuracy\"],\n",
    "    title=\"Model start logits accuracy\",\n",
    "    y_label=\"Accuracy\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_start_accuracy.png\",\n",
    ")\n",
    "\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"end_logits_accuracy\", \"val_end_logits_accuracy\"],\n",
    "    title=\"Model end logits accuracy\",\n",
    "    y_label=\"Accuracy\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_end_accuracy.png\",\n",
    ")\n",
    "\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"loss\", \"val_loss\"],\n",
    "    title=\"Model loss\",\n",
    "    y_label=\"Loss\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_loss.png\",\n",
    ")\n",
    "\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"start_logits_loss\", \"val_start_logits_loss\"],\n",
    "    title=\"Model start logits loss\",\n",
    "    y_label=\"Loss\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_start_loss.png\",\n",
    ")\n",
    "\n",
    "core_qa_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"end_logits_loss\", \"val_end_logits_loss\"],\n",
    "    title=\"Model end logits loss\",\n",
    "    y_label=\"Loss\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{full_model_name}_end_loss.png\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fea13d69640b6813"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get best version of the model\n",
    "best_model, best_epoch = core_qa_utils.get_best_model_from_checkpoints(\n",
    "    model, history, model_name=full_model_name, remove_checkpoints=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3bb5822853678b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save best model's weights\n",
    "extractive_qa_utils.save_model(best_model, model_name=full_model_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5833e48a61b8c809"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of the model on its test dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f3c39b4d6cfabf0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load best model\n",
    "loaded_model = extractive_qa_utils.load_model(\n",
    "    model_checkpoint, model_name=full_model_name\n",
    ")\n",
    "loaded_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a39737888dc79cf3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get predictions from the best model\n",
    "loaded_model_evaluation = loaded_model.evaluate(tf_test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2741f6a967e0f38e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model_preds = loaded_model.predict(tf_test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d05dc1dcbfba2cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert predictions to start and end position indices\n",
    "start_preds = extractive_qa_utils.get_class_preds(\n",
    "    predictions=loaded_model_preds, output_key=\"start_logits\"\n",
    ")\n",
    "end_preds = extractive_qa_utils.get_class_preds(\n",
    "    predictions=loaded_model_preds, output_key=\"end_logits\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "826e71c60ed88271"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert predictions to actual texts and mark samples as correctly predicted\n",
    "model_predictions = tokenized_test_dataset.map(\n",
    "    lambda row: extractive_qa_utils.extract_answer_tokens(row)\n",
    ")\n",
    "\n",
    "model_predictions = model_predictions.map(\n",
    "    lambda row: extractive_qa_utils.decode_answer_tokens(row, tokenizer)\n",
    ")\n",
    "\n",
    "model_predictions = model_predictions.map(\n",
    "    lambda row: extractive_qa_utils.mark_correct_predictions(row)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37d45745b501e709"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate start positions classification metrics\n",
    "(\n",
    "    start_precision,\n",
    "    start_recall,\n",
    "    start_f1,\n",
    ") = extractive_qa_utils.get_classification_evaluation_metrics(\n",
    "    class_actual=tokenized_test_dataset[\"start_positions\"],\n",
    "    class_preds=start_preds,\n",
    "    average=\"micro\",\n",
    ")\n",
    "\n",
    "print(f\"Start positions precision score: \", start_precision)\n",
    "print(f\"Start positions recall score: \", start_recall)\n",
    "print(f\"Start positions F1 score: \", start_f1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c42da820b498e35"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate end positions classification metrics\n",
    "(\n",
    "    end_precision,\n",
    "    end_recall,\n",
    "    end_f1,\n",
    ") = extractive_qa_utils.get_classification_evaluation_metrics(\n",
    "    class_actual=tokenized_test_dataset[\"end_positions\"],\n",
    "    class_preds=end_preds,\n",
    "    average=\"micro\",\n",
    ")\n",
    "\n",
    "print(f\"End positions precision score: \", end_precision)\n",
    "print(f\"End positions recall score: \", end_recall)\n",
    "print(f\"End positions F1 score: \", end_f1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93b0a88682c632e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate exact match for the test set\n",
    "(\n",
    "    exact_match_original,\n",
    "    exact_match_lowercase,\n",
    "    exact_match_lowercase_no_punctuation,\n",
    ") = extractive_qa_utils.calculate_pure_exact_match(\n",
    "    actual=model_predictions[\"answer_text\"],\n",
    "    predicted=model_predictions[\"predicted_answer_text\"],\n",
    ")\n",
    "\n",
    "print(f\"Exact match for original dataset: \", exact_match_original[\"exact_match\"])\n",
    "print(f\"Exact match case insensitive: \", exact_match_lowercase[\"exact_match\"])\n",
    "print(\n",
    "    f\"Exact match case insensitive and punctuation ignoring: \",\n",
    "    exact_match_lowercase_no_punctuation[\"exact_match\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70bd50e528a5ea34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate squad exact match for the test set\n",
    "squad_exact_match_results = extractive_qa_utils.calculate_squad_exact_match(\n",
    "    model_predictions\n",
    ")\n",
    "\n",
    "print(f\"SQuAD exact match: \", squad_exact_match_results[\"exact_match\"])\n",
    "print(f\"SQuAD F1: \", squad_exact_match_results[\"f1\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5eed2f3e2498f00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save all relevant training and evaluation metrics to a json file.\n",
    "evaluation_data = {\n",
    "    \"training\": {\n",
    "        \"metrics\": history.history,\n",
    "        \"attempted_epochs\": train_epochs,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"training_time\": time_measure_cb.total_training_time(),\n",
    "        \"gpu\": core_qa_utils.get_gpu_name(),\n",
    "    },\n",
    "    \"test_set\": {\n",
    "        \"loss\": loaded_model_evaluation[0],\n",
    "        \"end_logits_loss\": loaded_model_evaluation[1],\n",
    "        \"start_logits_loss\": loaded_model_evaluation[2],\n",
    "        \"end_logits_accuracy\": loaded_model_evaluation[3],\n",
    "        \"start_logits_accuracy\": loaded_model_evaluation[4],\n",
    "        \"start_positions\": {\n",
    "            \"precision\": start_precision,\n",
    "            \"recall\": start_recall,\n",
    "            \"f1\": start_f1,\n",
    "        },\n",
    "        \"end_positions\": {\n",
    "            \"precision\": end_precision,\n",
    "            \"recall\": end_recall,\n",
    "            \"f1\": end_f1,\n",
    "        },\n",
    "        \"exact_match\": {\n",
    "            \"case_sensitive\": exact_match_original[\"exact_match\"],\n",
    "            \"case_insensitive\": exact_match_lowercase[\"exact_match\"],\n",
    "            \"case_insensitive_and_no_punctuation\": exact_match_lowercase[\"exact_match\"],\n",
    "            \"squad\": squad_exact_match_results[\"exact_match\"],\n",
    "            \"squad_f1\": squad_exact_match_results[\"f1\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "core_qa_utils.save_dict_as_json(\n",
    "    evaluation_data, dir_path=model_evaluation_dir, filename=\"evaluation_data.json\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa5bec434e96e98d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "model_predictions = model_predictions.remove_columns(\n",
    "    [\"input_ids\", \"token_type_ids\", \"attention_mask\", \"answer_tokens\", \"answer_start\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d51b720b7ef8144d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if there exist any predictions where start position is greater than end positions\n",
    "for prediction in model_predictions:\n",
    "    if prediction[\"start_positions\"] > prediction[\"end_positions\"]:\n",
    "        print(\"Correct answer\", prediction[\"answer_text\"])\n",
    "        print(\"Predicted answer: \", prediction[\"predicted_answer_text\"])\n",
    "        print(\n",
    "            \"Start: \",\n",
    "            prediction[\"start_positions\"],\n",
    "            \" End: \",\n",
    "            prediction[\"end_positions\"],\n",
    "        )\n",
    "        print(\"------------\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7db96781a0601f91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save test dataset evaluation\n",
    "final_evaluation_df = model_predictions.to_pandas()\n",
    "final_evaluation_df.to_csv(\n",
    "    model_evaluation_dir / \"test_set_evaluation.csv\", index=True, index_label=\"index\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dfbcaf6ea3b5a0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of model trained on SQuAD on COVID-19 dataset\n",
    "\n",
    "Makes no sense due to the nature of the COVID-19 dataset which has very long contexts. This model however does not use stride technique and handles only shorter samples, making such evaluation obsolete."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b13dc29429cc1a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e8521b844c19985"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "question_answering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
